2022-05-12 16:52:45.589 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee602c2520>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fefa2c391f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fefa2bfc5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee606b7f10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fefa2becf70>
    └ <urllib3.connection.HTTPConnection object at 0x7fee602c2520>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fee602c2520>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fefa9ea3280>
    └ <urllib3.connection.HTTPConnection object at 0x7fee602c2520>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection.endheaders at 0x7fefa9ea3160>
    └ <urllib3.connection.HTTPConnection object at 0x7fee602c2520>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection._send_output at 0x7fefb84eed30>
    └ <urllib3.connection.HTTPConnection object at 0x7fee602c2520>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fefb84eeb80>
    └ <urllib3.connection.HTTPConnection object at 0x7fee602c2520>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fefa2becdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7fee602c2520>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fefa2becc10>
           └ <urllib3.connection.HTTPConnection object at 0x7fee602c2520>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fee602c2520>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fefa2bfc820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee606b7f10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fefa2c44b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee602c2520>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee606b7f10>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee602c2520>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fefc8c5ea60>
    └ <Thread(Thread-147, started daemon 140660766136064)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fefc8c5e790>
    └ <Thread(Thread-147, started daemon 140660766136064)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-147, started daemon 140660766136064)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-147, started daemon 140660766136064)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7feeb1169520>>
    └ <Thread(Thread-147, started daemon 140660766136064)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7feeb116f040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>
    └ <monitor.projectManager.ProjectManager object at 0x7feeb1169520>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7feeb0ea5af0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fee801e0640>
    │    │                                │              │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7feeb116f0d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fefa90e0550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fee801e0640>
               │    │                        │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7feeb116f1f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fee803a4160>
                   │    │       │                                  │        │           └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
                   │    │       │                                  │        └ <string.Template object at 0x7fee60396580>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7feeb0dc6490>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
               │        │    │          └ <function Template.substitute at 0x7fefc8c470d0>
               │        │    └ <string.Template object at 0x7fee60396580>
               │        └ <function post at 0x7fefa2a233a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fefa2a8d040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fefa2a22940>
           └ <requests.sessions.Session object at 0x7fee80470e50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fefa2a22dc0>
           └ <requests.sessions.Session object at 0x7fee80470e50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fefa2a22280>
        └ <requests.adapters.HTTPAdapter object at 0x7fee407e1370>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee602c2520>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:52:45.635 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee403728b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fefa2c391f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fefa2bfc5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee60417e80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fefa2becf70>
    └ <urllib3.connection.HTTPConnection object at 0x7fee403728b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fee403728b0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fefa9ea3280>
    └ <urllib3.connection.HTTPConnection object at 0x7fee403728b0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection.endheaders at 0x7fefa9ea3160>
    └ <urllib3.connection.HTTPConnection object at 0x7fee403728b0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection._send_output at 0x7fefb84eed30>
    └ <urllib3.connection.HTTPConnection object at 0x7fee403728b0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fefb84eeb80>
    └ <urllib3.connection.HTTPConnection object at 0x7fee403728b0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fefa2becdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7fee403728b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fefa2becc10>
           └ <urllib3.connection.HTTPConnection object at 0x7fee403728b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fee403728b0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fefa2bfc820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee60417e80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fefa2c44b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee403728b0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee60417e80>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee403728b0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fefc8c5ea60>
    └ <Thread(Thread-152, started daemon 140660749350656)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fefc8c5e790>
    └ <Thread(Thread-152, started daemon 140660749350656)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-152, started daemon 140660749350656)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-152, started daemon 140660749350656)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7feeb1169520>>
    └ <Thread(Thread-152, started daemon 140660749350656)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7feeb116f040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>
    └ <monitor.projectManager.ProjectManager object at 0x7feeb1169520>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7feeb0ea5af0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fee804b5820>
    │    │                                │              │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7feeb116f0d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fefa90e0550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fee804b5820>
               │    │                        │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7feeb116f1f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fee2066c040>
                   │    │       │                                  │        │           └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
                   │    │       │                                  │        └ <string.Template object at 0x7fee2066c700>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7feeb0dc6490>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
               │        │    │          └ <function Template.substitute at 0x7fefc8c470d0>
               │        │    └ <string.Template object at 0x7fee2066c700>
               │        └ <function post at 0x7fefa2a233a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fefa2a8d040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fefa2a22940>
           └ <requests.sessions.Session object at 0x7fee4044df40>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fefa2a22dc0>
           └ <requests.sessions.Session object at 0x7fee4044df40>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fefa2a22280>
        └ <requests.adapters.HTTPAdapter object at 0x7fee6068b850>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee403728b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:52:46.626 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee203b2820>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fefa2c391f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fefa2bfc5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7feeb00f0160>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit"...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fefa2becf70>
    └ <urllib3.connection.HTTPConnection object at 0x7fee203b2820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit": 10, "ha...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fee203b2820>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit": 10, "ha...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fefa9ea3280>
    └ <urllib3.connection.HTTPConnection object at 0x7fee203b2820>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit": 10, "ha...
    │    └ <function HTTPConnection.endheaders at 0x7fefa9ea3160>
    └ <urllib3.connection.HTTPConnection object at 0x7fee203b2820>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit": 10, "ha...
    │    └ <function HTTPConnection._send_output at 0x7fefb84eed30>
    └ <urllib3.connection.HTTPConnection object at 0x7fee203b2820>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fefb84eeb80>
    └ <urllib3.connection.HTTPConnection object at 0x7fee203b2820>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fefa2becdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7fee203b2820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fefa2becc10>
           └ <urllib3.connection.HTTPConnection object at 0x7fee203b2820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fee203b2820>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fefa2bfc820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7feeb00f0160>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fefa2c44b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee203b2820>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7feeb00f0160>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee203b2820>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fefc8c5ea60>
    └ <Thread(Thread-74, started daemon 140661839877888)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fefc8c5e790>
    └ <Thread(Thread-74, started daemon 140661839877888)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-74, started daemon 140661839877888)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-74, started daemon 140661839877888)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7feeb1169520>>
    └ <Thread(Thread-74, started daemon 140661839877888)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7feeb116f040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>
    └ <monitor.projectManager.ProjectManager object at 0x7feeb1169520>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7feeb0ea5af0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7feea0230730>
    │    │                                │              │         └ '印度启动无人战车研发计划'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7feeb116f0d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fefa90e0550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7feea0230730>
               │    │                        │         └ '印度启动无人战车研发计划'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7feeb116f1f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fee8065ba60>
                   │    │       │                                  │        │           └ '印度启动无人战车研发计划'
                   │    │       │                                  │        └ <string.Template object at 0x7fee205e2940>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7feeb0dc6490>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '印度启动无人战车研发计划', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType':...
               │        │    │          └ <function Template.substitute at 0x7fefc8c470d0>
               │        │    └ <string.Template object at 0x7fee205e2940>
               │        └ <function post at 0x7fefa2a233a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '印度启动无人战车研发计划', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType':...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fefa2a8d040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '印度启动无人战车研发计划', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True,...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fefa2a22940>
           └ <requests.sessions.Session object at 0x7fee40067520>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fefa2a22dc0>
           └ <requests.sessions.Session object at 0x7fee40067520>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fefa2a22280>
        └ <requests.adapters.HTTPAdapter object at 0x7fee6018bb50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee203b2820>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:52:48.254 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee8009fd90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fefa2c391f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fefa2bfc5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee4022eca0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fefa2becf70>
    └ <urllib3.connection.HTTPConnection object at 0x7fee8009fd90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fee8009fd90>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fefa9ea3280>
    └ <urllib3.connection.HTTPConnection object at 0x7fee8009fd90>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection.endheaders at 0x7fefa9ea3160>
    └ <urllib3.connection.HTTPConnection object at 0x7fee8009fd90>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection._send_output at 0x7fefb84eed30>
    └ <urllib3.connection.HTTPConnection object at 0x7fee8009fd90>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fefb84eeb80>
    └ <urllib3.connection.HTTPConnection object at 0x7fee8009fd90>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fefa2becdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7fee8009fd90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fefa2becc10>
           └ <urllib3.connection.HTTPConnection object at 0x7fee8009fd90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fee8009fd90>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fefa2bfc820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee4022eca0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fefa2c44b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee8009fd90>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee4022eca0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee8009fd90>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fefc8c5ea60>
    └ <Thread(Thread-180, started daemon 140660220872448)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fefc8c5e790>
    └ <Thread(Thread-180, started daemon 140660220872448)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-180, started daemon 140660220872448)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-180, started daemon 140660220872448)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7feeb1169520>>
    └ <Thread(Thread-180, started daemon 140660220872448)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7feeb116f040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>
    └ <monitor.projectManager.ProjectManager object at 0x7feeb1169520>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7feeb0ea5af0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7feeb00f3dc0>
    │    │                                │              │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7feeb116f0d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fefa90e0550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7feeb00f3dc0>
               │    │                        │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7feeb116f1f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fee60104550>
                   │    │       │                                  │        │           └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
                   │    │       │                                  │        └ <string.Template object at 0x7fee803f4280>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7feeb0dc6490>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
               │        │    │          └ <function Template.substitute at 0x7fefc8c470d0>
               │        │    └ <string.Template object at 0x7fee803f4280>
               │        └ <function post at 0x7fefa2a233a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fefa2a8d040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fefa2a22940>
           └ <requests.sessions.Session object at 0x7fee805a3820>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fefa2a22dc0>
           └ <requests.sessions.Session object at 0x7fee805a3820>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fefa2a22280>
        └ <requests.adapters.HTTPAdapter object at 0x7fee402009a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee8009fd90>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:52:50.083 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fefa2c391f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fefa2bfc5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee60474460>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fefa2becf70>
    └ <urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fefa9ea3280>
    └ <urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection.endheaders at 0x7fefa9ea3160>
    └ <urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection._send_output at 0x7fefb84eed30>
    └ <urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fefb84eeb80>
    └ <urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fefa2becdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fefa2becc10>
           └ <urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fefa2bfc820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee60474460>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fefa2c44b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee60474460>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fefc8c5ea60>
    └ <Thread(Thread-170, started daemon 140660246050560)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fefc8c5e790>
    └ <Thread(Thread-170, started daemon 140660246050560)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-170, started daemon 140660246050560)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-170, started daemon 140660246050560)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7feeb1169520>>
    └ <Thread(Thread-170, started daemon 140660246050560)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7feeb116f040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>
    └ <monitor.projectManager.ProjectManager object at 0x7feeb1169520>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7feeb0ea5af0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7feea04e82e0>
    │    │                                │              │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7feeb116f0d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fefa90e0550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7feea04e82e0>
               │    │                        │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7feeb116f1f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7feea0576130>
                   │    │       │                                  │        │           └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
                   │    │       │                                  │        └ <string.Template object at 0x7feeb00b8b80>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7feeb0dc6490>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
               │        │    │          └ <function Template.substitute at 0x7fefc8c470d0>
               │        │    └ <string.Template object at 0x7feeb00b8b80>
               │        └ <function post at 0x7fefa2a233a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fefa2a8d040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fefa2a22940>
           └ <requests.sessions.Session object at 0x7fee40347bb0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fefa2a22dc0>
           └ <requests.sessions.Session object at 0x7fee40347bb0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fefa2a22280>
        └ <requests.adapters.HTTPAdapter object at 0x7feea0293c10>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee2056b2e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:52:51.924 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee6014db80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fefa2c391f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fefa2bfc5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee60497250>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fefa2becf70>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6014db80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fee6014db80>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fefa9ea3280>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6014db80>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection.endheaders at 0x7fefa9ea3160>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6014db80>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection._send_output at 0x7fefb84eed30>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6014db80>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fefb84eeb80>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6014db80>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fefa2becdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6014db80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fefa2becc10>
           └ <urllib3.connection.HTTPConnection object at 0x7fee6014db80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fee6014db80>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fefa2bfc820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee60497250>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fefa2c44b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee6014db80>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee60497250>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee6014db80>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fefc8c5ea60>
    └ <Thread(Thread-166, started daemon 140660237657856)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fefc8c5e790>
    └ <Thread(Thread-166, started daemon 140660237657856)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-166, started daemon 140660237657856)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-166, started daemon 140660237657856)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7feeb1169520>>
    └ <Thread(Thread-166, started daemon 140660237657856)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7feeb116f040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>
    └ <monitor.projectManager.ProjectManager object at 0x7feeb1169520>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7feeb0ea5af0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7feea03e0af0>
    │    │                                │              │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7feeb116f0d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fefa90e0550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7feea03e0af0>
               │    │                        │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7feeb116f1f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fee80647280>
                   │    │       │                                  │        │           └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
                   │    │       │                                  │        └ <string.Template object at 0x7fee6078aca0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7feeb0dc6490>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
               │        │    │          └ <function Template.substitute at 0x7fefc8c470d0>
               │        │    └ <string.Template object at 0x7fee6078aca0>
               │        └ <function post at 0x7fefa2a233a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fefa2a8d040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fefa2a22940>
           └ <requests.sessions.Session object at 0x7fee8037a250>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fefa2a22dc0>
           └ <requests.sessions.Session object at 0x7fee8037a250>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fefa2a22280>
        └ <requests.adapters.HTTPAdapter object at 0x7fee40365370>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee6014db80>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:52:52.329 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7feeb019ca00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fefa2c391f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fefa2bfc5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7feeb03cbf70>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fefa2becf70>
    └ <urllib3.connection.HTTPConnection object at 0x7feeb019ca00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7feeb019ca00>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fefa9ea3280>
    └ <urllib3.connection.HTTPConnection object at 0x7feeb019ca00>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection.endheaders at 0x7fefa9ea3160>
    └ <urllib3.connection.HTTPConnection object at 0x7feeb019ca00>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection._send_output at 0x7fefb84eed30>
    └ <urllib3.connection.HTTPConnection object at 0x7feeb019ca00>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fefb84eeb80>
    └ <urllib3.connection.HTTPConnection object at 0x7feeb019ca00>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fefa2becdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7feeb019ca00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fefa2becc10>
           └ <urllib3.connection.HTTPConnection object at 0x7feeb019ca00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7feeb019ca00>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fefa2bfc820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7feeb03cbf70>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fefa2c44b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7feeb019ca00>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7feeb03cbf70>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7feeb019ca00>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fefc8c5ea60>
    └ <Thread(Thread-175, started daemon 140660229265152)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fefc8c5e790>
    └ <Thread(Thread-175, started daemon 140660229265152)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-175, started daemon 140660229265152)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-175, started daemon 140660229265152)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7feeb1169520>>
    └ <Thread(Thread-175, started daemon 140660229265152)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7feeb116f040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>
    └ <monitor.projectManager.ProjectManager object at 0x7feeb1169520>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7feeb0ea5af0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7feea04e2820>
    │    │                                │              │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7feeb116f0d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fefa90e0550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7feea04e2820>
               │    │                        │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7feeb116f1f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7feeb019c850>
                   │    │       │                                  │        │           └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
                   │    │       │                                  │        └ <string.Template object at 0x7feea006aeb0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7feeb0dc6490>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
               │        │    │          └ <function Template.substitute at 0x7fefc8c470d0>
               │        │    └ <string.Template object at 0x7feea006aeb0>
               │        └ <function post at 0x7fefa2a233a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fefa2a8d040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fefa2a22940>
           └ <requests.sessions.Session object at 0x7fee602c8850>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fefa2a22dc0>
           └ <requests.sessions.Session object at 0x7fee602c8850>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fefa2a22280>
        └ <requests.adapters.HTTPAdapter object at 0x7fee4074dd90>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7feeb019ca00>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:52:52.851 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee6047ba00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fefa2c391f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fefa2bfc5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee8046af40>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u82f1\\u56fd\\u65b0\\u578b\\u62a4\\u536b\\u8230\\u9996\\u8230\\u4e3e\\u884c\\u9f99\\u9aa8\\u94fa\\u8bbe...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fefa2becf70>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6047ba00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u82f1\\u56fd\\u65b0\\u578b\\u62a4\\u536b\\u8230\\u9996\\u8230\\u4e3e\\u884c\\u9f99\\u9aa8\\u94fa\\u8bbe\\u4eea\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fee6047ba00>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u82f1\\u56fd\\u65b0\\u578b\\u62a4\\u536b\\u8230\\u9996\\u8230\\u4e3e\\u884c\\u9f99\\u9aa8\\u94fa\\u8bbe\\u4eea\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fefa9ea3280>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6047ba00>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u82f1\\u56fd\\u65b0\\u578b\\u62a4\\u536b\\u8230\\u9996\\u8230\\u4e3e\\u884c\\u9f99\\u9aa8\\u94fa\\u8bbe\\u4eea\\...
    │    └ <function HTTPConnection.endheaders at 0x7fefa9ea3160>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6047ba00>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u82f1\\u56fd\\u65b0\\u578b\\u62a4\\u536b\\u8230\\u9996\\u8230\\u4e3e\\u884c\\u9f99\\u9aa8\\u94fa\\u8bbe\\u4eea\\...
    │    └ <function HTTPConnection._send_output at 0x7fefb84eed30>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6047ba00>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fefb84eeb80>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6047ba00>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fefa2becdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6047ba00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fefa2becc10>
           └ <urllib3.connection.HTTPConnection object at 0x7fee6047ba00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fee6047ba00>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fefa2bfc820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee8046af40>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fefa2c44b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee6047ba00>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee8046af40>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee6047ba00>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fefc8c5ea60>
    └ <Thread(Thread-208, started daemon 140659692394240)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fefc8c5e790>
    └ <Thread(Thread-208, started daemon 140659692394240)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-208, started daemon 140659692394240)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-208, started daemon 140659692394240)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7feeb1169520>>
    └ <Thread(Thread-208, started daemon 140659692394240)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7feeb116f040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>
    └ <monitor.projectManager.ProjectManager object at 0x7feeb1169520>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7feeb0ea5af0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7feea0644a30>
    │    │                                │              │         └ '英国新型护卫舰首舰举行龙骨铺设仪式'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7feeb116f0d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fefa90e0550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7feea0644a30>
               │    │                        │         └ '英国新型护卫舰首舰举行龙骨铺设仪式'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7feeb116f1f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fee207c91f0>
                   │    │       │                                  │        │           └ '英国新型护卫舰首舰举行龙骨铺设仪式'
                   │    │       │                                  │        └ <string.Template object at 0x7fee203b2b20>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7feeb0dc6490>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '英国新型护卫舰首舰举行龙骨铺设仪式', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortT...
               │        │    │          └ <function Template.substitute at 0x7fefc8c470d0>
               │        │    └ <string.Template object at 0x7fee203b2b20>
               │        └ <function post at 0x7fefa2a233a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '英国新型护卫舰首舰举行龙骨铺设仪式', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortT...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fefa2a8d040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '英国新型护卫舰首舰举行龙骨铺设仪式', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': ...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fefa2a22940>
           └ <requests.sessions.Session object at 0x7feea0fb2670>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fefa2a22dc0>
           └ <requests.sessions.Session object at 0x7feea0fb2670>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fefa2a22280>
        └ <requests.adapters.HTTPAdapter object at 0x7fee8074b520>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee6047ba00>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:52:53.641 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee606b78b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fefa2c391f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fefa2bfc5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee20785e80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit"...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fefa2becf70>
    └ <urllib3.connection.HTTPConnection object at 0x7fee606b78b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit": 10, "ha...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fee606b78b0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit": 10, "ha...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fefa9ea3280>
    └ <urllib3.connection.HTTPConnection object at 0x7fee606b78b0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit": 10, "ha...
    │    └ <function HTTPConnection.endheaders at 0x7fefa9ea3160>
    └ <urllib3.connection.HTTPConnection object at 0x7fee606b78b0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit": 10, "ha...
    │    └ <function HTTPConnection._send_output at 0x7fefb84eed30>
    └ <urllib3.connection.HTTPConnection object at 0x7fee606b78b0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fefb84eeb80>
    └ <urllib3.connection.HTTPConnection object at 0x7fee606b78b0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fefa2becdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7fee606b78b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fefa2becc10>
           └ <urllib3.connection.HTTPConnection object at 0x7fee606b78b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fee606b78b0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fefa2bfc820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee20785e80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fefa2c44b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee606b78b0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee20785e80>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee606b78b0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fefc8c5ea60>
    └ <Thread(Thread-15, started daemon 140662913619712)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fefc8c5e790>
    └ <Thread(Thread-15, started daemon 140662913619712)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-15, started daemon 140662913619712)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-15, started daemon 140662913619712)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7feeb1169520>>
    └ <Thread(Thread-15, started daemon 140662913619712)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7feeb116f040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>
    └ <monitor.projectManager.ProjectManager object at 0x7feeb1169520>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7feeb0ea5af0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7feeb0438ac0>
    │    │                                │              │         └ '印度启动无人战车研发计划'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7feeb116f0d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fefa90e0550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7feeb0438ac0>
               │    │                        │         └ '印度启动无人战车研发计划'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7feeb116f1f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7feea0576d30>
                   │    │       │                                  │        │           └ '印度启动无人战车研发计划'
                   │    │       │                                  │        └ <string.Template object at 0x7fee6014d850>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7feeb0dc6490>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '印度启动无人战车研发计划', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType':...
               │        │    │          └ <function Template.substitute at 0x7fefc8c470d0>
               │        │    └ <string.Template object at 0x7fee6014d850>
               │        └ <function post at 0x7fefa2a233a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '印度启动无人战车研发计划', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType':...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fefa2a8d040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '印度启动无人战车研发计划', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True,...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fefa2a22940>
           └ <requests.sessions.Session object at 0x7feea0414070>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fefa2a22dc0>
           └ <requests.sessions.Session object at 0x7feea0414070>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fefa2a22280>
        └ <requests.adapters.HTTPAdapter object at 0x7fee4022ea00>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee606b78b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:52:54.439 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee403aaa90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fefa2c391f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fefa2bfc5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee4066ce80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u738b\\u6bc5\\uff1a\\u4e2d\\u65b9\\u613f\\u540c\\u5df4\\u65b9\\u4e00\\u9053\\uff0c\\u575a\\u51b3\\u632b...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fefa2becf70>
    └ <urllib3.connection.HTTPConnection object at 0x7fee403aaa90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u738b\\u6bc5\\uff1a\\u4e2d\\u65b9\\u613f\\u540c\\u5df4\\u65b9\\u4e00\\u9053\\uff0c\\u575a\\u51b3\\u632b\\u8d25\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fee403aaa90>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u738b\\u6bc5\\uff1a\\u4e2d\\u65b9\\u613f\\u540c\\u5df4\\u65b9\\u4e00\\u9053\\uff0c\\u575a\\u51b3\\u632b\\u8d25\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fefa9ea3280>
    └ <urllib3.connection.HTTPConnection object at 0x7fee403aaa90>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u738b\\u6bc5\\uff1a\\u4e2d\\u65b9\\u613f\\u540c\\u5df4\\u65b9\\u4e00\\u9053\\uff0c\\u575a\\u51b3\\u632b\\u8d25\\...
    │    └ <function HTTPConnection.endheaders at 0x7fefa9ea3160>
    └ <urllib3.connection.HTTPConnection object at 0x7fee403aaa90>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u738b\\u6bc5\\uff1a\\u4e2d\\u65b9\\u613f\\u540c\\u5df4\\u65b9\\u4e00\\u9053\\uff0c\\u575a\\u51b3\\u632b\\u8d25\\...
    │    └ <function HTTPConnection._send_output at 0x7fefb84eed30>
    └ <urllib3.connection.HTTPConnection object at 0x7fee403aaa90>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fefb84eeb80>
    └ <urllib3.connection.HTTPConnection object at 0x7fee403aaa90>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fefa2becdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7fee403aaa90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fefa2becc10>
           └ <urllib3.connection.HTTPConnection object at 0x7fee403aaa90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fee403aaa90>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fefa2bfc820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee4066ce80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fefa2c44b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee403aaa90>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee4066ce80>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee403aaa90>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fefc8c5ea60>
    └ <Thread(Thread-212, started daemon 140659675608832)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fefc8c5e790>
    └ <Thread(Thread-212, started daemon 140659675608832)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-212, started daemon 140659675608832)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-212, started daemon 140659675608832)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7feeb1169520>>
    └ <Thread(Thread-212, started daemon 140659675608832)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7feeb116f040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>
    └ <monitor.projectManager.ProjectManager object at 0x7feeb1169520>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7feeb0ea5af0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fee407e2310>
    │    │                                │              │         └ '王毅：中方愿同巴方一道，坚决挫败一切破坏中巴关系的图谋'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7feeb116f0d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fefa90e0550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fee407e2310>
               │    │                        │         └ '王毅：中方愿同巴方一道，坚决挫败一切破坏中巴关系的图谋'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7feeb116f1f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7feea03cacd0>
                   │    │       │                                  │        │           └ '王毅：中方愿同巴方一道，坚决挫败一切破坏中巴关系的图谋'
                   │    │       │                                  │        └ <string.Template object at 0x7fee407a3490>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7feeb0dc6490>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '王毅：中方愿同巴方一道，坚决挫败一切破坏中巴关系的图谋', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type':...
               │        │    │          └ <function Template.substitute at 0x7fefc8c470d0>
               │        │    └ <string.Template object at 0x7fee407a3490>
               │        └ <function post at 0x7fefa2a233a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '王毅：中方愿同巴方一道，坚决挫败一切破坏中巴关系的图谋', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type':...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fefa2a8d040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '王毅：中方愿同巴方一道，坚决挫败一切破坏中巴关系的图谋', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, '...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fefa2a22940>
           └ <requests.sessions.Session object at 0x7fee406707c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fefa2a22dc0>
           └ <requests.sessions.Session object at 0x7fee406707c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fefa2a22280>
        └ <requests.adapters.HTTPAdapter object at 0x7fee80732a30>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee403aaa90>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:52:55.571 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee80043a00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fefa2c391f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fefa2bfc5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee40347ca0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit"...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fefa2becf70>
    └ <urllib3.connection.HTTPConnection object at 0x7fee80043a00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit": 10, "ha...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fee80043a00>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit": 10, "ha...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fefa9ea3280>
    └ <urllib3.connection.HTTPConnection object at 0x7fee80043a00>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit": 10, "ha...
    │    └ <function HTTPConnection.endheaders at 0x7fefa9ea3160>
    └ <urllib3.connection.HTTPConnection object at 0x7fee80043a00>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u5370\\u5ea6\\u542f\\u52a8\\u65e0\\u4eba\\u6218\\u8f66\\u7814\\u53d1\\u8ba1\\u5212", "page": 1, "limit": 10, "ha...
    │    └ <function HTTPConnection._send_output at 0x7fefb84eed30>
    └ <urllib3.connection.HTTPConnection object at 0x7fee80043a00>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fefb84eeb80>
    └ <urllib3.connection.HTTPConnection object at 0x7fee80043a00>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fefa2becdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7fee80043a00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fefa2becc10>
           └ <urllib3.connection.HTTPConnection object at 0x7fee80043a00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fee80043a00>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fefa2bfc820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee40347ca0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fefa2c44b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee80043a00>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee40347ca0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee80043a00>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fefc8c5ea60>
    └ <Thread(Thread-3, started daemon 140663145309952)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fefc8c5e790>
    └ <Thread(Thread-3, started daemon 140663145309952)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-3, started daemon 140663145309952)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-3, started daemon 140663145309952)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7feeb1169520>>
    └ <Thread(Thread-3, started daemon 140663145309952)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7feeb116f040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>
    └ <monitor.projectManager.ProjectManager object at 0x7feeb1169520>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7feeb0ea5af0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7feeb0dacf10>
    │    │                                │              │         └ '印度启动无人战车研发计划'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7feeb116f0d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fefa90e0550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7feeb0dacf10>
               │    │                        │         └ '印度启动无人战车研发计划'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7feeb116f1f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fee407d7ca0>
                   │    │       │                                  │        │           └ '印度启动无人战车研发计划'
                   │    │       │                                  │        └ <string.Template object at 0x7fee402a6f10>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7feeb0dc6490>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '印度启动无人战车研发计划', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType':...
               │        │    │          └ <function Template.substitute at 0x7fefc8c470d0>
               │        │    └ <string.Template object at 0x7fee402a6f10>
               │        └ <function post at 0x7fefa2a233a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '印度启动无人战车研发计划', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType':...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fefa2a8d040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '印度启动无人战车研发计划', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True,...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fefa2a22940>
           └ <requests.sessions.Session object at 0x7fee4073dd60>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fefa2a22dc0>
           └ <requests.sessions.Session object at 0x7fee4073dd60>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fefa2a22280>
        └ <requests.adapters.HTTPAdapter object at 0x7fee606afbb0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee80043a00>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:52:57.075 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fefa2c391f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fefa2bfc5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee401db280>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u53f8\\u6cd5\\u4eae\\u5251  \\u5b88\\u62a4\\u767e\\u59d3\\u517b\\u8001\\u94b1\\uff08\\u6cd5\\u6cbb\\u59...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fefa2becf70>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u53f8\\u6cd5\\u4eae\\u5251  \\u5b88\\u62a4\\u767e\\u59d3\\u517b\\u8001\\u94b1\\uff08\\u6cd5\\u6cbb\\u5934\\u6761...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u53f8\\u6cd5\\u4eae\\u5251  \\u5b88\\u62a4\\u767e\\u59d3\\u517b\\u8001\\u94b1\\uff08\\u6cd5\\u6cbb\\u5934\\u6761...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fefa9ea3280>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u53f8\\u6cd5\\u4eae\\u5251  \\u5b88\\u62a4\\u767e\\u59d3\\u517b\\u8001\\u94b1\\uff08\\u6cd5\\u6cbb\\u5934\\u6761...
    │    └ <function HTTPConnection.endheaders at 0x7fefa9ea3160>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u53f8\\u6cd5\\u4eae\\u5251  \\u5b88\\u62a4\\u767e\\u59d3\\u517b\\u8001\\u94b1\\uff08\\u6cd5\\u6cbb\\u5934\\u6761...
    │    └ <function HTTPConnection._send_output at 0x7fefb84eed30>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fefb84eeb80>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fefa2becdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fefa2becc10>
           └ <urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fefa2bfc820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee401db280>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fefa2c44b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fee401db280>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fefc8c5ea60>
    └ <Thread(Thread-111, started daemon 140661303006976)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fefc8c5e790>
    └ <Thread(Thread-111, started daemon 140661303006976)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-111, started daemon 140661303006976)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-111, started daemon 140661303006976)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7feeb1169520>>
    └ <Thread(Thread-111, started daemon 140661303006976)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7feeb116f040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>
    └ <monitor.projectManager.ProjectManager object at 0x7feeb1169520>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7feeb0ea5af0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fee8020f370>
    │    │                                │              │         └ '司法亮剑  守护百姓养老钱（法治头条）'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7feeb116f0d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fefa90e0550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fee8020f370>
               │    │                        │         └ '司法亮剑  守护百姓养老钱（法治头条）'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7feeb116f1f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fee403cc370>
                   │    │       │                                  │        │           └ '司法亮剑  守护百姓养老钱（法治头条）'
                   │    │       │                                  │        └ <string.Template object at 0x7feea05443a0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7feeb0dc6490>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7feeb0dc6c70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '司法亮剑  守护百姓养老钱（法治头条）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sor...
               │        │    │          └ <function Template.substitute at 0x7fefc8c470d0>
               │        │    └ <string.Template object at 0x7feea05443a0>
               │        └ <function post at 0x7fefa2a233a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '司法亮剑  守护百姓养老钱（法治头条）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sor...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fefa2a8d040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '司法亮剑  守护百姓养老钱（法治头条）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy'...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fefa2a22940>
           └ <requests.sessions.Session object at 0x7fee80643400>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fefa2a22dc0>
           └ <requests.sessions.Session object at 0x7fee80643400>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fefa2a22280>
        └ <requests.adapters.HTTPAdapter object at 0x7fee8074b970>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fee6060dfa0>: Failed to establish a new connection: [Errno 111] Connection refused'))
