2022-05-12 16:09:14.730 | ERROR    | monitor.searchSpiders.qinagguoLT:get_request_from_keyword:27 - E 强国论坛错误HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Max retries exceeded with url: /board/1.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90e4048b20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.223', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9124478c40>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': None, 'headers': {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0....
    │    │       │       └ '/board/1.html'
    │    │       └ 'GET'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f90e4048b20>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36', 'A...
          │               │             │       │         └ None
          │               │             │       └ '/board/1.html'
          │               │             └ 'GET'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f90e4048b20>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36', 'A...
    │    │             │       │    └ None
    │    │             │       └ '/board/1.html'
    │    │             └ 'GET'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f90e4048b20>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ None
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f90e4048b20>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ None
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f90e4048b20>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'GET /board/1.html HTTP/1.1\r\nHost: bbs1.people.com.cn\r\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (K...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f90e4048b20>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f90e4048b20>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f90e4048b20>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f90e4048b20>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9124478c40>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90e4048b20>: Failed to establish a new connection: [Errn...
          │             │      └ '/board/1.html'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9124478c40>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Max retries exceeded with url: /board/1.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90e4048b20>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-152, started daemon 140259799066368)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-152, started daemon 140259799066368)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-152, started daemon 140259799066368)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-152, started daemon 140259799066368)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-152, started daemon 140259799066368)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f916012db50>
    │    │                                │              │         └ '新华全媒+丨以青春的名义 致敬雄安'
    │    │                                │              └ '强国论坛'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f916012db50>
               │    │                        │         └ '新华全媒+丨以青春的名义 致敬雄安'
               │    │                        └ '强国论坛'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f90e40419d0>
                   │    │       │                                  │        │           └ '新华全媒+丨以青春的名义 致敬雄安'
                   │    │       │                                  │        └ <string.Template object at 0x7f91242919a0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (X11;...
                   │    │       └ '强国论坛'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qinagguoLT.py", line 18, in get_request_from_keyword
    response = requests.get(search_url.substitute(), headers=headers)
               │        │   │          │                     └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (X11;...
               │        │   │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │   └ <string.Template object at 0x7f91242919a0>
               │        └ <function get at 0x7f92583e71f0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozil...
           │              │           └ None
           │              └ 'http://bbs1.people.com.cn/board/1.html'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'Use...
           │       │              │           └ 'http://bbs1.people.com.cn/board/1.html'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f90a41ad5b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f90a41ad5b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f90c4717a00>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Max retries exceeded with url: /board/1.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90e4048b20>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:09:14.696 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90a43d8760>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90a44ff550>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u5e7f\\u897f\\u878d\\u5b89\\uff1a\\u9632\\u6c5b\\u6f14\\u7ec3\\u5907\\u6c5b\\u671f", "page": 4, "limit"...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a43d8760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u5e7f\\u897f\\u878d\\u5b89\\uff1a\\u9632\\u6c5b\\u6f14\\u7ec3\\u5907\\u6c5b\\u671f", "page": 4, "limit": 10, "ha...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f90a43d8760>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u5e7f\\u897f\\u878d\\u5b89\\uff1a\\u9632\\u6c5b\\u6f14\\u7ec3\\u5907\\u6c5b\\u671f", "page": 4, "limit": 10, "ha...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a43d8760>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u5e7f\\u897f\\u878d\\u5b89\\uff1a\\u9632\\u6c5b\\u6f14\\u7ec3\\u5907\\u6c5b\\u671f", "page": 4, "limit": 10, "ha...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a43d8760>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u5e7f\\u897f\\u878d\\u5b89\\uff1a\\u9632\\u6c5b\\u6f14\\u7ec3\\u5907\\u6c5b\\u671f", "page": 4, "limit": 10, "ha...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a43d8760>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a43d8760>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a43d8760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f90a43d8760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f90a43d8760>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90a44ff550>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90a43d8760>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90a44ff550>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90a43d8760>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-600, started daemon 140255017453312)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-600, started daemon 140255017453312)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-600, started daemon 140255017453312)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-600, started daemon 140255017453312)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-600, started daemon 140255017453312)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f90c434b880>
    │    │                                │              │         └ '广西融安：防汛演练备汛期'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f90c434b880>
               │    │                        │         └ '广西融安：防汛演练备汛期'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f914820e7c0>
        │          │    │       │                                  │        │           └ '广西融安：防汛演练备汛期'
        │          │    │       │                                  │        └ <string.Template object at 0x7f91042d7f40>
        │          │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
        │          │    │       └ '人民网'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
        └ <GET http://sc.people.com.cn/n2/2022/0429/c379469-35248710.html>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '广西融安：防汛演练备汛期', 'page': 4, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType':...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f91042d7f40>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '广西融安：防汛演练备汛期', 'page': 4, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType':...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '广西融安：防汛演练备汛期', 'page': 4, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True,...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f90c40f9340>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f90c40f9340>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f91245ff2b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90a43d8760>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:09:14.752 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91240c3070>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91600ffdc0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u975e\\u6d32\\u6781\\u7aef\\u7ec4\\u7ec7\\u6b66\\u5668\\u6765\\u6e90\\u5f15\\u5173\\u6ce8", "page": 1, ...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f91240c3070>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u975e\\u6d32\\u6781\\u7aef\\u7ec4\\u7ec7\\u6b66\\u5668\\u6765\\u6e90\\u5f15\\u5173\\u6ce8", "page": 1, "limit": ...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f91240c3070>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u975e\\u6d32\\u6781\\u7aef\\u7ec4\\u7ec7\\u6b66\\u5668\\u6765\\u6e90\\u5f15\\u5173\\u6ce8", "page": 1, "limit": ...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f91240c3070>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u975e\\u6d32\\u6781\\u7aef\\u7ec4\\u7ec7\\u6b66\\u5668\\u6765\\u6e90\\u5f15\\u5173\\u6ce8", "page": 1, "limit": ...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f91240c3070>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u975e\\u6d32\\u6781\\u7aef\\u7ec4\\u7ec7\\u6b66\\u5668\\u6765\\u6e90\\u5f15\\u5173\\u6ce8", "page": 1, "limit": ...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f91240c3070>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f91240c3070>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f91240c3070>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f91240c3070>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f91240c3070>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91600ffdc0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91240c3070>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91600ffdc0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91240c3070>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-330, started daemon 140257123104512)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-330, started daemon 140257123104512)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-330, started daemon 140257123104512)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-330, started daemon 140257123104512)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-330, started daemon 140257123104512)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9148138df0>
    │    │                                │              │         └ '非洲极端组织武器来源引关注'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9148138df0>
               │    │                        │         └ '非洲极端组织武器来源引关注'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f91486bb070>
                   │    │       │                                  │        │           └ '非洲极端组织武器来源引关注'
                   │    │       │                                  │        └ <string.Template object at 0x7f91485e9460>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '非洲极端组织武器来源引关注', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType'...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f91485e9460>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '非洲极端组织武器来源引关注', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType'...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '非洲极端组织武器来源引关注', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f916003d2b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f916003d2b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f90a475cdf0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91240c3070>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:09:14.836 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91242004f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90e40bb5b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242004f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f91242004f0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242004f0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242004f0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u534e\\u5357\\u6709\\u6301\\u7eed\\u6027\\u5f3a\\u964d\\u96e8 \\u591a\\u5730\\u6c14\\u8c61\\u90e8\\u95e8\\u5f3a\...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242004f0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242004f0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242004f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f91242004f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f91242004f0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90e40bb5b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91242004f0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90e40bb5b0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91242004f0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-326, started daemon 140257114711808)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-326, started daemon 140257114711808)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-326, started daemon 140257114711808)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-326, started daemon 140257114711808)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-326, started daemon 140257114711808)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f91603530d0>
    │    │                                │              │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f91603530d0>
               │    │                        │         └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f91486acc10>
        │          │    │       │                                  │        │           └ '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨'
        │          │    │       │                                  │        └ <string.Template object at 0x7f90e41ce310>
        │          │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
        │          │    │       └ '人民网'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
        └ <GET http://env.people.com.cn/n1/2022/0511/c1010-32418936.html>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 2, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f90e41ce310>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 2, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'ty...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '华南有持续性强降雨 多地气象部门强化应急联动全力防范应对强降雨', 'page': 2, 'limit': 10, 'hasTitle': True, 'hasContent': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f90c4481df0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f90c4481df0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f90e4762640>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91242004f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:09:15.098 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90a45dd460>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91245295b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u57c3\\u53ca\\u5b89\\u5168\\u90e8\\u961f\\u6253\\u6b7b14\\u540d\\u6050\\u6016\\u5206\\u5b50", "page": 5...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a45dd460>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u57c3\\u53ca\\u5b89\\u5168\\u90e8\\u961f\\u6253\\u6b7b14\\u540d\\u6050\\u6016\\u5206\\u5b50", "page": 5, "limit"...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f90a45dd460>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u57c3\\u53ca\\u5b89\\u5168\\u90e8\\u961f\\u6253\\u6b7b14\\u540d\\u6050\\u6016\\u5206\\u5b50", "page": 5, "limit"...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a45dd460>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u57c3\\u53ca\\u5b89\\u5168\\u90e8\\u961f\\u6253\\u6b7b14\\u540d\\u6050\\u6016\\u5206\\u5b50", "page": 5, "limit"...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a45dd460>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u57c3\\u53ca\\u5b89\\u5168\\u90e8\\u961f\\u6253\\u6b7b14\\u540d\\u6050\\u6016\\u5206\\u5b50", "page": 5, "limit"...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a45dd460>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a45dd460>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a45dd460>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f90a45dd460>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f90a45dd460>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91245295b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90a45dd460>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91245295b0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90a45dd460>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-381, started daemon 140256577840896)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-381, started daemon 140256577840896)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-381, started daemon 140256577840896)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-381, started daemon 140256577840896)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-381, started daemon 140256577840896)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f91240eaeb0>
    │    │                                │              │         └ '埃及安全部队打死14名恐怖分子'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f91240eaeb0>
               │    │                        │         └ '埃及安全部队打死14名恐怖分子'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f916015f610>
        │          │    │       │                                  │        │           └ '埃及安全部队打死14名恐怖分子'
        │          │    │       │                                  │        └ <string.Template object at 0x7f90c4558c10>
        │          │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
        │          │    │       └ '人民网'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
        └ <GET http://world.people.com.cn/n1/2022/0512/c1002-32420031.html>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '埃及安全部队打死14名恐怖分子', 'page': 5, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortTyp...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f90c4558c10>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '埃及安全部队打死14名恐怖分子', 'page': 5, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortTyp...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '埃及安全部队打死14名恐怖分子', 'page': 5, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tr...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f91042bfb20>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f91042bfb20>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f90a478c8b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90a45dd460>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:09:15.270 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90c412b910>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9124653a30>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u65b0\\u534e\\u5168\\u5a92+\\u4e28\\u4ee5\\u9752\\u6625\\u7684\\u540d\\u4e49 \\u81f4\\u656c\\u96c4\\u5b...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c412b910>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u65b0\\u534e\\u5168\\u5a92+\\u4e28\\u4ee5\\u9752\\u6625\\u7684\\u540d\\u4e49 \\u81f4\\u656c\\u96c4\\u5b89", "pag...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f90c412b910>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u65b0\\u534e\\u5168\\u5a92+\\u4e28\\u4ee5\\u9752\\u6625\\u7684\\u540d\\u4e49 \\u81f4\\u656c\\u96c4\\u5b89", "pag...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c412b910>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u65b0\\u534e\\u5168\\u5a92+\\u4e28\\u4ee5\\u9752\\u6625\\u7684\\u540d\\u4e49 \\u81f4\\u656c\\u96c4\\u5b89", "pag...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c412b910>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u65b0\\u534e\\u5168\\u5a92+\\u4e28\\u4ee5\\u9752\\u6625\\u7684\\u540d\\u4e49 \\u81f4\\u656c\\u96c4\\u5b89", "pag...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c412b910>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c412b910>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c412b910>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f90c412b910>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f90c412b910>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9124653a30>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90c412b910>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9124653a30>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90c412b910>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-212, started daemon 140258725324544)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-212, started daemon 140258725324544)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-212, started daemon 140258725324544)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-212, started daemon 140258725324544)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-212, started daemon 140258725324544)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f914827aee0>
    │    │                                │              │         └ '新华全媒+丨以青春的名义 致敬雄安'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f914827aee0>
               │    │                        │         └ '新华全媒+丨以青春的名义 致敬雄安'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f9253ea75e0>
        │          │    │       │                                  │        │           └ '新华全媒+丨以青春的名义 致敬雄安'
        │          │    │       │                                  │        └ <string.Template object at 0x7f91600ff940>
        │          │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
        │          │    │       └ '人民网'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
        └ <GET http://sn.people.com.cn/n2/2022/0501/c186331-35250384.html>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '新华全媒+丨以青春的名义 致敬雄安', 'page': 3, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortT...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f91600ff940>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '新华全媒+丨以青春的名义 致敬雄安', 'page': 3, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortT...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '新华全媒+丨以青春的名义 致敬雄安', 'page': 3, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': ...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f90a4721520>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f90a4721520>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f90c4634b20>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90c412b910>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:09:15.279 | ERROR    | monitor.searchSpiders.qinagguoLT:get_request_from_keyword:27 - E 强国论坛错误HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Max retries exceeded with url: /board/1.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f916063d340>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.223', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90e412a3a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': None, 'headers': {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0....
    │    │       │       └ '/board/1.html'
    │    │       └ 'GET'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f916063d340>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36', 'A...
          │               │             │       │         └ None
          │               │             │       └ '/board/1.html'
          │               │             └ 'GET'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f916063d340>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36', 'A...
    │    │             │       │    └ None
    │    │             │       └ '/board/1.html'
    │    │             └ 'GET'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f916063d340>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ None
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f916063d340>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ None
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f916063d340>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'GET /board/1.html HTTP/1.1\r\nHost: bbs1.people.com.cn\r\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (K...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f916063d340>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f916063d340>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f916063d340>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f916063d340>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90e412a3a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f916063d340>: Failed to establish a new connection: [Errn...
          │             │      └ '/board/1.html'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90e412a3a0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Max retries exceeded with url: /board/1.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f916063d340>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-496, started daemon 140255202092800)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-496, started daemon 140255202092800)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-496, started daemon 140255202092800)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-496, started daemon 140255202092800)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-496, started daemon 140255202092800)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f91040c6d90>
    │    │                                │              │         └ '土耳其通货膨胀率持续高位运行'
    │    │                                │              └ '强国论坛'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f91040c6d90>
               │    │                        │         └ '土耳其通货膨胀率持续高位运行'
               │    │                        └ '强国论坛'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f90e40649d0>
                   │    │       │                                  │        │           └ '土耳其通货膨胀率持续高位运行'
                   │    │       │                                  │        └ <string.Template object at 0x7f90e4064640>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (X11;...
                   │    │       └ '强国论坛'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qinagguoLT.py", line 18, in get_request_from_keyword
    response = requests.get(search_url.substitute(), headers=headers)
               │        │   │          │                     └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (X11;...
               │        │   │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │   └ <string.Template object at 0x7f90e4064640>
               │        └ <function get at 0x7f92583e71f0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozil...
           │              │           └ None
           │              └ 'http://bbs1.people.com.cn/board/1.html'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'Use...
           │       │              │           └ 'http://bbs1.people.com.cn/board/1.html'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f914815cca0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f914815cca0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f90a40ffa00>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Max retries exceeded with url: /board/1.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f916063d340>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:09:15.316 | ERROR    | monitor.searchSpiders.qinagguoLT:get_request_from_keyword:27 - E 强国论坛错误HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Max retries exceeded with url: /board/1.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.223', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9160098b80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': None, 'headers': {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0....
    │    │       │       └ '/board/1.html'
    │    │       └ 'GET'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36', 'A...
          │               │             │       │         └ None
          │               │             │       └ '/board/1.html'
          │               │             └ 'GET'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36', 'A...
    │    │             │       │    └ None
    │    │             │       └ '/board/1.html'
    │    │             └ 'GET'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ None
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ None
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'GET /board/1.html HTTP/1.1\r\nHost: bbs1.people.com.cn\r\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (K...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9160098b80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>: Failed to establish a new connection: [Errn...
          │             │      └ '/board/1.html'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9160098b80>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Max retries exceeded with url: /board/1.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-468, started daemon 140255462135552)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-468, started daemon 140255462135552)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-468, started daemon 140255462135552)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-468, started daemon 140255462135552)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-468, started daemon 140255462135552)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f91482d3280>
    │    │                                │              │         └ '土耳其通货膨胀率持续高位运行'
    │    │                                │              └ '强国论坛'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f91482d3280>
               │    │                        │         └ '土耳其通货膨胀率持续高位运行'
               │    │                        └ '强国论坛'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9148495550>
                   │    │       │                                  │        │           └ '土耳其通货膨胀率持续高位运行'
                   │    │       │                                  │        └ <string.Template object at 0x7f90a42dd8b0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (X11;...
                   │    │       └ '强国论坛'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qinagguoLT.py", line 18, in get_request_from_keyword
    response = requests.get(search_url.substitute(), headers=headers)
               │        │   │          │                     └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (X11;...
               │        │   │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │   └ <string.Template object at 0x7f90a42dd8b0>
               │        └ <function get at 0x7f92583e71f0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozil...
           │              │           └ None
           │              └ 'http://bbs1.people.com.cn/board/1.html'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'Use...
           │       │              │           └ 'http://bbs1.people.com.cn/board/1.html'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f90e47ae9a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f90e47ae9a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9124478400>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Max retries exceeded with url: /board/1.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90c471d6a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:09:15.427 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90c422d430>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90e4783ca0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "pag...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c422d430>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 3, "l...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f90c422d430>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 3, "l...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c422d430>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 3, "l...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c422d430>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 3, "l...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c422d430>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c422d430>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f90c422d430>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f90c422d430>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f90c422d430>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90e4783ca0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90c422d430>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90e4783ca0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90c422d430>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-491, started daemon 140255210485504)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-491, started daemon 140255210485504)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-491, started daemon 140255210485504)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-491, started daemon 140255210485504)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-491, started daemon 140255210485504)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f90e4308820>
    │    │                                │              │         └ '土耳其通货膨胀率持续高位运行'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f90e4308820>
               │    │                        │         └ '土耳其通货膨胀率持续高位运行'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f90e40b00a0>
        │          │    │       │                                  │        │           └ '土耳其通货膨胀率持续高位运行'
        │          │    │       │                                  │        └ <string.Template object at 0x7f91042cddf0>
        │          │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
        │          │    │       └ '人民网'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
        └ <GET http://bj.people.com.cn/n2/2022/0506/c14540-35256097.html>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '土耳其通货膨胀率持续高位运行', 'page': 3, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f91042cddf0>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '土耳其通货膨胀率持续高位运行', 'page': 3, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '土耳其通货膨胀率持续高位运行', 'page': 3, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f90c4749340>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f90c4749340>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f90e4589f70>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90c422d430>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:09:15.481 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f916063d7f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90e4130eb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u79d1\\u666e\\uff1a\\u5965\\u5bc6\\u514b\\u620e\\u6bd2\\u682a\\u6301\\u7eed\\u53d8\\u5f02\\u4f1a\\u6709...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f916063d7f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u79d1\\u666e\\uff1a\\u5965\\u5bc6\\u514b\\u620e\\u6bd2\\u682a\\u6301\\u7eed\\u53d8\\u5f02\\u4f1a\\u6709\\u591a\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f916063d7f0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u79d1\\u666e\\uff1a\\u5965\\u5bc6\\u514b\\u620e\\u6bd2\\u682a\\u6301\\u7eed\\u53d8\\u5f02\\u4f1a\\u6709\\u591a\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f916063d7f0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u79d1\\u666e\\uff1a\\u5965\\u5bc6\\u514b\\u620e\\u6bd2\\u682a\\u6301\\u7eed\\u53d8\\u5f02\\u4f1a\\u6709\\u591a\\...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f916063d7f0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u79d1\\u666e\\uff1a\\u5965\\u5bc6\\u514b\\u620e\\u6bd2\\u682a\\u6301\\u7eed\\u53d8\\u5f02\\u4f1a\\u6709\\u591a\\...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f916063d7f0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f916063d7f0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f916063d7f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f916063d7f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f916063d7f0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90e4130eb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f916063d7f0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f90e4130eb0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f916063d7f0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-78, started daemon 140261376108288)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-78, started daemon 140261376108288)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-78, started daemon 140261376108288)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-78, started daemon 140261376108288)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-78, started daemon 140261376108288)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f91601652e0>
    │    │                                │              │         └ '科普：奥密克戎毒株持续变异会有多大影响'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f91601652e0>
               │    │                        │         └ '科普：奥密克戎毒株持续变异会有多大影响'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f90c41e1b80>
        │          │    │       │                                  │        │           └ '科普：奥密克戎毒株持续变异会有多大影响'
        │          │    │       │                                  │        └ <string.Template object at 0x7f90a4576e80>
        │          │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
        │          │    │       └ '人民网'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
        └ <GET http://world.people.com.cn/n1/2022/0505/c1002-32414745.html>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '科普：奥密克戎毒株持续变异会有多大影响', 'page': 2, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sor...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f90a4576e80>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '科普：奥密克戎毒株持续变异会有多大影响', 'page': 2, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sor...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '科普：奥密克戎毒株持续变异会有多大影响', 'page': 2, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy'...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f90c46b1100>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f90c46b1100>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f90c42a06a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f916063d7f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:09:15.478 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90a45194f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91603e3940>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u975e\\u6d32\\u6781\\u7aef\\u7ec4\\u7ec7\\u6b66\\u5668\\u6765\\u6e90\\u5f15\\u5173\\u6ce8", "page": 2, ...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a45194f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u975e\\u6d32\\u6781\\u7aef\\u7ec4\\u7ec7\\u6b66\\u5668\\u6765\\u6e90\\u5f15\\u5173\\u6ce8", "page": 2, "limit": ...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f90a45194f0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u975e\\u6d32\\u6781\\u7aef\\u7ec4\\u7ec7\\u6b66\\u5668\\u6765\\u6e90\\u5f15\\u5173\\u6ce8", "page": 2, "limit": ...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a45194f0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u975e\\u6d32\\u6781\\u7aef\\u7ec4\\u7ec7\\u6b66\\u5668\\u6765\\u6e90\\u5f15\\u5173\\u6ce8", "page": 2, "limit": ...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a45194f0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u975e\\u6d32\\u6781\\u7aef\\u7ec4\\u7ec7\\u6b66\\u5668\\u6765\\u6e90\\u5f15\\u5173\\u6ce8", "page": 2, "limit": ...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a45194f0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a45194f0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f90a45194f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f90a45194f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f90a45194f0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91603e3940>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90a45194f0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91603e3940>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90a45194f0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-302, started daemon 140257634797312)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-302, started daemon 140257634797312)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-302, started daemon 140257634797312)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-302, started daemon 140257634797312)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-302, started daemon 140257634797312)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f91601f6be0>
    │    │                                │              │         └ '非洲极端组织武器来源引关注'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f91601f6be0>
               │    │                        │         └ '非洲极端组织武器来源引关注'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f90c471db80>
        │          │    │       │                                  │        │           └ '非洲极端组织武器来源引关注'
        │          │    │       │                                  │        └ <string.Template object at 0x7f9160199a90>
        │          │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
        │          │    │       └ '人民网'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
        └ <GET http://military.people.com.cn/n1/2022/0506/c1011-32415584.html>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '非洲极端组织武器来源引关注', 'page': 2, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType'...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f9160199a90>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '非洲极端组织武器来源引关注', 'page': 2, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType'...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '非洲极端组织武器来源引关注', 'page': 2, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f90a4443250>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f90a4443250>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f90c4697e20>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f90a45194f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 16:09:15.649 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f910426a760>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91247e76d0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u5e7f\\u897f\\u878d\\u5b89\\uff1a\\u9632\\u6c5b\\u6f14\\u7ec3\\u5907\\u6c5b\\u671f", "page": 3, "limit"...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f910426a760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u5e7f\\u897f\\u878d\\u5b89\\uff1a\\u9632\\u6c5b\\u6f14\\u7ec3\\u5907\\u6c5b\\u671f", "page": 3, "limit": 10, "ha...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f910426a760>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u5e7f\\u897f\\u878d\\u5b89\\uff1a\\u9632\\u6c5b\\u6f14\\u7ec3\\u5907\\u6c5b\\u671f", "page": 3, "limit": 10, "ha...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f910426a760>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u5e7f\\u897f\\u878d\\u5b89\\uff1a\\u9632\\u6c5b\\u6f14\\u7ec3\\u5907\\u6c5b\\u671f", "page": 3, "limit": 10, "ha...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f910426a760>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u5e7f\\u897f\\u878d\\u5b89\\uff1a\\u9632\\u6c5b\\u6f14\\u7ec3\\u5907\\u6c5b\\u671f", "page": 3, "limit": 10, "ha...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f910426a760>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f910426a760>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f910426a760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f910426a760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f910426a760>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91247e76d0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f910426a760>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91247e76d0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f910426a760>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-614, started daemon 140255000667904)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-614, started daemon 140255000667904)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-614, started daemon 140255000667904)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-614, started daemon 140255000667904)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-614, started daemon 140255000667904)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f91244a6ac0>
    │    │                                │              │         └ '广西融安：防汛演练备汛期'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f91244a6ac0>
               │    │                        │         └ '广西融安：防汛演练备汛期'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f90e43975b0>
        │          │    │       │                                  │        │           └ '广西融安：防汛演练备汛期'
        │          │    │       │                                  │        └ <string.Template object at 0x7f90c433f220>
        │          │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
        │          │    │       └ '人民网'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
        └ <GET http://henan.people.com.cn/n2/2022/0501/c351638-35250864.html>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '广西融安：防汛演练备汛期', 'page': 3, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType':...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f90c433f220>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '广西融安：防汛演练备汛期', 'page': 3, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType':...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '广西融安：防汛演练备汛期', 'page': 3, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True,...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f90e42fa850>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f90e42fa850>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f90c40c6fa0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f910426a760>: Failed to establish a new connection: [Errno 111] Connection refused'))
