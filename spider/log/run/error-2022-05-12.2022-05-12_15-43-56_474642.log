2022-05-12 15:43:56.211 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9124518520>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9253e8e4c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u4e1c\\u90e8\\u6218\\u533a\\u7ec4\\u7ec7\\u5175\\u529b\\u5728\\u53f0\\u5c9b\\u4ee5\\u4e1c\\u548c\\u897f...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f9124518520>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u4e1c\\u90e8\\u6218\\u533a\\u7ec4\\u7ec7\\u5175\\u529b\\u5728\\u53f0\\u5c9b\\u4ee5\\u4e1c\\u548c\\u897f\\u5357\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f9124518520>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u4e1c\\u90e8\\u6218\\u533a\\u7ec4\\u7ec7\\u5175\\u529b\\u5728\\u53f0\\u5c9b\\u4ee5\\u4e1c\\u548c\\u897f\\u5357\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f9124518520>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u4e1c\\u90e8\\u6218\\u533a\\u7ec4\\u7ec7\\u5175\\u529b\\u5728\\u53f0\\u5c9b\\u4ee5\\u4e1c\\u548c\\u897f\\u5357\\...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f9124518520>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u4e1c\\u90e8\\u6218\\u533a\\u7ec4\\u7ec7\\u5175\\u529b\\u5728\\u53f0\\u5c9b\\u4ee5\\u4e1c\\u548c\\u897f\\u5357\\...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f9124518520>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f9124518520>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f9124518520>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f9124518520>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9124518520>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9253e8e4c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9124518520>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9253e8e4c0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9124518520>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-65, started daemon 140261392893696)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-65, started daemon 140261392893696)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-65, started daemon 140261392893696)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-65, started daemon 140261392893696)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-65, started daemon 140261392893696)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f91601075e0>
    │    │                                │              │         └ '东部战区组织兵力在台岛以东和西南海空域进行实兵演练'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f91601075e0>
               │    │                        │         └ '东部战区组织兵力在台岛以东和西南海空域进行实兵演练'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9160322340>
                   │    │       │                                  │        │           └ '东部战区组织兵力在台岛以东和西南海空域进行实兵演练'
                   │    │       │                                  │        └ <string.Template object at 0x7f9160322250>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '东部战区组织兵力在台岛以东和西南海空域进行实兵演练', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f9160322250>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '东部战区组织兵力在台岛以东和西南海空域进行实兵演练', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '东部战区组织兵力在台岛以东和西南海空域进行实兵演练', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'is...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f91247dce80>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f91247dce80>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f91480e01c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9124518520>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:43:56.476 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9160199760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u5e94\\u5bf9\\u6c14\\u5019\\u53d8\\u5316\\uff0c\\u4e2d\\u56fd\\u91cd\\u4fe1\\u5b88\\u8bfa\\uff08\\u56fd...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u5e94\\u5bf9\\u6c14\\u5019\\u53d8\\u5316\\uff0c\\u4e2d\\u56fd\\u91cd\\u4fe1\\u5b88\\u8bfa\\uff08\\u56fd\\u9645\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u5e94\\u5bf9\\u6c14\\u5019\\u53d8\\u5316\\uff0c\\u4e2d\\u56fd\\u91cd\\u4fe1\\u5b88\\u8bfa\\uff08\\u56fd\\u9645\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u5e94\\u5bf9\\u6c14\\u5019\\u53d8\\u5316\\uff0c\\u4e2d\\u56fd\\u91cd\\u4fe1\\u5b88\\u8bfa\\uff08\\u56fd\\u9645\\...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u5e94\\u5bf9\\u6c14\\u5019\\u53d8\\u5316\\uff0c\\u4e2d\\u56fd\\u91cd\\u4fe1\\u5b88\\u8bfa\\uff08\\u56fd\\u9645\\...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9160199760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9160199760>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-42, started daemon 140261980088064)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-42, started daemon 140261980088064)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-42, started daemon 140261980088064)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-42, started daemon 140261980088064)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-42, started daemon 140261980088064)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f91603ec070>
    │    │                                │              │         └ '应对气候变化，中国重信守诺（国际论坛）'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f91603ec070>
               │    │                        │         └ '应对气候变化，中国重信守诺（国际论坛）'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9148777c70>
                   │    │       │                                  │        │           └ '应对气候变化，中国重信守诺（国际论坛）'
                   │    │       │                                  │        └ <string.Template object at 0x7f9148565e50>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '应对气候变化，中国重信守诺（国际论坛）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sor...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f9148565e50>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '应对气候变化，中国重信守诺（国际论坛）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sor...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '应对气候变化，中国重信守诺（国际论坛）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy'...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f9148507d00>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f9148507d00>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f91487778b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91483ab0d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:43:56.577 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91242cc130>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9160251c70>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u5317\\u7ea6\\u79d8\\u4e66\\u957f\\u65b0\\u51a0\\u75c5\\u6bd2\\u68c0\\u6d4b\\u7ed3\\u679c\\u5448\\u9633...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242cc130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u5317\\u7ea6\\u79d8\\u4e66\\u957f\\u65b0\\u51a0\\u75c5\\u6bd2\\u68c0\\u6d4b\\u7ed3\\u679c\\u5448\\u9633\\u6027",...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f91242cc130>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u5317\\u7ea6\\u79d8\\u4e66\\u957f\\u65b0\\u51a0\\u75c5\\u6bd2\\u68c0\\u6d4b\\u7ed3\\u679c\\u5448\\u9633\\u6027",...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242cc130>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u5317\\u7ea6\\u79d8\\u4e66\\u957f\\u65b0\\u51a0\\u75c5\\u6bd2\\u68c0\\u6d4b\\u7ed3\\u679c\\u5448\\u9633\\u6027",...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242cc130>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u5317\\u7ea6\\u79d8\\u4e66\\u957f\\u65b0\\u51a0\\u75c5\\u6bd2\\u68c0\\u6d4b\\u7ed3\\u679c\\u5448\\u9633\\u6027",...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242cc130>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242cc130>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242cc130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f91242cc130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f91242cc130>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9160251c70>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91242cc130>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9160251c70>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91242cc130>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-120, started daemon 140260327544576)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-120, started daemon 140260327544576)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-120, started daemon 140260327544576)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-120, started daemon 140260327544576)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-120, started daemon 140260327544576)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9160073700>
    │    │                                │              │         └ '北约秘书长新冠病毒检测结果呈阳性'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9160073700>
               │    │                        │         └ '北约秘书长新冠病毒检测结果呈阳性'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f916012dac0>
                   │    │       │                                  │        │           └ '北约秘书长新冠病毒检测结果呈阳性'
                   │    │       │                                  │        └ <string.Template object at 0x7f91605c5190>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '北约秘书长新冠病毒检测结果呈阳性', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortTy...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f91605c5190>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '北约秘书长新冠病毒检测结果呈阳性', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortTy...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '北约秘书长新冠病毒检测结果呈阳性', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': T...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f9253eb64f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f9253eb64f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f91480e08b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91242cc130>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:43:57.886 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91242cc070>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91246079a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "pag...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242cc070>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f91242cc070>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242cc070>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242cc070>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242cc070>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242cc070>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f91242cc070>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f91242cc070>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f91242cc070>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91246079a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91242cc070>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91246079a0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91242cc070>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-170, started daemon 140259773888256)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-170, started daemon 140259773888256)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-170, started daemon 140259773888256)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-170, started daemon 140259773888256)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-170, started daemon 140259773888256)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9148581f40>
    │    │                                │              │         └ '土耳其通货膨胀率持续高位运行'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9148581f40>
               │    │                        │         └ '土耳其通货膨胀率持续高位运行'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f916040a610>
                   │    │       │                                  │        │           └ '土耳其通货膨胀率持续高位运行'
                   │    │       │                                  │        └ <string.Template object at 0x7f9148071d90>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '土耳其通货膨胀率持续高位运行', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f9148071d90>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '土耳其通货膨胀率持续高位运行', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '土耳其通货膨胀率持续高位运行', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f91603945e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f91603945e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f91600e84f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91242cc070>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:43:58.056 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f912428d910>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9253e0a610>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u5e94\\u5bf9\\u6c14\\u5019\\u53d8\\u5316\\uff0c\\u4e2d\\u56fd\\u91cd\\u4fe1\\u5b88\\u8bfa\\uff08\\u56fd...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f912428d910>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u5e94\\u5bf9\\u6c14\\u5019\\u53d8\\u5316\\uff0c\\u4e2d\\u56fd\\u91cd\\u4fe1\\u5b88\\u8bfa\\uff08\\u56fd\\u9645\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f912428d910>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u5e94\\u5bf9\\u6c14\\u5019\\u53d8\\u5316\\uff0c\\u4e2d\\u56fd\\u91cd\\u4fe1\\u5b88\\u8bfa\\uff08\\u56fd\\u9645\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f912428d910>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u5e94\\u5bf9\\u6c14\\u5019\\u53d8\\u5316\\uff0c\\u4e2d\\u56fd\\u91cd\\u4fe1\\u5b88\\u8bfa\\uff08\\u56fd\\u9645\\...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f912428d910>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u5e94\\u5bf9\\u6c14\\u5019\\u53d8\\u5316\\uff0c\\u4e2d\\u56fd\\u91cd\\u4fe1\\u5b88\\u8bfa\\uff08\\u56fd\\u9645\\...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f912428d910>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f912428d910>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f912428d910>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f912428d910>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f912428d910>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9253e0a610>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f912428d910>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9253e0a610>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f912428d910>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-22, started daemon 140261996873472)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-22, started daemon 140261996873472)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-22, started daemon 140261996873472)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-22, started daemon 140261996873472)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-22, started daemon 140261996873472)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f91603edbe0>
    │    │                                │              │         └ '应对气候变化，中国重信守诺（国际论坛）'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f91603edbe0>
               │    │                        │         └ '应对气候变化，中国重信守诺（国际论坛）'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9253fe8700>
                   │    │       │                                  │        │           └ '应对气候变化，中国重信守诺（国际论坛）'
                   │    │       │                                  │        └ <string.Template object at 0x7f9160394760>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '应对气候变化，中国重信守诺（国际论坛）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sor...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f9160394760>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '应对气候变化，中国重信守诺（国际论坛）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sor...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '应对气候变化，中国重信守诺（国际论坛）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy'...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f9148743af0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f9148743af0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f91600e6e20>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f912428d910>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:43:59.408 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f914823d040>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91247aeb80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "pag...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f914823d040>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f914823d040>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f914823d040>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f914823d040>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f914823d040>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f914823d040>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f914823d040>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f914823d040>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f914823d040>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91247aeb80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f914823d040>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91247aeb80>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f914823d040>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-134, started daemon 140260310759168)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-134, started daemon 140260310759168)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-134, started daemon 140260310759168)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-134, started daemon 140260310759168)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-134, started daemon 140260310759168)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f914866fd00>
    │    │                                │              │         └ '土耳其通货膨胀率持续高位运行'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f914866fd00>
               │    │                        │         └ '土耳其通货膨胀率持续高位运行'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f914824f5e0>
                   │    │       │                                  │        │           └ '土耳其通货膨胀率持续高位运行'
                   │    │       │                                  │        └ <string.Template object at 0x7f91242ccee0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '土耳其通货膨胀率持续高位运行', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f91242ccee0>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '土耳其通货膨胀率持续高位运行', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '土耳其通货膨胀率持续高位运行', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f91485ebb80>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f91485ebb80>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f914823d0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f914823d040>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:43:59.424 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91247dce80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91486bb520>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitl...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f91247dce80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f91247dce80>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f91247dce80>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f91247dce80>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f91247dce80>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f91247dce80>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f91247dce80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f91247dce80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f91247dce80>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91486bb520>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91247dce80>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91486bb520>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91247dce80>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-235, started daemon 140258683361024)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-235, started daemon 140258683361024)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-235, started daemon 140258683361024)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-235, started daemon 140258683361024)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-235, started daemon 140258683361024)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9160425d00>
    │    │                                │              │         └ '俄罗斯举行胜利日阅兵'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9160425d00>
               │    │                        │         └ '俄罗斯举行胜利日阅兵'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f91242cc850>
                   │    │       │                                  │        │           └ '俄罗斯举行胜利日阅兵'
                   │    │       │                                  │        └ <string.Template object at 0x7f91242cc8b0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '俄罗斯举行胜利日阅兵', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': 2...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f91242cc8b0>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '俄罗斯举行胜利日阅兵', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': 2...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '俄罗斯举行胜利日阅兵', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, '...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f9148347e50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f9148347e50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f91485eba90>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91247dce80>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:44:00.192 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91487f0490>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91601f63d0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "pag...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f91487f0490>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f91487f0490>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f91487f0490>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f91487f0490>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f91487f0490>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f91487f0490>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f91487f0490>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f91487f0490>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f91487f0490>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91601f63d0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91487f0490>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f91601f63d0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91487f0490>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-180, started daemon 140259270588160)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-180, started daemon 140259270588160)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-180, started daemon 140259270588160)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-180, started daemon 140259270588160)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-180, started daemon 140259270588160)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f916040aa90>
    │    │                                │              │         └ '土耳其通货膨胀率持续高位运行'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f916040aa90>
               │    │                        │         └ '土耳其通货膨胀率持续高位运行'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f91600de730>
                   │    │       │                                  │        │           └ '土耳其通货膨胀率持续高位运行'
                   │    │       │                                  │        └ <string.Template object at 0x7f916063de50>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '土耳其通货膨胀率持续高位运行', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f916063de50>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '土耳其通货膨胀率持续高位运行', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '土耳其通货膨胀率持续高位运行', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f91600de430>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f91600de430>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9253e0aa90>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91487f0490>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:44:00.694 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91485035e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9160619a60>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitl...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485035e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f91485035e0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485035e0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485035e0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485035e0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485035e0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485035e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f91485035e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f91485035e0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9160619a60>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91485035e0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9160619a60>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91485035e0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-212, started daemon 140258725324544)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-212, started daemon 140258725324544)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-212, started daemon 140258725324544)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-212, started daemon 140258725324544)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-212, started daemon 140258725324544)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f914827aee0>
    │    │                                │              │         └ '俄罗斯举行胜利日阅兵'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f914827aee0>
               │    │                        │         └ '俄罗斯举行胜利日阅兵'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f91485909a0>
                   │    │       │                                  │        │           └ '俄罗斯举行胜利日阅兵'
                   │    │       │                                  │        └ <string.Template object at 0x7f916040a910>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '俄罗斯举行胜利日阅兵', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': 2...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f916040a910>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '俄罗斯举行胜利日阅兵', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': 2...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '俄罗斯举行胜利日阅兵', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, '...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f914874e190>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f914874e190>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f914874e6d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91485035e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:44:03.985 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91485efeb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9124623580>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "pag...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485efeb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f91485efeb0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485efeb0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485efeb0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u571f\\u8033\\u5176\\u901a\\u8d27\\u81a8\\u80c0\\u7387\\u6301\\u7eed\\u9ad8\\u4f4d\\u8fd0\\u884c", "page": 1, "l...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485efeb0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485efeb0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485efeb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f91485efeb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f91485efeb0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9124623580>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91485efeb0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9124623580>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91485efeb0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-185, started daemon 140259262195456)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-185, started daemon 140259262195456)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-185, started daemon 140259262195456)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-185, started daemon 140259262195456)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-185, started daemon 140259262195456)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9148263820>
    │    │                                │              │         └ '土耳其通货膨胀率持续高位运行'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9148263820>
               │    │                        │         └ '土耳其通货膨胀率持续高位运行'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f91485039d0>
                   │    │       │                                  │        │           └ '土耳其通货膨胀率持续高位运行'
                   │    │       │                                  │        └ <string.Template object at 0x7f91481e2df0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '土耳其通货膨胀率持续高位运行', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f91481e2df0>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '土耳其通货膨胀率持续高位运行', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '土耳其通货膨胀率持续高位运行', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f9148539460>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f9148539460>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f91244a6df0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91485efeb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:44:03.983 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f912454dc10>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9253f5f670>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitl...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f912454dc10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f912454dc10>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f912454dc10>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f912454dc10>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f912454dc10>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f912454dc10>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f912454dc10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f912454dc10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f912454dc10>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9253f5f670>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f912454dc10>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9253f5f670>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f912454dc10>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-231, started daemon 140258700146432)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-231, started daemon 140258700146432)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-231, started daemon 140258700146432)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-231, started daemon 140258700146432)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-231, started daemon 140258700146432)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9148139100>
    │    │                                │              │         └ '俄罗斯举行胜利日阅兵'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9148139100>
               │    │                        │         └ '俄罗斯举行胜利日阅兵'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f914842b070>
                   │    │       │                                  │        │           └ '俄罗斯举行胜利日阅兵'
                   │    │       │                                  │        └ <string.Template object at 0x7f9148507ee0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '俄罗斯举行胜利日阅兵', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': 2...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f9148507ee0>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '俄罗斯举行胜利日阅兵', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': 2...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '俄罗斯举行胜利日阅兵', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, '...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f9148209340>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f9148209340>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f91245188e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f912454dc10>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:44:04.618 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f92585fd1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f92585c05e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9148138820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitl...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f92585b0f70>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f926be50280>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
    │    └ <function HTTPConnection.endheaders at 0x7f926be50160>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u4fc4\\u7f57\\u65af\\u4e3e\\u884c\\u80dc\\u5229\\u65e5\\u9605\\u5175", "page": 1, "limit": 10, "hasTitle": true,...
    │    └ <function HTTPConnection._send_output at 0x7f926beb7d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f926beb7b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f92585b0dc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f92585b0c10>
           └ <urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f92585c0820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9148138820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9258608b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9148138820>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f927a614a60>
    └ <Thread(Thread-221, started daemon 140258716931840)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f927a614790>
    └ <Thread(Thread-221, started daemon 140258716931840)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-221, started daemon 140258716931840)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-221, started daemon 140258716931840)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9162af4700>>
    └ <Thread(Thread-221, started daemon 140258716931840)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9162b00040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9162af4700>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f91628317f0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9148591b20>
    │    │                                │              │         └ '俄罗斯举行胜利日阅兵'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9162b000d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f925aaa8550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9148591b20>
               │    │                        │         └ '俄罗斯举行胜利日阅兵'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9162b001f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9148503a00>
                   │    │       │                                  │        │           └ '俄罗斯举行胜利日阅兵'
                   │    │       │                                  │        └ <string.Template object at 0x7f914821eeb0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f916270f220>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f916270f0d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '俄罗斯举行胜利日阅兵', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': 2...
               │        │    │          └ <function Template.substitute at 0x7f927a5fd0d0>
               │        │    └ <string.Template object at 0x7f914821eeb0>
               │        └ <function post at 0x7f92583e73a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '俄罗斯举行胜利日阅兵', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': 2...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9258455040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '俄罗斯举行胜利日阅兵', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, '...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f92583e6940>
           └ <requests.sessions.Session object at 0x7f9253f7e130>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f92583e6dc0>
           └ <requests.sessions.Session object at 0x7f9253f7e130>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f92583e6280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9124729280>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f91485e6bb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
