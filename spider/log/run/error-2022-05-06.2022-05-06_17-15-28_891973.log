2022-05-06 17:15:28.827 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fcb23698280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fcb236a6670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc86730f730>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u201c\\u7ee7\\u7eed\\u52a0\\u5927\\u5728\\u4e2d\\u56fd\\u7684\\u6295\\u8d44\\u201d\\uff08\\u89c1\\u8bc1...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fcb2364e040>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u201c\\u7ee7\\u7eed\\u52a0\\u5927\\u5728\\u4e2d\\u56fd\\u7684\\u6295\\u8d44\\u201d\\uff08\\u89c1\\u8bc1\\u00b7\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u201c\\u7ee7\\u7eed\\u52a0\\u5927\\u5728\\u4e2d\\u56fd\\u7684\\u6295\\u8d44\\u201d\\uff08\\u89c1\\u8bc1\\u00b7\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fcb38ef2280>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u201c\\u7ee7\\u7eed\\u52a0\\u5927\\u5728\\u4e2d\\u56fd\\u7684\\u6295\\u8d44\\u201d\\uff08\\u89c1\\u8bc1\\u00b7\\...
    │    └ <function HTTPConnection.endheaders at 0x7fcb38ef2160>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u201c\\u7ee7\\u7eed\\u52a0\\u5927\\u5728\\u4e2d\\u56fd\\u7684\\u6295\\u8d44\\u201d\\uff08\\u89c1\\u8bc1\\u00b7\\...
    │    └ <function HTTPConnection._send_output at 0x7fcb38f59d30>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fcb38f59b80>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fcb2364ce50>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fcb2364cca0>
           └ <urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fcb236a68b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc86730f730>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fcb236a2c10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc86730f730>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fcb496b6a60>
    └ <Thread(Thread-324, started daemon 140500881876736)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fcb496b6790>
    └ <Thread(Thread-324, started daemon 140500881876736)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-324, started daemon 140500881876736)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-324, started daemon 140500881876736)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>>
    └ <Thread(Thread-324, started daemon 140500881876736)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fca31ba7dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>
    └ <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fca318b4460>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fc9de7be940>
    │    │                                │              │         └ '“继续加大在中国的投资”（见证·中国机遇）'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fca31ba7e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fcb29b4a550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fc9de7be940>
               │    │                        │         └ '“继续加大在中国的投资”（见证·中国机遇）'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fca31ba7f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fc9fc4253a0>
                   │    │       │                                  │        │           └ '“继续加大在中国的投资”（见证·中国机遇）'
                   │    │       │                                  │        └ <string.Template object at 0x7fc86f3e2c70>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fca317b5610>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '“继续加大在中国的投资”（见证·中国机遇）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 's...
               │        │    │          └ <function Template.substitute at 0x7fcb4969f0d0>
               │        │    └ <string.Template object at 0x7fc86f3e2c70>
               │        └ <function post at 0x7fcb23482430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '“继续加大在中国的投资”（见证·中国机遇）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 's...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fcb234ee0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '“继续加大在中国的投资”（见证·中国机遇）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzz...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fcb234809d0>
           └ <requests.sessions.Session object at 0x7fc86fee6e80>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fcb23480e50>
           └ <requests.sessions.Session object at 0x7fc86fee6e80>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fcb23480310>
        └ <requests.adapters.HTTPAdapter object at 0x7fc873c44850>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9fce86a90>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 17:15:30.064 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fcb23698280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fcb236a6670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc86506bd90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u97e9\\u56fd\\u73af\\u4fdd\\u4eba\\u58eb\\u548c\\u667a\\u5229\\u5b66\\u8005\\u547c\\u5401\\u963b\\u6b62...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fcb2364e040>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u97e9\\u56fd\\u73af\\u4fdd\\u4eba\\u58eb\\u548c\\u667a\\u5229\\u5b66\\u8005\\u547c\\u5401\\u963b\\u6b62\\u65e5\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u97e9\\u56fd\\u73af\\u4fdd\\u4eba\\u58eb\\u548c\\u667a\\u5229\\u5b66\\u8005\\u547c\\u5401\\u963b\\u6b62\\u65e5\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fcb38ef2280>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u97e9\\u56fd\\u73af\\u4fdd\\u4eba\\u58eb\\u548c\\u667a\\u5229\\u5b66\\u8005\\u547c\\u5401\\u963b\\u6b62\\u65e5\\...
    │    └ <function HTTPConnection.endheaders at 0x7fcb38ef2160>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u97e9\\u56fd\\u73af\\u4fdd\\u4eba\\u58eb\\u548c\\u667a\\u5229\\u5b66\\u8005\\u547c\\u5401\\u963b\\u6b62\\u65e5\\...
    │    └ <function HTTPConnection._send_output at 0x7fcb38f59d30>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fcb38f59b80>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fcb2364ce50>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fcb2364cca0>
           └ <urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fcb236a68b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc86506bd90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fcb236a2c10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc86506bd90>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fcb496b6a60>
    └ <Thread(Thread-29, started daemon 140506122135296)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fcb496b6790>
    └ <Thread(Thread-29, started daemon 140506122135296)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-29, started daemon 140506122135296)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-29, started daemon 140506122135296)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>>
    └ <Thread(Thread-29, started daemon 140506122135296)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fca31ba7dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>
    └ <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fca318b4460>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fca30115b20>
    │    │                                │              │         └ '韩国环保人士和智利学者呼吁阻止日本核污染水排海计划'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fca31ba7e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fcb29b4a550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fca30115b20>
               │    │                        │         └ '韩国环保人士和智利学者呼吁阻止日本核污染水排海计划'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fca31ba7f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fc865a64ca0>
                   │    │       │                                  │        │           └ '韩国环保人士和智利学者呼吁阻止日本核污染水排海计划'
                   │    │       │                                  │        └ <string.Template object at 0x7fc928707460>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fca317b5610>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '韩国环保人士和智利学者呼吁阻止日本核污染水排海计划', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0...
               │        │    │          └ <function Template.substitute at 0x7fcb4969f0d0>
               │        │    └ <string.Template object at 0x7fc928707460>
               │        └ <function post at 0x7fcb23482430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '韩国环保人士和智利学者呼吁阻止日本核污染水排海计划', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fcb234ee0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '韩国环保人士和智利学者呼吁阻止日本核污染水排海计划', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'is...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fcb234809d0>
           └ <requests.sessions.Session object at 0x7fc87cf3bb20>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fcb23480e50>
           └ <requests.sessions.Session object at 0x7fc87cf3bb20>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fcb23480310>
        └ <requests.adapters.HTTPAdapter object at 0x7fc8b0297970>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c8998e50>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 17:15:33.554 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fcb23698280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fcb236a6670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc908374400>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u6b27\\u6d32\\u836f\\u7ba1\\u5c40\\uff1a\\u65b0\\u51a0\\u75ab\\u60c5\\u8fdc\\u672a\\u7ed3\\u675f \\u5e0...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fcb2364e040>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u6b27\\u6d32\\u836f\\u7ba1\\u5c40\\uff1a\\u65b0\\u51a0\\u75ab\\u60c5\\u8fdc\\u672a\\u7ed3\\u675f \\u5e0c\\u671b\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u6b27\\u6d32\\u836f\\u7ba1\\u5c40\\uff1a\\u65b0\\u51a0\\u75ab\\u60c5\\u8fdc\\u672a\\u7ed3\\u675f \\u5e0c\\u671b\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fcb38ef2280>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u6b27\\u6d32\\u836f\\u7ba1\\u5c40\\uff1a\\u65b0\\u51a0\\u75ab\\u60c5\\u8fdc\\u672a\\u7ed3\\u675f \\u5e0c\\u671b\...
    │    └ <function HTTPConnection.endheaders at 0x7fcb38ef2160>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u6b27\\u6d32\\u836f\\u7ba1\\u5c40\\uff1a\\u65b0\\u51a0\\u75ab\\u60c5\\u8fdc\\u672a\\u7ed3\\u675f \\u5e0c\\u671b\...
    │    └ <function HTTPConnection._send_output at 0x7fcb38f59d30>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fcb38f59b80>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fcb2364ce50>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fcb2364cca0>
           └ <urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fcb236a68b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc908374400>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fcb236a2c10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc908374400>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fcb496b6a60>
    └ <Thread(Thread-8, started daemon 140506164098816)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fcb496b6790>
    └ <Thread(Thread-8, started daemon 140506164098816)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-8, started daemon 140506164098816)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-8, started daemon 140506164098816)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>>
    └ <Thread(Thread-8, started daemon 140506164098816)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fca31ba7dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>
    └ <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fca318b4460>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fca30720d60>
    │    │                                │              │         └ '欧洲药管局：新冠疫情远未结束 希望改进版疫苗9月前获批'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fca31ba7e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fcb29b4a550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fca30720d60>
               │    │                        │         └ '欧洲药管局：新冠疫情远未结束 希望改进版疫苗9月前获批'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fca31ba7f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fc9c582e790>
                   │    │       │                                  │        │           └ '欧洲药管局：新冠疫情远未结束 希望改进版疫苗9月前获批'
                   │    │       │                                  │        └ <string.Template object at 0x7fc8c82c5d30>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fca317b5610>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '欧洲药管局：新冠疫情远未结束 希望改进版疫苗9月前获批', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type':...
               │        │    │          └ <function Template.substitute at 0x7fcb4969f0d0>
               │        │    └ <string.Template object at 0x7fc8c82c5d30>
               │        └ <function post at 0x7fcb23482430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '欧洲药管局：新冠疫情远未结束 希望改进版疫苗9月前获批', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type':...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fcb234ee0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '欧洲药管局：新冠疫情远未结束 希望改进版疫苗9月前获批', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, '...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fcb234809d0>
           └ <requests.sessions.Session object at 0x7fc9c44f1a30>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fcb23480e50>
           └ <requests.sessions.Session object at 0x7fc9c44f1a30>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fcb23480310>
        └ <requests.adapters.HTTPAdapter object at 0x7fc8b06f8d90>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c94125e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 17:15:42.133 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc864ffad00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fcb23698280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fcb236a6670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc9861f5040>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u4e2d\\u56fd\\u7535\\u52a8\\u8f66\\u4f01\\u4e1a\\u52a9\\u529b\\u6cf0\\u56fd\\u4ee5\\u7535\\u6469\\u66ff...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fcb2364e040>
    └ <urllib3.connection.HTTPConnection object at 0x7fc864ffad00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u4e2d\\u56fd\\u7535\\u52a8\\u8f66\\u4f01\\u4e1a\\u52a9\\u529b\\u6cf0\\u56fd\\u4ee5\\u7535\\u6469\\u66ff\\u4ee3\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fc864ffad00>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u4e2d\\u56fd\\u7535\\u52a8\\u8f66\\u4f01\\u4e1a\\u52a9\\u529b\\u6cf0\\u56fd\\u4ee5\\u7535\\u6469\\u66ff\\u4ee3\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fcb38ef2280>
    └ <urllib3.connection.HTTPConnection object at 0x7fc864ffad00>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u4e2d\\u56fd\\u7535\\u52a8\\u8f66\\u4f01\\u4e1a\\u52a9\\u529b\\u6cf0\\u56fd\\u4ee5\\u7535\\u6469\\u66ff\\u4ee3\\...
    │    └ <function HTTPConnection.endheaders at 0x7fcb38ef2160>
    └ <urllib3.connection.HTTPConnection object at 0x7fc864ffad00>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u4e2d\\u56fd\\u7535\\u52a8\\u8f66\\u4f01\\u4e1a\\u52a9\\u529b\\u6cf0\\u56fd\\u4ee5\\u7535\\u6469\\u66ff\\u4ee3\\...
    │    └ <function HTTPConnection._send_output at 0x7fcb38f59d30>
    └ <urllib3.connection.HTTPConnection object at 0x7fc864ffad00>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fcb38f59b80>
    └ <urllib3.connection.HTTPConnection object at 0x7fc864ffad00>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fcb2364ce50>
    └ <urllib3.connection.HTTPConnection object at 0x7fc864ffad00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fcb2364cca0>
           └ <urllib3.connection.HTTPConnection object at 0x7fc864ffad00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc864ffad00>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fcb236a68b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc9861f5040>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fcb236a2c10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc864ffad00>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc9861f5040>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc864ffad00>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fcb496b6a60>
    └ <Thread(Thread-307, started daemon 140500898924288)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fcb496b6790>
    └ <Thread(Thread-307, started daemon 140500898924288)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-307, started daemon 140500898924288)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-307, started daemon 140500898924288)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>>
    └ <Thread(Thread-307, started daemon 140500898924288)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fca31ba7dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>
    └ <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fca318b4460>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fc9ab1c89d0>
    │    │                                │              │         └ '中国电动车企业助力泰国以电摩替代燃油摩的'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fca31ba7e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fcb29b4a550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fc9ab1c89d0>
               │    │                        │         └ '中国电动车企业助力泰国以电摩替代燃油摩的'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fca31ba7f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fc9666c1790>
                   │    │       │                                  │        │           └ '中国电动车企业助力泰国以电摩替代燃油摩的'
                   │    │       │                                  │        └ <string.Template object at 0x7fc9a8076310>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fca317b5610>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '中国电动车企业助力泰国以电摩替代燃油摩的', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
               │        │    │          └ <function Template.substitute at 0x7fcb4969f0d0>
               │        │    └ <string.Template object at 0x7fc9a8076310>
               │        └ <function post at 0x7fcb23482430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '中国电动车企业助力泰国以电摩替代燃油摩的', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fcb234ee0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '中国电动车企业助力泰国以电摩替代燃油摩的', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fcb234809d0>
           └ <requests.sessions.Session object at 0x7fc864d66820>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fcb23480e50>
           └ <requests.sessions.Session object at 0x7fc864d66820>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fcb23480310>
        └ <requests.adapters.HTTPAdapter object at 0x7fc9c5c4e280>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc864ffad00>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 17:15:43.236 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc94c251460>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fcb23698280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fcb236a6670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fca30458760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u6b27\\u6d32\\u836f\\u7ba1\\u5c40\\uff1a\\u65b0\\u51a0\\u75ab\\u60c5\\u8fdc\\u672a\\u7ed3\\u675f \\u5e0...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fcb2364e040>
    └ <urllib3.connection.HTTPConnection object at 0x7fc94c251460>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u6b27\\u6d32\\u836f\\u7ba1\\u5c40\\uff1a\\u65b0\\u51a0\\u75ab\\u60c5\\u8fdc\\u672a\\u7ed3\\u675f \\u5e0c\\u671b\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fc94c251460>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u6b27\\u6d32\\u836f\\u7ba1\\u5c40\\uff1a\\u65b0\\u51a0\\u75ab\\u60c5\\u8fdc\\u672a\\u7ed3\\u675f \\u5e0c\\u671b\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fcb38ef2280>
    └ <urllib3.connection.HTTPConnection object at 0x7fc94c251460>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u6b27\\u6d32\\u836f\\u7ba1\\u5c40\\uff1a\\u65b0\\u51a0\\u75ab\\u60c5\\u8fdc\\u672a\\u7ed3\\u675f \\u5e0c\\u671b\...
    │    └ <function HTTPConnection.endheaders at 0x7fcb38ef2160>
    └ <urllib3.connection.HTTPConnection object at 0x7fc94c251460>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u6b27\\u6d32\\u836f\\u7ba1\\u5c40\\uff1a\\u65b0\\u51a0\\u75ab\\u60c5\\u8fdc\\u672a\\u7ed3\\u675f \\u5e0c\\u671b\...
    │    └ <function HTTPConnection._send_output at 0x7fcb38f59d30>
    └ <urllib3.connection.HTTPConnection object at 0x7fc94c251460>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fcb38f59b80>
    └ <urllib3.connection.HTTPConnection object at 0x7fc94c251460>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fcb2364ce50>
    └ <urllib3.connection.HTTPConnection object at 0x7fc94c251460>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fcb2364cca0>
           └ <urllib3.connection.HTTPConnection object at 0x7fc94c251460>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc94c251460>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fcb236a68b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fca30458760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fcb236a2c10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc94c251460>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fca30458760>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc94c251460>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fcb496b6a60>
    └ <Thread(Thread-3, started daemon 140506389980928)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fcb496b6790>
    └ <Thread(Thread-3, started daemon 140506389980928)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-3, started daemon 140506389980928)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-3, started daemon 140506389980928)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>>
    └ <Thread(Thread-3, started daemon 140506389980928)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fca31ba7dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>
    └ <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fca318b4460>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fca31798070>
    │    │                                │              │         └ '欧洲药管局：新冠疫情远未结束 希望改进版疫苗9月前获批'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fca31ba7e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fcb29b4a550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fca31798070>
               │    │                        │         └ '欧洲药管局：新冠疫情远未结束 希望改进版疫苗9月前获批'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fca31ba7f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fc96615a370>
                   │    │       │                                  │        │           └ '欧洲药管局：新冠疫情远未结束 希望改进版疫苗9月前获批'
                   │    │       │                                  │        └ <string.Template object at 0x7fc87fef5610>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fca317b5610>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '欧洲药管局：新冠疫情远未结束 希望改进版疫苗9月前获批', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type':...
               │        │    │          └ <function Template.substitute at 0x7fcb4969f0d0>
               │        │    └ <string.Template object at 0x7fc87fef5610>
               │        └ <function post at 0x7fcb23482430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '欧洲药管局：新冠疫情远未结束 希望改进版疫苗9月前获批', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type':...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fcb234ee0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '欧洲药管局：新冠疫情远未结束 希望改进版疫苗9月前获批', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, '...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fcb234809d0>
           └ <requests.sessions.Session object at 0x7fc86728ad90>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fcb23480e50>
           └ <requests.sessions.Session object at 0x7fc86728ad90>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fcb23480310>
        └ <requests.adapters.HTTPAdapter object at 0x7fc86655be50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc94c251460>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 17:15:44.990 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fcb23698280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fcb236a6670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8670314c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u4e2d\\u56fd\\u7535\\u52a8\\u8f66\\u4f01\\u4e1a\\u52a9\\u529b\\u6cf0\\u56fd\\u4ee5\\u7535\\u6469\\u66ff...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fcb2364e040>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u4e2d\\u56fd\\u7535\\u52a8\\u8f66\\u4f01\\u4e1a\\u52a9\\u529b\\u6cf0\\u56fd\\u4ee5\\u7535\\u6469\\u66ff\\u4ee3\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u4e2d\\u56fd\\u7535\\u52a8\\u8f66\\u4f01\\u4e1a\\u52a9\\u529b\\u6cf0\\u56fd\\u4ee5\\u7535\\u6469\\u66ff\\u4ee3\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fcb38ef2280>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u4e2d\\u56fd\\u7535\\u52a8\\u8f66\\u4f01\\u4e1a\\u52a9\\u529b\\u6cf0\\u56fd\\u4ee5\\u7535\\u6469\\u66ff\\u4ee3\\...
    │    └ <function HTTPConnection.endheaders at 0x7fcb38ef2160>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u4e2d\\u56fd\\u7535\\u52a8\\u8f66\\u4f01\\u4e1a\\u52a9\\u529b\\u6cf0\\u56fd\\u4ee5\\u7535\\u6469\\u66ff\\u4ee3\\...
    │    └ <function HTTPConnection._send_output at 0x7fcb38f59d30>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fcb38f59b80>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fcb2364ce50>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fcb2364cca0>
           └ <urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fcb236a68b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8670314c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fcb236a2c10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8670314c0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fcb496b6a60>
    └ <Thread(Thread-148, started daemon 140504093398784)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fcb496b6790>
    └ <Thread(Thread-148, started daemon 140504093398784)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-148, started daemon 140504093398784)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-148, started daemon 140504093398784)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>>
    └ <Thread(Thread-148, started daemon 140504093398784)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fca31ba7dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>
    └ <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fca318b4460>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fc9fc0552e0>
    │    │                                │              │         └ '中国电动车企业助力泰国以电摩替代燃油摩的'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fca31ba7e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fcb29b4a550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fc9fc0552e0>
               │    │                        │         └ '中国电动车企业助力泰国以电摩替代燃油摩的'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fca31ba7f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fc986214970>
                   │    │       │                                  │        │           └ '中国电动车企业助力泰国以电摩替代燃油摩的'
                   │    │       │                                  │        └ <string.Template object at 0x7fc8902b2370>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fca317b5610>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '中国电动车企业助力泰国以电摩替代燃油摩的', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
               │        │    │          └ <function Template.substitute at 0x7fcb4969f0d0>
               │        │    └ <string.Template object at 0x7fc8902b2370>
               │        └ <function post at 0x7fcb23482430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '中国电动车企业助力泰国以电摩替代燃油摩的', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fcb234ee0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '中国电动车企业助力泰国以电摩替代燃油摩的', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fcb234809d0>
           └ <requests.sessions.Session object at 0x7fc9661fe3d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fcb23480e50>
           └ <requests.sessions.Session object at 0x7fc9661fe3d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fcb23480310>
        └ <requests.adapters.HTTPAdapter object at 0x7fca300fa910>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9664a1d90>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 17:15:49.465 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc872de4d30>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fcb23698280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('118.212.233.249', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fcb236a6670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8ca4c8640>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fcb2364e040>
    └ <urllib3.connection.HTTPConnection object at 0x7fc872de4d30>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee\\u4ef7\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fc872de4d30>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee\\u4ef7\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fcb38ef2280>
    └ <urllib3.connection.HTTPConnection object at 0x7fc872de4d30>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee\\u4ef7\\...
    │    └ <function HTTPConnection.endheaders at 0x7fcb38ef2160>
    └ <urllib3.connection.HTTPConnection object at 0x7fc872de4d30>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee\\u4ef7\\...
    │    └ <function HTTPConnection._send_output at 0x7fcb38f59d30>
    └ <urllib3.connection.HTTPConnection object at 0x7fc872de4d30>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fcb38f59b80>
    └ <urllib3.connection.HTTPConnection object at 0x7fc872de4d30>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fcb2364ce50>
    └ <urllib3.connection.HTTPConnection object at 0x7fc872de4d30>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fcb2364cca0>
           └ <urllib3.connection.HTTPConnection object at 0x7fc872de4d30>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc872de4d30>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fcb236a68b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8ca4c8640>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fcb236a2c10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc872de4d30>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8ca4c8640>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc872de4d30>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fcb496b6a60>
    └ <Thread(Thread-601, started daemon 140498746484480)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fcb496b6790>
    └ <Thread(Thread-601, started daemon 140498746484480)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-601, started daemon 140498746484480)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-601, started daemon 140498746484480)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>>
    └ <Thread(Thread-601, started daemon 140498746484480)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fca31ba7dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>
    └ <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fca318b4460>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fc9c5780610>
    │    │                                │              │         └ '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fca31ba7e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fcb29b4a550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fc9c5780610>
               │    │                        │         └ '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fca31ba7f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fc87e55d610>
                   │    │       │                                  │        │           └ '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点'
                   │    │       │                                  │        └ <string.Template object at 0x7fc9ab548b20>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fca317b5610>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tru...
               │        │    │          └ <function Template.substitute at 0x7fcb4969f0d0>
               │        │    └ <string.Template object at 0x7fc9ab548b20>
               │        └ <function post at 0x7fcb23482430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tru...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fcb234ee0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fcb234809d0>
           └ <requests.sessions.Session object at 0x7fc873c64490>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fcb23480e50>
           └ <requests.sessions.Session object at 0x7fc873c64490>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fcb23480310>
        └ <requests.adapters.HTTPAdapter object at 0x7fc96635e7f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc872de4d30>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 17:15:49.855 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fcb23698280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fcb236a6670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8b0192ee0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fcb2364e040>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee\\u4ef7\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee\\u4ef7\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fcb38ef2280>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee\\u4ef7\\...
    │    └ <function HTTPConnection.endheaders at 0x7fcb38ef2160>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee\\u4ef7\\...
    │    └ <function HTTPConnection._send_output at 0x7fcb38f59d30>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fcb38f59b80>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fcb2364ce50>
    └ <urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fcb2364cca0>
           └ <urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fcb236a68b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8b0192ee0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fcb236a2c10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8b0192ee0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fcb496b6a60>
    └ <Thread(Thread-541, started daemon 140498927232768)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fcb496b6790>
    └ <Thread(Thread-541, started daemon 140498927232768)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-541, started daemon 140498927232768)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-541, started daemon 140498927232768)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>>
    └ <Thread(Thread-541, started daemon 140498927232768)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fca31ba7dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>
    └ <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fca318b4460>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fc872db73a0>
    │    │                                │              │         └ '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fca31ba7e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fcb29b4a550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fc872db73a0>
               │    │                        │         └ '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fca31ba7f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fc8711b6460>
                   │    │       │                                  │        │           └ '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点'
                   │    │       │                                  │        └ <string.Template object at 0x7fc870e56190>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fca317b5610>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tru...
               │        │    │          └ <function Template.substitute at 0x7fcb4969f0d0>
               │        │    └ <string.Template object at 0x7fc870e56190>
               │        └ <function post at 0x7fcb23482430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tru...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fcb234ee0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fcb234809d0>
           └ <requests.sessions.Session object at 0x7fc864c69100>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fcb23480e50>
           └ <requests.sessions.Session object at 0x7fc864c69100>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fcb23480310>
        └ <requests.adapters.HTTPAdapter object at 0x7fc873c7e460>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9c41d00d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 17:15:50.045 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fcb23698280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fcb236a6670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8b063cf40>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u5305\\u6d25\\u71d5\\uff1a\\u624e\\u6839\\u5ba1\\u5224\\u4e00\\u7ebf \\u5168\\u5fc3\\u5168\\u610f\\u4e3...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fcb2364e040>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u5305\\u6d25\\u71d5\\uff1a\\u624e\\u6839\\u5ba1\\u5224\\u4e00\\u7ebf \\u5168\\u5fc3\\u5168\\u610f\\u4e3a\\u7fa4\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u5305\\u6d25\\u71d5\\uff1a\\u624e\\u6839\\u5ba1\\u5224\\u4e00\\u7ebf \\u5168\\u5fc3\\u5168\\u610f\\u4e3a\\u7fa4\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fcb38ef2280>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u5305\\u6d25\\u71d5\\uff1a\\u624e\\u6839\\u5ba1\\u5224\\u4e00\\u7ebf \\u5168\\u5fc3\\u5168\\u610f\\u4e3a\\u7fa4\...
    │    └ <function HTTPConnection.endheaders at 0x7fcb38ef2160>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u5305\\u6d25\\u71d5\\uff1a\\u624e\\u6839\\u5ba1\\u5224\\u4e00\\u7ebf \\u5168\\u5fc3\\u5168\\u610f\\u4e3a\\u7fa4\...
    │    └ <function HTTPConnection._send_output at 0x7fcb38f59d30>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fcb38f59b80>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fcb2364ce50>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fcb2364cca0>
           └ <urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fcb236a68b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8b063cf40>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fcb236a2c10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8b063cf40>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fcb496b6a60>
    └ <Thread(Thread-223, started daemon 140502582150912)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fcb496b6790>
    └ <Thread(Thread-223, started daemon 140502582150912)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-223, started daemon 140502582150912)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-223, started daemon 140502582150912)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>>
    └ <Thread(Thread-223, started daemon 140502582150912)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fca31ba7dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>
    └ <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fca318b4460>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fc9c590e970>
    │    │                                │              │         └ '包津燕：扎根审判一线 全心全意为群众化解矛盾'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fca31ba7e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fcb29b4a550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fc9c590e970>
               │    │                        │         └ '包津燕：扎根审判一线 全心全意为群众化解矛盾'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fca31ba7f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fc86bc3e670>
                   │    │       │                                  │        │           └ '包津燕：扎根审判一线 全心全意为群众化解矛盾'
                   │    │       │                                  │        └ <string.Template object at 0x7fc8ca17d9a0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fca317b5610>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '包津燕：扎根审判一线 全心全意为群众化解矛盾', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, '...
               │        │    │          └ <function Template.substitute at 0x7fcb4969f0d0>
               │        │    └ <string.Template object at 0x7fc8ca17d9a0>
               │        └ <function post at 0x7fcb23482430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '包津燕：扎根审判一线 全心全意为群众化解矛盾', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, '...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fcb234ee0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '包津燕：扎根审判一线 全心全意为群众化解矛盾', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuz...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fcb234809d0>
           └ <requests.sessions.Session object at 0x7fc86bc41c70>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fcb23480e50>
           └ <requests.sessions.Session object at 0x7fc86bc41c70>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fcb23480310>
        └ <requests.adapters.HTTPAdapter object at 0x7fc9abf5f7c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c8827a00>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 17:15:56.167 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fcb23698280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fcb236a6670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc96669f490>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u9a6c\\u62c9\\u5580\\u4ec0\\u6761\\u7ea6\\u5bf9\\u6211\\u56fd\\u751f\\u6548", "page": 1, "limit": 10, "...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fcb2364e040>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u9a6c\\u62c9\\u5580\\u4ec0\\u6761\\u7ea6\\u5bf9\\u6211\\u56fd\\u751f\\u6548", "page": 1, "limit": 10, "hasTitle"...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u9a6c\\u62c9\\u5580\\u4ec0\\u6761\\u7ea6\\u5bf9\\u6211\\u56fd\\u751f\\u6548", "page": 1, "limit": 10, "hasTitle"...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fcb38ef2280>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u9a6c\\u62c9\\u5580\\u4ec0\\u6761\\u7ea6\\u5bf9\\u6211\\u56fd\\u751f\\u6548", "page": 1, "limit": 10, "hasTitle"...
    │    └ <function HTTPConnection.endheaders at 0x7fcb38ef2160>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u9a6c\\u62c9\\u5580\\u4ec0\\u6761\\u7ea6\\u5bf9\\u6211\\u56fd\\u751f\\u6548", "page": 1, "limit": 10, "hasTitle"...
    │    └ <function HTTPConnection._send_output at 0x7fcb38f59d30>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fcb38f59b80>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fcb2364ce50>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fcb2364cca0>
           └ <urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fcb236a68b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc96669f490>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fcb236a2c10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc96669f490>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fcb496b6a60>
    └ <Thread(Thread-127, started daemon 140504126969600)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fcb496b6790>
    └ <Thread(Thread-127, started daemon 140504126969600)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-127, started daemon 140504126969600)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-127, started daemon 140504126969600)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>>
    └ <Thread(Thread-127, started daemon 140504126969600)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fca31ba7dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>
    └ <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fca318b4460>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fca204db130>
    │    │                                │              │         └ '马拉喀什条约对我国生效'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fca31ba7e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fcb29b4a550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fca204db130>
               │    │                        │         └ '马拉喀什条约对我国生效'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fca31ba7f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fc87420fc40>
                   │    │       │                                  │        │           └ '马拉喀什条约对我国生效'
                   │    │       │                                  │        └ <string.Template object at 0x7fc94c4beb20>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fca317b5610>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '马拉喀什条约对我国生效', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': ...
               │        │    │          └ <function Template.substitute at 0x7fcb4969f0d0>
               │        │    └ <string.Template object at 0x7fc94c4beb20>
               │        └ <function post at 0x7fcb23482430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '马拉喀什条约对我国生效', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': ...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fcb234ee0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '马拉喀什条约对我国生效', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, ...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fcb234809d0>
           └ <requests.sessions.Session object at 0x7fc94c5e6400>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fcb23480e50>
           └ <requests.sessions.Session object at 0x7fc94c5e6400>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fcb23480310>
        └ <requests.adapters.HTTPAdapter object at 0x7fc8702cb0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c834e9a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 17:15:59.339 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fcb23698280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fcb236a6670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8b02f11c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fcb2364e040>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee\\u4ef7\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee\\u4ef7\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fcb38ef2280>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee\\u4ef7\\...
    │    └ <function HTTPConnection.endheaders at 0x7fcb38ef2160>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u94bb\\u6f0f\\u6d1e\\u975e\\u6cd5\\u725f\\u5229\\u3001\\u865a\\u589e\\u4e2d\\u95f4\\u5546\\u8d5a\\u5dee\\u4ef7\\...
    │    └ <function HTTPConnection._send_output at 0x7fcb38f59d30>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fcb38f59b80>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fcb2364ce50>
    └ <urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fcb2364cca0>
           └ <urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fcb236a68b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8b02f11c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fcb236a2c10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc8b02f11c0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fcb496b6a60>
    └ <Thread(Thread-544, started daemon 140498910451456)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fcb496b6790>
    └ <Thread(Thread-544, started daemon 140498910451456)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-544, started daemon 140498910451456)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-544, started daemon 140498910451456)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>>
    └ <Thread(Thread-544, started daemon 140498910451456)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fca31ba7dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>
    └ <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fca318b4460>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fca3028a9d0>
    │    │                                │              │         └ '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fca31ba7e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fcb29b4a550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fca3028a9d0>
               │    │                        │         └ '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fca31ba7f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fc8ca10af40>
                   │    │       │                                  │        │           └ '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点'
                   │    │       │                                  │        └ <string.Template object at 0x7fc89019c580>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fca317b5610>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tru...
               │        │    │          └ <function Template.substitute at 0x7fcb4969f0d0>
               │        │    └ <string.Template object at 0x7fc89019c580>
               │        └ <function post at 0x7fcb23482430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tru...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fcb234ee0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '钻漏洞非法牟利、虚增中间商赚差价……最高检典型案例揭示职务侵占犯罪这些特点', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fcb234809d0>
           └ <requests.sessions.Session object at 0x7fc8665be970>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fcb23480e50>
           └ <requests.sessions.Session object at 0x7fc8665be970>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fcb23480310>
        └ <requests.adapters.HTTPAdapter object at 0x7fc9287b77c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8c93d5b50>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 17:16:12.938 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc871d717f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7fcb23698280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fcb236a6670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc86d8f9f10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "2022\\u5e74\\u201c\\u7ea2\\u5341\\u5b57\\u535a\\u7231\\u5468\\u201d\\u6d3b\\u52a8\\u4e30\\u5bcc\\u591a\\u...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7fcb2364e040>
    └ <urllib3.connection.HTTPConnection object at 0x7fc871d717f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "2022\\u5e74\\u201c\\u7ea2\\u5341\\u5b57\\u535a\\u7231\\u5468\\u201d\\u6d3b\\u52a8\\u4e30\\u5bcc\\u591a\\u5f69", "p...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7fc871d717f0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "2022\\u5e74\\u201c\\u7ea2\\u5341\\u5b57\\u535a\\u7231\\u5468\\u201d\\u6d3b\\u52a8\\u4e30\\u5bcc\\u591a\\u5f69", "p...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7fcb38ef2280>
    └ <urllib3.connection.HTTPConnection object at 0x7fc871d717f0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "2022\\u5e74\\u201c\\u7ea2\\u5341\\u5b57\\u535a\\u7231\\u5468\\u201d\\u6d3b\\u52a8\\u4e30\\u5bcc\\u591a\\u5f69", "p...
    │    └ <function HTTPConnection.endheaders at 0x7fcb38ef2160>
    └ <urllib3.connection.HTTPConnection object at 0x7fc871d717f0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "2022\\u5e74\\u201c\\u7ea2\\u5341\\u5b57\\u535a\\u7231\\u5468\\u201d\\u6d3b\\u52a8\\u4e30\\u5bcc\\u591a\\u5f69", "p...
    │    └ <function HTTPConnection._send_output at 0x7fcb38f59d30>
    └ <urllib3.connection.HTTPConnection object at 0x7fc871d717f0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7fcb38f59b80>
    └ <urllib3.connection.HTTPConnection object at 0x7fc871d717f0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7fcb2364ce50>
    └ <urllib3.connection.HTTPConnection object at 0x7fc871d717f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7fcb2364cca0>
           └ <urllib3.connection.HTTPConnection object at 0x7fc871d717f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc871d717f0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fcb236a68b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc86d8f9f10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fcb236a2c10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc871d717f0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7fc86d8f9f10>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc871d717f0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fcb496b6a60>
    └ <Thread(Thread-117, started daemon 140504149784320)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fcb496b6790>
    └ <Thread(Thread-117, started daemon 140504149784320)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-117, started daemon 140504149784320)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-117, started daemon 140504149784320)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>>
    └ <Thread(Thread-117, started daemon 140504149784320)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fca31ba7dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>
    └ <monitor.projectManager.ProjectManager object at 0x7fca31ba5190>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fca318b4460>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fc9fce66f40>
    │    │                                │              │         └ '2022年“红十字博爱周”活动丰富多彩'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fca31ba7e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fcb29b4a550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fc9fce66f40>
               │    │                        │         └ '2022年“红十字博爱周”活动丰富多彩'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fca31ba7f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fc9ab618730>
                   │    │       │                                  │        │           └ '2022年“红十字博爱周”活动丰富多彩'
                   │    │       │                                  │        └ <string.Template object at 0x7fc872f697f0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fca317b5610>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fca317b5880>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '2022年“红十字博爱周”活动丰富多彩', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sor...
               │        │    │          └ <function Template.substitute at 0x7fcb4969f0d0>
               │        │    └ <string.Template object at 0x7fc872f697f0>
               │        └ <function post at 0x7fcb23482430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '2022年“红十字博爱周”活动丰富多彩', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sor...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7fcb234ee0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '2022年“红十字博爱周”活动丰富多彩', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy'...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7fcb234809d0>
           └ <requests.sessions.Session object at 0x7fc8c877fd60>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7fcb23480e50>
           └ <requests.sessions.Session object at 0x7fc8c877fd60>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7fcb23480310>
        └ <requests.adapters.HTTPAdapter object at 0x7fc9dc2e0310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc871d717f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
