2022-07-11 16:05:11.253 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25A8%2581%25E5%25B0%2594%25E5%25A3%25AB%25E6%2594%25BF%25E5%2595%2586%25E5%25AD%25A6%25E7%2595%258C%25E5%25A4%259A%25E4%25BD%258D%25E4%25BA%25BA%25E5%25A3%25AB%25E8%25A1%25A8%25E7%25A4%25BA%25E6%2584%25BF%25E5%2590%258C%25E4%25B8%25AD%25E5%259B%25BD%25E5%25A2%259E%25E8%25BF%259B%25E4%25BA%25A4%25E6%25B5%2581%25E5%2590%2588%25E4%25BD%259C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D11&timestamp=1657526711&signature=a28d0b02c7c4ef1a30827179bc8a5d4d (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe7b6686430>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fe7ad94e3a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fe7ad9788b0>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe7b6686940>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fe7ad94e3a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe7b6676040>
    └ <urllib3.connection.HTTPSConnection object at 0x7fe7ad9788b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe7b666dd30>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fe7ad9788b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe7b666dee0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe7bbe34e50>
           └ <ssl.SSLContext object at 0x7fe7ae27d440>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe7d7b70af0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fe7ae27d440>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe7d7b75d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe7b6686670>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fe7ad94e3a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe7b699e940>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fe7ad94e3a0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25A8%2581%25E5%25B0%2594%25E5%25A3%25AB%25E6%2594%25BF%25E5%2595%2586%25E5%25AD%25A6%25E7%2595%258C%25E5%25A4%259A%25E4%25BD%258D%25E4%25BA%25BA%25E5%25A3%25AB%25E8%25A1%25A8%25E7%25A4%25BA%25E6%2584%25BF%25E5%2590%258C%25E4%25B8%25AD%25E5%259B%25BD%25E5%25A2%259E%25E8%25BF%259B%25E4%25BA%25A4%25E6%25B5%2581%25E5%2590%2588%25E4%25BD%259C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D11&timestamp=1657526711&signature=a28d0b02c7c4ef1a30827179bc8a5d4d (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe7dabcfa60>
    └ <Thread(Thread-185, started daemon 140633035892480)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe7dabcf790>
    └ <Thread(Thread-185, started daemon 140633035892480)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-185, started daemon 140633035892480)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-185, started daemon 140633035892480)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe7aeef8eb0>>
    └ <Thread(Thread-185, started daemon 140633035892480)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 902, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe7aef188b0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe7aeb4d9a0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe7aeef8eb0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 120, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'eWuChongTu': <monitor.TimeSection object at 0x7fe7aebe5430>, 'default': <monitor.TimeSection object at 0x7fe7aec08bb0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fe7aeacfa60>
    │    │                                │              │         └ '威尔士政商学界多位人士表示愿同中国增进交流合作'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe7aef189d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe7aeb4d9a0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 152, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe7b6b221f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fe7aeacfa60>
               │    │                        │         └ '威尔士政商学界多位人士表示愿同中国增进交流合作'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe7aef18af0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe7aeb4d9a0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,**kwargs):
                   │    │       │                                  │        │           │        │             └ {'start': '2021-06-09 16:05:47', 'end': '2022-07-11 15:58:32'}
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '威尔士政商学界多位人士表示愿同中国增进交流合作'
                   │    │       │                                  │        └ <string.Template object at 0x7fe7aeb5f9a0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe7aeb4d7f0>, '知乎': <monitor.searchSpiders.zhihu.Zhihu object at 0x7f...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe7aeb4d9a0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=威尔士政商学界多位人士表示愿同中国增进交流合作&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=11'
               │        └ <function get at 0x7fe7b6a10a60>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=威尔士政商学界多位人士表示愿同中国增进交流合作&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=11'
           └ <function request at 0x7fe7b64ff9d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=威尔士政商学界多位人士表示愿同中国增进交流合作&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=11'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe7b6a13280>
           └ <requests.sessions.Session object at 0x7fe7ad956b50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe7b6a10e50>
           └ <requests.sessions.Session object at 0x7fe7ad956b50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fe7ac1c9a50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe7b6a10e50>
           └ <requests.sessions.Session object at 0x7fe7ad956b50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe7b6a139d0>
        └ <requests.adapters.HTTPAdapter object at 0x7fe7ad956f10>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25A8%2581%25E5%25B0%2594%25E5%25A3%25AB%25E6%2594%25BF%25E5%2595%2586%25E5%25AD%25A6%25E7%2595%258C%25E5%25A4%259A%25E4%25BD%258D%25E4%25BA%25BA%25E5%25A3%25AB%25E8%25A1%25A8%25E7%25A4%25BA%25E6%2584%25BF%25E5%2590%258C%25E4%25B8%25AD%25E5%259B%25BD%25E5%25A2%259E%25E8%25BF%259B%25E4%25BA%25A4%25E6%25B5%2581%25E5%2590%2588%25E4%25BD%259C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D11&timestamp=1657526711&signature=a28d0b02c7c4ef1a30827179bc8a5d4d (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
