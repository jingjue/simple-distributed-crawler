2022-06-08 19:14:40.858 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%2597%25A5%25E6%259C%25AC%25E5%2585%25B3%25E4%25B8%259C%25E7%2594%25B2%25E4%25BF%25A1%25E5%259C%25B0%25E5%258C%25BA%25E8%25BF%259B%25E5%2585%25A5%25E6%25A2%2585%25E9%259B%25A8%25E5%25AD%25A3%25E8%258A%2582%2520%25E6%25AF%2594%25E5%258E%25BB%25E5%25B9%25B4%25E6%258F%2590%25E5%2589%258D8%25E5%25A4%25A9%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D12&timestamp=1654686880&signature=10e63e791b377448a5f3f7339c88d6d4 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd3a7c7910>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fde506200d0>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd3a7c7910>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fde506200d0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fde506200d0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fde503d58c0>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fde503d58c0>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd3a7c7910>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd3a7c7910>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%2597%25A5%25E6%259C%25AC%25E5%2585%25B3%25E4%25B8%259C%25E7%2594%25B2%25E4%25BF%25A1%25E5%259C%25B0%25E5%258C%25BA%25E8%25BF%259B%25E5%2585%25A5%25E6%25A2%2585%25E9%259B%25A8%25E5%25AD%25A3%25E8%258A%2582%2520%25E6%25AF%2594%25E5%258E%25BB%25E5%25B9%25B4%25E6%258F%2590%25E5%2589%258D8%25E5%25A4%25A9%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D12&timestamp=1654686880&signature=10e63e791b377448a5f3f7339c88d6d4 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-33232, started daemon 140587730921216)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-33232, started daemon 140587730921216)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-33232, started daemon 140587730921216)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-33232, started daemon 140587730921216)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-33232, started daemon 140587730921216)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fdd1e88a1f0>
    │    │                                │              │         └ '日本关东甲信地区进入梅雨季节 比去年提前8天'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fdd1e88a1f0>
               │    │                        │         └ '日本关东甲信地区进入梅雨季节 比去年提前8天'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '日本关东甲信地区进入梅雨季节 比去年提前8天'
                   │    │       │                                  │        └ <string.Template object at 0x7fdf300b6910>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=日本关东甲信地区进入梅雨季节 比去年提前8天&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=12'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=日本关东甲信地区进入梅雨季节 比去年提前8天&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=12'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=日本关东甲信地区进入梅雨季节 比去年提前8天&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=12'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fdd2f4081f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdd2f4081f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdf54676200>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdd2f4081f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdf742e2af0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%2597%25A5%25E6%259C%25AC%25E5%2585%25B3%25E4%25B8%259C%25E7%2594%25B2%25E4%25BF%25A1%25E5%259C%25B0%25E5%258C%25BA%25E8%25BF%259B%25E5%2585%25A5%25E6%25A2%2585%25E9%259B%25A8%25E5%25AD%25A3%25E8%258A%2582%2520%25E6%25AF%2594%25E5%258E%25BB%25E5%25B9%25B4%25E6%258F%2590%25E5%2589%258D8%25E5%25A4%25A9%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D12&timestamp=1654686880&signature=10e63e791b377448a5f3f7339c88d6d4 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 19:15:20.664 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%2597%25A5%25E6%259C%25AC%25E7%25A0%2594%25E7%25A9%25B6%25E5%258F%2591%25E7%258E%25B0%25E5%25B0%258F%25E8%25A1%258C%25E6%2598%259F%25E6%25A0%25B7%25E6%259C%25AC%25E4%25B8%25AD%25E5%25AD%2598%25E5%259C%25A8%25E5%25A4%259A%25E7%25A7%258D%25E6%25B0%25A8%25E5%259F%25BA%25E9%2585%25B8%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D14&timestamp=1654686920&signature=c038018cd68b295965cf96768bd571d0 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd0cd7da00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fdd01963a00>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd0cd7da00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fdd01963a00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fdd01963a00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdd3cd0c140>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdd3cd0c140>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd0cd7da00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd0cd7da00>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%2597%25A5%25E6%259C%25AC%25E7%25A0%2594%25E7%25A9%25B6%25E5%258F%2591%25E7%258E%25B0%25E5%25B0%258F%25E8%25A1%258C%25E6%2598%259F%25E6%25A0%25B7%25E6%259C%25AC%25E4%25B8%25AD%25E5%25AD%2598%25E5%259C%25A8%25E5%25A4%259A%25E7%25A7%258D%25E6%25B0%25A8%25E5%259F%25BA%25E9%2585%25B8%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D14&timestamp=1654686920&signature=c038018cd68b295965cf96768bd571d0 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-32901, started daemon 140596081583872)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-32901, started daemon 140596081583872)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-32901, started daemon 140596081583872)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-32901, started daemon 140596081583872)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-32901, started daemon 140596081583872)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fdf103ce250>
    │    │                                │              │         └ '日本研究发现小行星样本中存在多种氨基酸'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fdf103ce250>
               │    │                        │         └ '日本研究发现小行星样本中存在多种氨基酸'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '日本研究发现小行星样本中存在多种氨基酸'
                   │    │       │                                  │        └ <string.Template object at 0x7fde502aeeb0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=日本研究发现小行星样本中存在多种氨基酸&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=14'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=日本研究发现小行星样本中存在多种氨基酸&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=14'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=日本研究发现小行星样本中存在多种氨基酸&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=14'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fdeb038c2e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdeb038c2e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fde502954a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdeb038c2e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdf30360e50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%2597%25A5%25E6%259C%25AC%25E7%25A0%2594%25E7%25A9%25B6%25E5%258F%2591%25E7%258E%25B0%25E5%25B0%258F%25E8%25A1%258C%25E6%2598%259F%25E6%25A0%25B7%25E6%259C%25AC%25E4%25B8%25AD%25E5%25AD%2598%25E5%259C%25A8%25E5%25A4%259A%25E7%25A7%258D%25E6%25B0%25A8%25E5%259F%25BA%25E9%2585%25B8%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D14&timestamp=1654686920&signature=c038018cd68b295965cf96768bd571d0 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 19:25:50.835 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%2585%2595%25E5%25B0%25BC%25E9%25BB%2591%25E7%258E%25AF%25E5%258D%259A%25E4%25BC%259A%25E8%2581%259A%25E7%2584%25A6%25E7%258E%25AF%25E4%25BF%259D%25E6%2596%25B0%25E6%258A%2580%25E6%259C%25AF%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D6&timestamp=1654687550&signature=3d658d6e8b3e98d367388149083ade43 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdcf08fb670>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fdf74261d90>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdcf08fb670>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fdf74261d90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fdf74261d90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdd0cd8d240>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdd0cd8d240>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdcf08fb670>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdcf08fb670>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%2585%2595%25E5%25B0%25BC%25E9%25BB%2591%25E7%258E%25AF%25E5%258D%259A%25E4%25BC%259A%25E8%2581%259A%25E7%2584%25A6%25E7%258E%25AF%25E4%25BF%259D%25E6%2596%25B0%25E6%258A%2580%25E6%259C%25AF%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D6&timestamp=1654687550&signature=3d658d6e8b3e98d367388149083ade43 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-34432, started daemon 140586801706752)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-34432, started daemon 140586801706752)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-34432, started daemon 140586801706752)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-34432, started daemon 140586801706752)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-34432, started daemon 140586801706752)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fded0226190>
    │    │                                │              │         └ '慕尼黑环博会聚焦环保新技术'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fded0226190>
               │    │                        │         └ '慕尼黑环博会聚焦环保新技术'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '慕尼黑环博会聚焦环保新技术'
                   │    │       │                                  │        └ <string.Template object at 0x7fde901fb490>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=慕尼黑环博会聚焦环保新技术&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=6'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=慕尼黑环博会聚焦环保新技术&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=6'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=慕尼黑环博会聚焦环保新技术&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=6'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fddd0619700>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fddd0619700>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdce3d4c190>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fddd0619700>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fde5057dc70>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%2585%2595%25E5%25B0%25BC%25E9%25BB%2591%25E7%258E%25AF%25E5%258D%259A%25E4%25BC%259A%25E8%2581%259A%25E7%2584%25A6%25E7%258E%25AF%25E4%25BF%259D%25E6%2596%25B0%25E6%258A%2580%25E6%259C%25AF%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D6&timestamp=1654687550&signature=3d658d6e8b3e98d367388149083ade43 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 19:28:50.818 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E9%259D%259E%25E6%25B4%25B2%25E6%259E%2581%25E7%25AB%25AF%25E7%25BB%2584%25E7%25BB%2587%25E6%25AD%25A6%25E5%2599%25A8%25E6%259D%25A5%25E6%25BA%2590%25E5%25BC%2595%25E5%2585%25B3%25E6%25B3%25A8%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D3&timestamp=1654687730&signature=d12caed76e46c4fbc68e7e8d48900941 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd4befabb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fded0188100>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd4befabb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fded0188100>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fded0188100>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdda2141a40>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdda2141a40>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd4befabb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd4befabb0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E9%259D%259E%25E6%25B4%25B2%25E6%259E%2581%25E7%25AB%25AF%25E7%25BB%2584%25E7%25BB%2587%25E6%25AD%25A6%25E5%2599%25A8%25E6%259D%25A5%25E6%25BA%2590%25E5%25BC%2595%25E5%2585%25B3%25E6%25B3%25A8%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D3&timestamp=1654687730&signature=d12caed76e46c4fbc68e7e8d48900941 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-32760, started daemon 140587055318784)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-32760, started daemon 140587055318784)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-32760, started daemon 140587055318784)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-32760, started daemon 140587055318784)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-32760, started daemon 140587055318784)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fde304be5e0>
    │    │                                │              │         └ '非洲极端组织武器来源引关注'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fde304be5e0>
               │    │                        │         └ '非洲极端组织武器来源引关注'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '非洲极端组织武器来源引关注'
                   │    │       │                                  │        └ <string.Template object at 0x7fdcf13c4a00>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=非洲极端组织武器来源引关注&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=3'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=非洲极端组织武器来源引关注&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=3'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=非洲极端组织武器来源引关注&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=3'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fdd3ba9b370>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdd3ba9b370>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdceff47190>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdd3ba9b370>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fde50e62d30>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E9%259D%259E%25E6%25B4%25B2%25E6%259E%2581%25E7%25AB%25AF%25E7%25BB%2584%25E7%25BB%2587%25E6%25AD%25A6%25E5%2599%25A8%25E6%259D%25A5%25E6%25BA%2590%25E5%25BC%2595%25E5%2585%25B3%25E6%25B3%25A8%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D3&timestamp=1654687730&signature=d12caed76e46c4fbc68e7e8d48900941 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 19:30:30.191 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E7%258F%25A0%25E5%25B3%25B0%25E7%25A7%2591%25E8%2580%2583%25E9%2598%259F%25E5%2591%2598%25E9%25A1%25BA%25E5%2588%25A9%25E8%25BF%2594%25E5%259B%259E%25E5%25A4%25A7%25E6%259C%25AC%25E8%2590%25A5%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D12&timestamp=1654687830&signature=f62d431f76590df37f02625b2babc345 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdf102d9220>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fdcf0812970>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdf102d9220>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fdcf0812970>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fdcf0812970>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fde10224ac0>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fde10224ac0>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdf102d9220>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdf102d9220>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E7%258F%25A0%25E5%25B3%25B0%25E7%25A7%2591%25E8%2580%2583%25E9%2598%259F%25E5%2591%2598%25E9%25A1%25BA%25E5%2588%25A9%25E8%25BF%2594%25E5%259B%259E%25E5%25A4%25A7%25E6%259C%25AC%25E8%2590%25A5%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D12&timestamp=1654687830&signature=f62d431f76590df37f02625b2babc345 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-29991, started daemon 140588606371584)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-29991, started daemon 140588606371584)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-29991, started daemon 140588606371584)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-29991, started daemon 140588606371584)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-29991, started daemon 140588606371584)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fe06cd979a0>
    │    │                                │              │         └ '珠峰科考队员顺利返回大本营'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fe06cd979a0>
               │    │                        │         └ '珠峰科考队员顺利返回大本营'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '珠峰科考队员顺利返回大本营'
                   │    │       │                                  │        └ <string.Template object at 0x7fde3008e4c0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=珠峰科考队员顺利返回大本营&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=12'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=珠峰科考队员顺利返回大本营&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=12'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=珠峰科考队员顺利返回大本营&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=12'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fdeb0582f40>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdeb0582f40>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdf545eb5f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdeb0582f40>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdd3d70b700>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E7%258F%25A0%25E5%25B3%25B0%25E7%25A7%2591%25E8%2580%2583%25E9%2598%259F%25E5%2591%2598%25E9%25A1%25BA%25E5%2588%25A9%25E8%25BF%2594%25E5%259B%259E%25E5%25A4%25A7%25E6%259C%25AC%25E8%2590%25A5%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D12&timestamp=1654687830&signature=f62d431f76590df37f02625b2babc345 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 19:33:10.588 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E9%259D%259E%25E6%25B4%25B2%25E6%259E%2581%25E7%25AB%25AF%25E7%25BB%2584%25E7%25BB%2587%25E6%25AD%25A6%25E5%2599%25A8%25E6%259D%25A5%25E6%25BA%2590%25E5%25BC%2595%25E5%2585%25B3%25E6%25B3%25A8%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D1&timestamp=1654687990&signature=9c7403d1a30abfd8890ef2b0415af4ea (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdda1fbe550>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fdd2f3a33a0>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdda1fbe550>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fdd2f3a33a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fdd2f3a33a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fde501211c0>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fde501211c0>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdda1fbe550>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdda1fbe550>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E9%259D%259E%25E6%25B4%25B2%25E6%259E%2581%25E7%25AB%25AF%25E7%25BB%2584%25E7%25BB%2587%25E6%25AD%25A6%25E5%2599%25A8%25E6%259D%25A5%25E6%25BA%2590%25E5%25BC%2595%25E5%2585%25B3%25E6%25B3%25A8%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D1&timestamp=1654687990&signature=9c7403d1a30abfd8890ef2b0415af4ea (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-32850, started daemon 140587563333376)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-32850, started daemon 140587563333376)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-32850, started daemon 140587563333376)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-32850, started daemon 140587563333376)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-32850, started daemon 140587563333376)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fde3014c520>
    │    │                                │              │         └ '非洲极端组织武器来源引关注'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fde3014c520>
               │    │                        │         └ '非洲极端组织武器来源引关注'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '非洲极端组织武器来源引关注'
                   │    │       │                                  │        └ <string.Template object at 0x7fde70619700>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=非洲极端组织武器来源引关注&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=1'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=非洲极端组织武器来源引关注&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=1'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=非洲极端组织武器来源引关注&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=1'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fdd1bdae9a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdd1bdae9a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fddf027b120>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdd1bdae9a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fde7072faf0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E9%259D%259E%25E6%25B4%25B2%25E6%259E%2581%25E7%25AB%25AF%25E7%25BB%2584%25E7%25BB%2587%25E6%25AD%25A6%25E5%2599%25A8%25E6%259D%25A5%25E6%25BA%2590%25E5%25BC%2595%25E5%2585%25B3%25E6%25B3%25A8%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D1&timestamp=1654687990&signature=9c7403d1a30abfd8890ef2b0415af4ea (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 19:37:20.085 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E4%25B8%25AD%25E4%25BC%2581%25E5%258A%25A9%25E5%258A%259B%25E6%25B3%25B0%25E5%259B%25BD%25E6%2591%25A9%25E6%2589%2598%25E8%25BD%25A6%25E7%2594%25B5%25E6%25B0%2594%25E5%258C%2596%25E8%25BD%25AC%25E5%259E%258B%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D27&timestamp=1654688240&signature=800b7c1b887f276fbac99f5bf7609975 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdda23a5d90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fdcc89ce7f0>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdda23a5d90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fdcc89ce7f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fdcc89ce7f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fde300700c0>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fde300700c0>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdda23a5d90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdda23a5d90>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E4%25B8%25AD%25E4%25BC%2581%25E5%258A%25A9%25E5%258A%259B%25E6%25B3%25B0%25E5%259B%25BD%25E6%2591%25A9%25E6%2589%2598%25E8%25BD%25A6%25E7%2594%25B5%25E6%25B0%2594%25E5%258C%2596%25E8%25BD%25AC%25E5%259E%258B%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D27&timestamp=1654688240&signature=800b7c1b887f276fbac99f5bf7609975 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-34429, started daemon 140588874938112)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-34429, started daemon 140588874938112)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-34429, started daemon 140588874938112)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-34429, started daemon 140588874938112)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-34429, started daemon 140588874938112)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fe06cf78490>
    │    │                                │              │         └ '中企助力泰国摩托车电气化转型'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fe06cf78490>
               │    │                        │         └ '中企助力泰国摩托车电气化转型'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '中企助力泰国摩托车电气化转型'
                   │    │       │                                  │        └ <string.Template object at 0x7fdef0125700>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=中企助力泰国摩托车电气化转型&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=27'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=中企助力泰国摩托车电气化转型&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=27'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=中企助力泰国摩托车电气化转型&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=27'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fde103fc700>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde103fc700>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fde102a0e40>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde103fc700>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fde1039aeb0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E4%25B8%25AD%25E4%25BC%2581%25E5%258A%25A9%25E5%258A%259B%25E6%25B3%25B0%25E5%259B%25BD%25E6%2591%25A9%25E6%2589%2598%25E8%25BD%25A6%25E7%2594%25B5%25E6%25B0%2594%25E5%258C%2596%25E8%25BD%25AC%25E5%259E%258B%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D27&timestamp=1654688240&signature=800b7c1b887f276fbac99f5bf7609975 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 19:37:30.290 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25BE%25B7%25E5%259B%25BD%25E5%2592%258C%25E4%25B9%258C%25E5%2585%258B%25E5%2585%25B0%25E4%25B8%25A4%25E5%259B%25BD%25E6%2580%25BB%25E7%25BB%259F%25E9%2580%259A%25E7%2594%25B5%25E8%25AF%259D%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D13&timestamp=1654688250&signature=200edecc94f1dd6176bb6321cce51016 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fded071c250>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fdd14371c10>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fded071c250>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fdd14371c10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fdd14371c10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdd3bc26b40>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdd3bc26b40>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fded071c250>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fded071c250>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25BE%25B7%25E5%259B%25BD%25E5%2592%258C%25E4%25B9%258C%25E5%2585%258B%25E5%2585%25B0%25E4%25B8%25A4%25E5%259B%25BD%25E6%2580%25BB%25E7%25BB%259F%25E9%2580%259A%25E7%2594%25B5%25E8%25AF%259D%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D13&timestamp=1654688250&signature=200edecc94f1dd6176bb6321cce51016 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-34111, started daemon 140587571726080)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-34111, started daemon 140587571726080)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-34111, started daemon 140587571726080)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-34111, started daemon 140587571726080)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-34111, started daemon 140587571726080)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fdda257fbe0>
    │    │                                │              │         └ '德国和乌克兰两国总统通电话'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fdda257fbe0>
               │    │                        │         └ '德国和乌克兰两国总统通电话'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '德国和乌克兰两国总统通电话'
                   │    │       │                                  │        └ <string.Template object at 0x7fde7078b880>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=德国和乌克兰两国总统通电话&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=13'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=德国和乌克兰两国总统通电话&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=13'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=德国和乌克兰两国总统通电话&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=13'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fde1053caf0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde1053caf0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdcec6e43c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde1053caf0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdd0f0901f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25BE%25B7%25E5%259B%25BD%25E5%2592%258C%25E4%25B9%258C%25E5%2585%258B%25E5%2585%25B0%25E4%25B8%25A4%25E5%259B%25BD%25E6%2580%25BB%25E7%25BB%259F%25E9%2580%259A%25E7%2594%25B5%25E8%25AF%259D%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D13&timestamp=1654688250&signature=200edecc94f1dd6176bb6321cce51016 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
