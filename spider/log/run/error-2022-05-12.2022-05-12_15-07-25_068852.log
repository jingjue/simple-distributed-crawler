2022-05-12 15:07:24.866 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-41, started daemon 140320197043968)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-41, started daemon 140320197043968)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-41, started daemon 140320197043968)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-41, started daemon 140320197043968)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-41, started daemon 140320197043968)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9ed5d3e820>
    │    │                                │              │         └ '山东春季苗情好于预期 一、二类苗麦田占比达84%'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9ed5d3e820>
               │    │                        │         └ '山东春季苗情好于预期 一、二类苗麦田占比达84%'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9ef42f2bb0>
                   │    │       │                                  │        │           └ '山东春季苗情好于预期 一、二类苗麦田占比达84%'
                   │    │       │                                  │        └ <string.Template object at 0x7f9ed42756d0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
                   │    │       └ '求是'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 22, in get_request_from_keyword
    page_json = json.loads(page_response.text[14:-2])
                │    │     │             └ <property object at 0x7f9feccacf90>
                │    │     └ <Response [404]>
                │    └ <function loads at 0x7fa00ed46f70>
                └ <module 'json' from '/usr/lib/python3.8/json/__init__.py'>

  File "/usr/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
           │                │      └ ''
           │                └ <function JSONDecoder.decode at 0x7fa00ed468b0>
           └ <json.decoder.JSONDecoder object at 0x7fa00ed3e760>
  File "/usr/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ ''
               │    │          │      └ <built-in method match of re.Pattern object at 0x7fa00ed69f30>
               │    │          └ ''
               │    └ <function JSONDecoder.raw_decode at 0x7fa00ed46940>
               └ <json.decoder.JSONDecoder object at 0x7fa00ed3e760>
  File "/usr/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
          │                                  └ ''
          └ <class 'json.decoder.JSONDecodeError'>

json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2022-05-12 15:07:34.192 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/2/1/2/177701251.html
2022-05-12 15:07:34.329 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误'NoneType' object is not subscriptable
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-28, started daemon 140320698681088)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-28, started daemon 140320698681088)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-28, started daemon 140320698681088)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-28, started daemon 140320698681088)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-28, started daemon 140320698681088)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9ef4568070>
    │    │                                │              │         └ '2022年第二场金砖国家智库国际研讨会举行'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9ef4568070>
               │    │                        │         └ '2022年第二场金砖国家智库国际研讨会举行'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f9e9e6ab5b0>
        │          │    │       │                                  │        │           └ '2022年第二场金砖国家智库国际研讨会举行'
        │          │    │       │                                  │        └ <string.Template object at 0x7f9ed5fe68b0>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
        └ <GET http://www.qstheory.cn/yaowen/2021-10/27/c_1128002383.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 28, in get_request_from_keyword
    for res in json_response['results']:
        │      └ None
        └ {'des': "<font color='red'>国家</font>主席习近平《与世界相交\u3000与时代相通\u3000在可持续发展道路上阔步前行——在<font color='red'>第二</font>届联合国全球可持续交通", 'pub...

TypeError: 'NoneType' object is not subscriptable
2022-05-12 15:07:50.812 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177698766.html
2022-05-12 15:07:51.496 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177698766.html
2022-05-12 15:07:54.047 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177702798.html
2022-05-12 15:07:55.588 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177704094.html
2022-05-12 15:08:30.055 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177702798.html
2022-05-12 15:08:31.143 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177699586.html
2022-05-12 15:08:31.531 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177704094.html
2022-05-12 15:08:42.706 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177698766.html
2022-05-12 15:08:43.277 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177702798.html
2022-05-12 15:08:45.014 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177704094.html
2022-05-12 15:08:48.100 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-28, started daemon 140320698681088)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-28, started daemon 140320698681088)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-28, started daemon 140320698681088)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-28, started daemon 140320698681088)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-28, started daemon 140320698681088)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9ef4568070>
    │    │                                │              │         └ '山东春季苗情好于预期 一、二类苗麦田占比达84%'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9ef4568070>
               │    │                        │         └ '山东春季苗情好于预期 一、二类苗麦田占比达84%'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9eb4d49bb0>
                   │    │       │                                  │        │           └ '山东春季苗情好于预期 一、二类苗麦田占比达84%'
                   │    │       │                                  │        └ <string.Template object at 0x7f9eb517e250>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
                   │    │       └ '求是'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 22, in get_request_from_keyword
    page_json = json.loads(page_response.text[14:-2])
                │    │     │             └ <property object at 0x7f9feccacf90>
                │    │     └ <Response [404]>
                │    └ <function loads at 0x7fa00ed46f70>
                └ <module 'json' from '/usr/lib/python3.8/json/__init__.py'>

  File "/usr/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
           │                │      └ ''
           │                └ <function JSONDecoder.decode at 0x7fa00ed468b0>
           └ <json.decoder.JSONDecoder object at 0x7fa00ed3e760>
  File "/usr/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ ''
               │    │          │      └ <built-in method match of re.Pattern object at 0x7fa00ed69f30>
               │    │          └ ''
               │    └ <function JSONDecoder.raw_decode at 0x7fa00ed46940>
               └ <json.decoder.JSONDecoder object at 0x7fa00ed3e760>
  File "/usr/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
          │                                  └ ''
          └ <class 'json.decoder.JSONDecodeError'>

json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2022-05-12 15:08:57.980 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177712698.html
2022-05-12 15:09:01.003 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/2/1/2/177697202.html
2022-05-12 15:09:05.466 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177702798.html
2022-05-12 15:09:06.018 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177702798.html
2022-05-12 15:09:07.089 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177704094.html
2022-05-12 15:09:07.589 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177704094.html
2022-05-12 15:09:07.849 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177699586.html
2022-05-12 15:09:09.025 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177699586.html
2022-05-12 15:09:17.098 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/2/1/2/177701537.html
2022-05-12 15:09:17.649 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177698766.html
2022-05-12 15:09:17.875 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/2/1/2/177701915.html
2022-05-12 15:09:17.951 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177701917.html
2022-05-12 15:09:25.329 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-33, started daemon 140320689501952)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-33, started daemon 140320689501952)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-33, started daemon 140320689501952)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-33, started daemon 140320689501952)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-33, started daemon 140320689501952)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9ef446a0d0>
    │    │                                │              │         └ '山东春季苗情好于预期 一、二类苗麦田占比达84%'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9ef446a0d0>
               │    │                        │         └ '山东春季苗情好于预期 一、二类苗麦田占比达84%'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9ed53f4a00>
                   │    │       │                                  │        │           └ '山东春季苗情好于预期 一、二类苗麦田占比达84%'
                   │    │       │                                  │        └ <string.Template object at 0x7f9ed53f4ac0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
                   │    │       └ '求是'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 22, in get_request_from_keyword
    page_json = json.loads(page_response.text[14:-2])
                │    │     │             └ <property object at 0x7f9feccacf90>
                │    │     └ <Response [404]>
                │    └ <function loads at 0x7fa00ed46f70>
                └ <module 'json' from '/usr/lib/python3.8/json/__init__.py'>

  File "/usr/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
           │                │      └ ''
           │                └ <function JSONDecoder.decode at 0x7fa00ed468b0>
           └ <json.decoder.JSONDecoder object at 0x7fa00ed3e760>
  File "/usr/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ ''
               │    │          │      └ <built-in method match of re.Pattern object at 0x7fa00ed69f30>
               │    │          └ ''
               │    └ <function JSONDecoder.raw_decode at 0x7fa00ed46940>
               └ <json.decoder.JSONDecoder object at 0x7fa00ed3e760>
  File "/usr/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
          │                                  └ ''
          └ <class 'json.decoder.JSONDecodeError'>

json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2022-05-12 15:09:26.689 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-37, started daemon 140320188651264)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-37, started daemon 140320188651264)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-37, started daemon 140320188651264)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-37, started daemon 140320188651264)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-37, started daemon 140320188651264)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9ef412c340>
    │    │                                │              │         └ '山东春季苗情好于预期 一、二类苗麦田占比达84%'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9ef412c340>
               │    │                        │         └ '山东春季苗情好于预期 一、二类苗麦田占比达84%'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9eb4ef58b0>
                   │    │       │                                  │        │           └ '山东春季苗情好于预期 一、二类苗麦田占比达84%'
                   │    │       │                                  │        └ <string.Template object at 0x7f9ed5c9efd0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
                   │    │       └ '求是'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 22, in get_request_from_keyword
    page_json = json.loads(page_response.text[14:-2])
                │    │     │             └ <property object at 0x7f9feccacf90>
                │    │     └ <Response [404]>
                │    └ <function loads at 0x7fa00ed46f70>
                └ <module 'json' from '/usr/lib/python3.8/json/__init__.py'>

  File "/usr/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
           │                │      └ ''
           │                └ <function JSONDecoder.decode at 0x7fa00ed468b0>
           └ <json.decoder.JSONDecoder object at 0x7fa00ed3e760>
  File "/usr/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ ''
               │    │          │      └ <built-in method match of re.Pattern object at 0x7fa00ed69f30>
               │    │          └ ''
               │    └ <function JSONDecoder.raw_decode at 0x7fa00ed46940>
               └ <json.decoder.JSONDecoder object at 0x7fa00ed3e760>
  File "/usr/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
          │                                  └ ''
          └ <class 'json.decoder.JSONDecodeError'>

json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2022-05-12 15:09:28.194 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:44 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef4037190>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f9fece5c1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f9fece1f5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ef4387af0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u7f8e\\u836f\\u7ba1\\u5c40\\u56e0\\u8840\\u6813\\u98ce\\u9669\\u9650\\u5236\\u5f3a\\u751f\\u65b0\\u51a0...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f9fece0ff70>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef4037190>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u7f8e\\u836f\\u7ba1\\u5c40\\u56e0\\u8840\\u6813\\u98ce\\u9669\\u9650\\u5236\\u5f3a\\u751f\\u65b0\\u51a0\\u75ab\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f9ef4037190>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u7f8e\\u836f\\u7ba1\\u5c40\\u56e0\\u8840\\u6813\\u98ce\\u9669\\u9650\\u5236\\u5f3a\\u751f\\u65b0\\u51a0\\u75ab\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f9ff00be280>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef4037190>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u7f8e\\u836f\\u7ba1\\u5c40\\u56e0\\u8840\\u6813\\u98ce\\u9669\\u9650\\u5236\\u5f3a\\u751f\\u65b0\\u51a0\\u75ab\\...
    │    └ <function HTTPConnection.endheaders at 0x7f9ff00be160>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef4037190>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u7f8e\\u836f\\u7ba1\\u5c40\\u56e0\\u8840\\u6813\\u98ce\\u9669\\u9650\\u5236\\u5f3a\\u751f\\u65b0\\u51a0\\u75ab\\...
    │    └ <function HTTPConnection._send_output at 0x7f9ffe709d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef4037190>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f9ffe709b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef4037190>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f9fece0fdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef4037190>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f9fece0fc10>
           └ <urllib3.connection.HTTPConnection object at 0x7f9ef4037190>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9ef4037190>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f9fece1f820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ef4387af0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9fece66b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef4037190>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ef4387af0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef4037190>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-136, started daemon 140319248602880)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-136, started daemon 140319248602880)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-136, started daemon 140319248602880)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-136, started daemon 140319248602880)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-136, started daemon 140319248602880)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9e9d450610>
    │    │                                │              │         └ '美药管局因血栓风险限制强生新冠疫苗使用'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9e9d450610>
               │    │                        │         └ '美药管局因血栓风险限制强生新冠疫苗使用'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f9ed5c803a0>
        │          │    │       │                                  │        │           └ '美药管局因血栓风险限制强生新冠疫苗使用'
        │          │    │       │                                  │        └ <string.Template object at 0x7f9ed5eb5ac0>
        │          │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
        │          │    │       └ '人民网'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
        └ <GET http://world.people.com.cn/n1/2022/0415/c1002-32400032.html>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '美药管局因血栓风险限制强生新冠疫苗使用', 'page': 8, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sor...
               │        │    │          └ <function Template.substitute at 0x7fa00ee620d0>
               │        │    └ <string.Template object at 0x7f9ed5eb5ac0>
               │        └ <function post at 0x7f9fecc463a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '美药管局因血栓风险限制强生新冠疫苗使用', 'page': 8, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sor...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9feccb0040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '美药管局因血栓风险限制强生新冠疫苗使用', 'page': 8, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy'...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f9fecc45940>
           └ <requests.sessions.Session object at 0x7f9e9e71a6a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f9fecc45dc0>
           └ <requests.sessions.Session object at 0x7f9e9e71a6a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f9fecc45280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9ed544a490>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef4037190>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:09:28.080 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:44 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f9fece5c1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f9fece1f5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9eb410aa30>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u6210\\u8bed\\u91ca\\u6cd5\\u4e4b\\u5c82\\u6709\\u6b64\\u201c\\u7406\\u201d", "page": 2, "limit": 10, "...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f9fece0ff70>
    └ <urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u6210\\u8bed\\u91ca\\u6cd5\\u4e4b\\u5c82\\u6709\\u6b64\\u201c\\u7406\\u201d", "page": 2, "limit": 10, "hasTitle"...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u6210\\u8bed\\u91ca\\u6cd5\\u4e4b\\u5c82\\u6709\\u6b64\\u201c\\u7406\\u201d", "page": 2, "limit": 10, "hasTitle"...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f9ff00be280>
    └ <urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u6210\\u8bed\\u91ca\\u6cd5\\u4e4b\\u5c82\\u6709\\u6b64\\u201c\\u7406\\u201d", "page": 2, "limit": 10, "hasTitle"...
    │    └ <function HTTPConnection.endheaders at 0x7f9ff00be160>
    └ <urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u6210\\u8bed\\u91ca\\u6cd5\\u4e4b\\u5c82\\u6709\\u6b64\\u201c\\u7406\\u201d", "page": 2, "limit": 10, "hasTitle"...
    │    └ <function HTTPConnection._send_output at 0x7f9ffe709d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f9ffe709b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f9fece0fdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f9fece0fc10>
           └ <urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f9fece1f820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9eb410aa30>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9fece66b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9eb410aa30>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-180, started daemon 140318762579712)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-180, started daemon 140318762579712)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-180, started daemon 140318762579712)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-180, started daemon 140318762579712)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-180, started daemon 140318762579712)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9ed538f9d0>
    │    │                                │              │         └ '成语释法之岂有此“理”'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9ed538f9d0>
               │    │                        │         └ '成语释法之岂有此“理”'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f9e9e39a1c0>
        │          │    │       │                                  │        │           └ '成语释法之岂有此“理”'
        │          │    │       │                                  │        └ <string.Template object at 0x7f9ed416ff10>
        │          │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
        │          │    │       └ '人民网'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
        └ <GET http://society.people.com.cn/n1/2022/0512/c1008-32419860.html>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '成语释法之岂有此“理”', 'page': 2, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': ...
               │        │    │          └ <function Template.substitute at 0x7fa00ee620d0>
               │        │    └ <string.Template object at 0x7f9ed416ff10>
               │        └ <function post at 0x7f9fecc463a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '成语释法之岂有此“理”', 'page': 2, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': ...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9feccb0040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '成语释法之岂有此“理”', 'page': 2, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, ...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f9fecc45940>
           └ <requests.sessions.Session object at 0x7f9e9e432370>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f9fecc45dc0>
           └ <requests.sessions.Session object at 0x7f9e9e432370>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f9fecc45280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9e9e43e8b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9e9e24fc70>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:09:28.228 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:44 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f9fece5c1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f9fece1f5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9eb4e973a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u7f8e\\u56fd\\u662f\\u7978\\u4e71\\u4e16\\u754c\\u7684\\u201c\\u4f0f\\u5730\\u9b54\\u201d", "page": 14,...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f9fece0ff70>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u7f8e\\u56fd\\u662f\\u7978\\u4e71\\u4e16\\u754c\\u7684\\u201c\\u4f0f\\u5730\\u9b54\\u201d", "page": 14, "limit":...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u7f8e\\u56fd\\u662f\\u7978\\u4e71\\u4e16\\u754c\\u7684\\u201c\\u4f0f\\u5730\\u9b54\\u201d", "page": 14, "limit":...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f9ff00be280>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u7f8e\\u56fd\\u662f\\u7978\\u4e71\\u4e16\\u754c\\u7684\\u201c\\u4f0f\\u5730\\u9b54\\u201d", "page": 14, "limit":...
    │    └ <function HTTPConnection.endheaders at 0x7f9ff00be160>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u7f8e\\u56fd\\u662f\\u7978\\u4e71\\u4e16\\u754c\\u7684\\u201c\\u4f0f\\u5730\\u9b54\\u201d", "page": 14, "limit":...
    │    └ <function HTTPConnection._send_output at 0x7f9ffe709d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f9ffe709b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f9fece0fdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f9fece0fc10>
           └ <urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f9fece1f820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9eb4e973a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9fece66b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9eb4e973a0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-75, started daemon 140319668565760)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-75, started daemon 140319668565760)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-75, started daemon 140319668565760)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-75, started daemon 140319668565760)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-75, started daemon 140319668565760)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9ed5f5f070>
    │    │                                │              │         └ '美国是祸乱世界的“伏地魔”'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9ed5f5f070>
               │    │                        │         └ '美国是祸乱世界的“伏地魔”'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f9ef43657c0>
        │          │    │       │                                  │        │           └ '美国是祸乱世界的“伏地魔”'
        │          │    │       │                                  │        └ <string.Template object at 0x7f9e9e76ad00>
        │          │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
        │          │    │       └ '人民网'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
        └ <GET http://v.people.cn/n1/2022/0417/c431206-32401079.html>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '美国是祸乱世界的“伏地魔”', 'page': 14, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType...
               │        │    │          └ <function Template.substitute at 0x7fa00ee620d0>
               │        │    └ <string.Template object at 0x7f9e9e76ad00>
               │        └ <function post at 0x7f9fecc463a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '美国是祸乱世界的“伏地魔”', 'page': 14, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9feccb0040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '美国是祸乱世界的“伏地魔”', 'page': 14, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tru...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f9fecc45940>
           └ <requests.sessions.Session object at 0x7f9eb5cf8880>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f9fecc45dc0>
           └ <requests.sessions.Session object at 0x7f9eb5cf8880>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f9fecc45280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9e9e24fd90>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef42c84f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:09:28.179 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:44 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f9fece5c1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f9fece1f5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9eb5e7f850>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u8fbd\\u5b81\\u7701\\u846b\\u82a6\\u5c9b\\u5e02\\u5728\\u56fd\\u6709\\u4f01\\u4e1a\\u8bd5\\u70b9\\u5efa...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f9fece0ff70>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u8fbd\\u5b81\\u7701\\u846b\\u82a6\\u5c9b\\u5e02\\u5728\\u56fd\\u6709\\u4f01\\u4e1a\\u8bd5\\u70b9\\u5efa\\u8bbe\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u8fbd\\u5b81\\u7701\\u846b\\u82a6\\u5c9b\\u5e02\\u5728\\u56fd\\u6709\\u4f01\\u4e1a\\u8bd5\\u70b9\\u5efa\\u8bbe\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f9ff00be280>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u8fbd\\u5b81\\u7701\\u846b\\u82a6\\u5c9b\\u5e02\\u5728\\u56fd\\u6709\\u4f01\\u4e1a\\u8bd5\\u70b9\\u5efa\\u8bbe\\...
    │    └ <function HTTPConnection.endheaders at 0x7f9ff00be160>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u8fbd\\u5b81\\u7701\\u846b\\u82a6\\u5c9b\\u5e02\\u5728\\u56fd\\u6709\\u4f01\\u4e1a\\u8bd5\\u70b9\\u5efa\\u8bbe\\...
    │    └ <function HTTPConnection._send_output at 0x7f9ffe709d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f9ffe709b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f9fece0fdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f9fece0fc10>
           └ <urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f9fece1f820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9eb5e7f850>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9fece66b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9eb5e7f850>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-160, started daemon 140318796150528)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-160, started daemon 140318796150528)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-160, started daemon 140318796150528)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-160, started daemon 140318796150528)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-160, started daemon 140318796150528)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9eb500ba00>
    │    │                                │              │         └ '辽宁省葫芦岛市在国有企业试点建设退役军人服务中心'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9eb500ba00>
               │    │                        │         └ '辽宁省葫芦岛市在国有企业试点建设退役军人服务中心'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f9eb5ce1550>
        │          │    │       │                                  │        │           └ '辽宁省葫芦岛市在国有企业试点建设退役军人服务中心'
        │          │    │       │                                  │        └ <string.Template object at 0x7f9ed5e6dac0>
        │          │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
        │          │    │       └ '人民网'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
        └ <GET http://military.people.com.cn/n1/2022/0509/c1011-32417127.html>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '辽宁省葫芦岛市在国有企业试点建设退役军人服务中心', 'page': 9, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0,...
               │        │    │          └ <function Template.substitute at 0x7fa00ee620d0>
               │        │    └ <string.Template object at 0x7f9ed5e6dac0>
               │        └ <function post at 0x7f9fecc463a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '辽宁省葫芦岛市在国有企业试点建设退役军人服务中心', 'page': 9, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0,...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9feccb0040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '辽宁省葫芦岛市在国有企业试点建设退役军人服务中心', 'page': 9, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isF...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f9fecc45940>
           └ <requests.sessions.Session object at 0x7f9eb40b27c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f9fecc45dc0>
           └ <requests.sessions.Session object at 0x7f9eb40b27c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f9fecc45280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9e9e677f10>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef416ae50>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:09:32.151 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:44 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f9fece5c1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f9fece1f5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9eb5efbc10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u5168\\u7403\\u7d2f\\u8ba1\\u65b0\\u51a0\\u786e\\u8bca\\u75c5\\u4f8b...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f9fece0ff70>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u5168\\u7403\\u7d2f\\u8ba1\\u65b0\\u51a0\\u786e\\u8bca\\u75c5\\u4f8b\\u8fbe51...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u5168\\u7403\\u7d2f\\u8ba1\\u65b0\\u51a0\\u786e\\u8bca\\u75c5\\u4f8b\\u8fbe51...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f9ff00be280>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u5168\\u7403\\u7d2f\\u8ba1\\u65b0\\u51a0\\u786e\\u8bca\\u75c5\\u4f8b\\u8fbe51...
    │    └ <function HTTPConnection.endheaders at 0x7f9ff00be160>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u5168\\u7403\\u7d2f\\u8ba1\\u65b0\\u51a0\\u786e\\u8bca\\u75c5\\u4f8b\\u8fbe51...
    │    └ <function HTTPConnection._send_output at 0x7f9ffe709d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f9ffe709b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f9fece0fdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f9fece0fc10>
           └ <urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f9fece1f820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9eb5efbc10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9fece66b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9eb5efbc10>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-33, started daemon 140320689501952)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-33, started daemon 140320689501952)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-33, started daemon 140320689501952)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-33, started daemon 140320689501952)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-33, started daemon 140320689501952)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9ef446a0d0>
    │    │                                │              │         └ '世卫组织：全球累计新冠确诊病例达512607587例'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9ef446a0d0>
               │    │                        │         └ '世卫组织：全球累计新冠确诊病例达512607587例'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9ef405f9a0>
                   │    │       │                                  │        │           └ '世卫组织：全球累计新冠确诊病例达512607587例'
                   │    │       │                                  │        └ <string.Template object at 0x7f9eb5bb3a90>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '世卫组织：全球累计新冠确诊病例达512607587例', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': ...
               │        │    │          └ <function Template.substitute at 0x7fa00ee620d0>
               │        │    └ <string.Template object at 0x7f9eb5bb3a90>
               │        └ <function post at 0x7f9fecc463a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '世卫组织：全球累计新冠确诊病例达512607587例', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': ...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9feccb0040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '世卫组织：全球累计新冠确诊病例达512607587例', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'i...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f9fecc45940>
           └ <requests.sessions.Session object at 0x7f9ed5d038e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f9fecc45dc0>
           └ <requests.sessions.Session object at 0x7f9ed5d038e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f9fecc45280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9eb4e0a070>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ed5ef5c40>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:09:33.711 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:44 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f9fece5c1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f9fece1f5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ed5f9d970>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u5168\\u7403\\u7d2f\\u8ba1\\u65b0\\u51a0\\u786e\\u8bca\\u75c5\\u4f8b...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f9fece0ff70>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u5168\\u7403\\u7d2f\\u8ba1\\u65b0\\u51a0\\u786e\\u8bca\\u75c5\\u4f8b\\u8fbe51...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u5168\\u7403\\u7d2f\\u8ba1\\u65b0\\u51a0\\u786e\\u8bca\\u75c5\\u4f8b\\u8fbe51...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f9ff00be280>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u5168\\u7403\\u7d2f\\u8ba1\\u65b0\\u51a0\\u786e\\u8bca\\u75c5\\u4f8b\\u8fbe51...
    │    └ <function HTTPConnection.endheaders at 0x7f9ff00be160>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u5168\\u7403\\u7d2f\\u8ba1\\u65b0\\u51a0\\u786e\\u8bca\\u75c5\\u4f8b\\u8fbe51...
    │    └ <function HTTPConnection._send_output at 0x7f9ffe709d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f9ffe709b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f9fece0fdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f9fece0fc10>
           └ <urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f9fece1f820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ed5f9d970>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9fece66b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ed5f9d970>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-37, started daemon 140320188651264)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-37, started daemon 140320188651264)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-37, started daemon 140320188651264)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-37, started daemon 140320188651264)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-37, started daemon 140320188651264)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9ef412c340>
    │    │                                │              │         └ '世卫组织：全球累计新冠确诊病例达512607587例'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9ef412c340>
               │    │                        │         └ '世卫组织：全球累计新冠确诊病例达512607587例'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9eb5047520>
                   │    │       │                                  │        │           └ '世卫组织：全球累计新冠确诊病例达512607587例'
                   │    │       │                                  │        └ <string.Template object at 0x7f9eb5047610>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '世卫组织：全球累计新冠确诊病例达512607587例', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': ...
               │        │    │          └ <function Template.substitute at 0x7fa00ee620d0>
               │        │    └ <string.Template object at 0x7f9eb5047610>
               │        └ <function post at 0x7f9fecc463a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '世卫组织：全球累计新冠确诊病例达512607587例', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': ...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9feccb0040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '世卫组织：全球累计新冠确诊病例达512607587例', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'i...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f9fecc45940>
           └ <requests.sessions.Session object at 0x7f9eb529b5e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f9fecc45dc0>
           └ <requests.sessions.Session object at 0x7f9eb529b5e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f9fecc45280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9ef4467970>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ed535bfd0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:09:39.298 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:44 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f9fece5c1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f9fece1f5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ef4176880>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u611f\\u89c9\\u4e0d\\u9519\\uff01\\u975e\\u6d32\\u7559\\u5b66\\u751f\\u76f4\\u64ad\\u5e26\\u8d27\\u521d...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f9fece0ff70>
    └ <urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u611f\\u89c9\\u4e0d\\u9519\\uff01\\u975e\\u6d32\\u7559\\u5b66\\u751f\\u76f4\\u64ad\\u5e26\\u8d27\\u521d\\u4f53\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u611f\\u89c9\\u4e0d\\u9519\\uff01\\u975e\\u6d32\\u7559\\u5b66\\u751f\\u76f4\\u64ad\\u5e26\\u8d27\\u521d\\u4f53\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f9ff00be280>
    └ <urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u611f\\u89c9\\u4e0d\\u9519\\uff01\\u975e\\u6d32\\u7559\\u5b66\\u751f\\u76f4\\u64ad\\u5e26\\u8d27\\u521d\\u4f53\\...
    │    └ <function HTTPConnection.endheaders at 0x7f9ff00be160>
    └ <urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u611f\\u89c9\\u4e0d\\u9519\\uff01\\u975e\\u6d32\\u7559\\u5b66\\u751f\\u76f4\\u64ad\\u5e26\\u8d27\\u521d\\u4f53\\...
    │    └ <function HTTPConnection._send_output at 0x7f9ffe709d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f9ffe709b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f9fece0fdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f9fece0fc10>
           └ <urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f9fece1f820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ef4176880>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9fece66b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ef4176880>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-213, started daemon 140318158599936)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-213, started daemon 140318158599936)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-213, started daemon 140318158599936)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-213, started daemon 140318158599936)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-213, started daemon 140318158599936)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9eb5d6e940>
    │    │                                │              │         └ '感觉不错！非洲留学生直播带货初体验'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9eb5d6e940>
               │    │                        │         └ '感觉不错！非洲留学生直播带货初体验'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9eb5ee1550>
                   │    │       │                                  │        │           └ '感觉不错！非洲留学生直播带货初体验'
                   │    │       │                                  │        └ <string.Template object at 0x7f9eb4154b80>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '感觉不错！非洲留学生直播带货初体验', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortT...
               │        │    │          └ <function Template.substitute at 0x7fa00ee620d0>
               │        │    └ <string.Template object at 0x7f9eb4154b80>
               │        └ <function post at 0x7f9fecc463a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '感觉不错！非洲留学生直播带货初体验', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortT...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9feccb0040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '感觉不错！非洲留学生直播带货初体验', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': ...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f9fecc45940>
           └ <requests.sessions.Session object at 0x7f9e9e6b5ca0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f9fecc45dc0>
           └ <requests.sessions.Session object at 0x7f9e9e6b5ca0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f9fecc45280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9ed5f6ebb0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9eb4c0e7c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:09:45.383 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:44 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef424b430>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f9fece5c1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f9fece1f5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ed5d48bb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u4e2d\\u56fd\\u7b2c8\\u6279\\u8d74\\u5357\\u82cf\\u4e39\\u7ef4\\u548c\\u6b65\\u5175\\u8425\\u9ad8\\u680...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f9fece0ff70>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef424b430>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u4e2d\\u56fd\\u7b2c8\\u6279\\u8d74\\u5357\\u82cf\\u4e39\\u7ef4\\u548c\\u6b65\\u5175\\u8425\\u9ad8\\u6807\\u51c6\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f9ef424b430>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u4e2d\\u56fd\\u7b2c8\\u6279\\u8d74\\u5357\\u82cf\\u4e39\\u7ef4\\u548c\\u6b65\\u5175\\u8425\\u9ad8\\u6807\\u51c6\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f9ff00be280>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef424b430>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u4e2d\\u56fd\\u7b2c8\\u6279\\u8d74\\u5357\\u82cf\\u4e39\\u7ef4\\u548c\\u6b65\\u5175\\u8425\\u9ad8\\u6807\\u51c6\...
    │    └ <function HTTPConnection.endheaders at 0x7f9ff00be160>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef424b430>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u4e2d\\u56fd\\u7b2c8\\u6279\\u8d74\\u5357\\u82cf\\u4e39\\u7ef4\\u548c\\u6b65\\u5175\\u8425\\u9ad8\\u6807\\u51c6\...
    │    └ <function HTTPConnection._send_output at 0x7f9ffe709d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef424b430>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f9ffe709b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef424b430>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f9fece0fdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ef424b430>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f9fece0fc10>
           └ <urllib3.connection.HTTPConnection object at 0x7f9ef424b430>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9ef424b430>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f9fece1f820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ed5d48bb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9fece66b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef424b430>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ed5d48bb0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef424b430>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-190, started daemon 140318745794304)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-190, started daemon 140318745794304)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-190, started daemon 140318745794304)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-190, started daemon 140318745794304)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-190, started daemon 140318745794304)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9e9e5a38b0>
    │    │                                │              │         └ '中国第8批赴南苏丹维和步兵营高标准通过联合国装备核查'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9e9e5a38b0>
               │    │                        │         └ '中国第8批赴南苏丹维和步兵营高标准通过联合国装备核查'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9eb4d49730>
                   │    │       │                                  │        │           └ '中国第8批赴南苏丹维和步兵营高标准通过联合国装备核查'
                   │    │       │                                  │        └ <string.Template object at 0x7f9eb5d41b80>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '中国第8批赴南苏丹维和步兵营高标准通过联合国装备核查', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': ...
               │        │    │          └ <function Template.substitute at 0x7fa00ee620d0>
               │        │    └ <string.Template object at 0x7f9eb5d41b80>
               │        └ <function post at 0x7f9fecc463a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '中国第8批赴南苏丹维和步兵营高标准通过联合国装备核查', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': ...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9feccb0040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '中国第8批赴南苏丹维和步兵营高标准通过联合国装备核查', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'i...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f9fecc45940>
           └ <requests.sessions.Session object at 0x7f9e9e5eac10>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f9fecc45dc0>
           └ <requests.sessions.Session object at 0x7f9e9e5eac10>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f9fecc45280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9ed5f79670>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ef424b430>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:09:45.593 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:44 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f9fece5c1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f9fece1f5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9e9e460490>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u5065\\u5168\\u4f53\\u7cfb\\u57f9\\u517b\\u5fc3\\u7406\\u670d\\u52a1\\u4eba\\u624d", "page": 1, "limit"...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f9fece0ff70>
    └ <urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u5065\\u5168\\u4f53\\u7cfb\\u57f9\\u517b\\u5fc3\\u7406\\u670d\\u52a1\\u4eba\\u624d", "page": 1, "limit": 10, "ha...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u5065\\u5168\\u4f53\\u7cfb\\u57f9\\u517b\\u5fc3\\u7406\\u670d\\u52a1\\u4eba\\u624d", "page": 1, "limit": 10, "ha...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f9ff00be280>
    └ <urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u5065\\u5168\\u4f53\\u7cfb\\u57f9\\u517b\\u5fc3\\u7406\\u670d\\u52a1\\u4eba\\u624d", "page": 1, "limit": 10, "ha...
    │    └ <function HTTPConnection.endheaders at 0x7f9ff00be160>
    └ <urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u5065\\u5168\\u4f53\\u7cfb\\u57f9\\u517b\\u5fc3\\u7406\\u670d\\u52a1\\u4eba\\u624d", "page": 1, "limit": 10, "ha...
    │    └ <function HTTPConnection._send_output at 0x7f9ffe709d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f9ffe709b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f9fece0fdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f9fece0fc10>
           └ <urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f9fece1f820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9e9e460490>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9fece66b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9e9e460490>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-165, started daemon 140318787757824)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-165, started daemon 140318787757824)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-165, started daemon 140318787757824)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-165, started daemon 140318787757824)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-165, started daemon 140318787757824)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9ed53d16a0>
    │    │                                │              │         └ '健全体系培养心理服务人才'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9ed53d16a0>
               │    │                        │         └ '健全体系培养心理服务人才'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9ed5dd3880>
                   │    │       │                                  │        │           └ '健全体系培养心理服务人才'
                   │    │       │                                  │        └ <string.Template object at 0x7f9eb5ecabe0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '健全体系培养心理服务人才', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType':...
               │        │    │          └ <function Template.substitute at 0x7fa00ee620d0>
               │        │    └ <string.Template object at 0x7f9eb5ecabe0>
               │        └ <function post at 0x7f9fecc463a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '健全体系培养心理服务人才', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType':...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9feccb0040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '健全体系培养心理服务人才', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True,...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f9fecc45940>
           └ <requests.sessions.Session object at 0x7f9e9e5707f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f9fecc45dc0>
           └ <requests.sessions.Session object at 0x7f9e9e5707f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f9fecc45280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9eb4fcbdf0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9eb5f84130>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-12 15:09:45.633 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:44 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f9fece5c1f0>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f9fece1f5e0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ed5e26610>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u5df4\\u62ff\\u9a6c\\u52a0\\u5f3a\\u6d77\\u6d0b\\u751f\\u6001\\u7cfb\\u7edf\\u4fdd\\u62a4", "page": 1, ...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f9fece0ff70>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
          │               │             │       │         └ b'{"key": "\\u5df4\\u62ff\\u9a6c\\u52a0\\u5f3a\\u6d77\\u6d0b\\u751f\\u6001\\u7cfb\\u7edf\\u4fdd\\u62a4", "page": 1, "limit": ...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/...
    │    │             │       │    └ b'{"key": "\\u5df4\\u62ff\\u9a6c\\u52a0\\u5f3a\\u6d77\\u6d0b\\u751f\\u6001\\u7cfb\\u7edf\\u4fdd\\u62a4", "page": 1, "limit": ...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f9ff00be280>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u5df4\\u62ff\\u9a6c\\u52a0\\u5f3a\\u6d77\\u6d0b\\u751f\\u6001\\u7cfb\\u7edf\\u4fdd\\u62a4", "page": 1, "limit": ...
    │    └ <function HTTPConnection.endheaders at 0x7f9ff00be160>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u5df4\\u62ff\\u9a6c\\u52a0\\u5f3a\\u6d77\\u6d0b\\u751f\\u6001\\u7cfb\\u7edf\\u4fdd\\u62a4", "page": 1, "limit": ...
    │    └ <function HTTPConnection._send_output at 0x7f9ffe709d30>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f9ffe709b80>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f9fece0fdc0>
    └ <urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f9fece0fc10>
           └ <urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f9fece1f820>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ed5e26610>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f9fece66b80>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9ed5e26610>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa00ee79a60>
    └ <Thread(Thread-75, started daemon 140319668565760)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa00ee79790>
    └ <Thread(Thread-75, started daemon 140319668565760)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-75, started daemon 140319668565760)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-75, started daemon 140319668565760)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>>
    └ <Thread(Thread-75, started daemon 140319668565760)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 795, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f9ef73a2040>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>
    └ <monitor.projectManager.ProjectManager object at 0x7f9ef739e2e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f9ef70e43d0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f9ed5f5f070>
    │    │                                │              │         └ '巴拿马加强海洋生态系统保护'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f9ef73a20d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 134, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f9fef2fb550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f9ed5f5f070>
               │    │                        │         └ '巴拿马加强海洋生态系统保护'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f9ef73a21f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 191, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f9ed4153e80>
                   │    │       │                                  │        │           └ '巴拿马加强海洋生态系统保护'
                   │    │       │                                  │        └ <string.Template object at 0x7f9ed42ac730>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f9ef6fafaf0>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f9ef6faf6d0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 28, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '巴拿马加强海洋生态系统保护', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType'...
               │        │    │          └ <function Template.substitute at 0x7fa00ee620d0>
               │        │    └ <string.Template object at 0x7f9ed42ac730>
               │        └ <function post at 0x7f9fecc463a0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '巴拿马加强海洋生态系统保护', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType'...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f9feccb0040>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '巴拿马加强海洋生态系统保护', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f9fecc45940>
           └ <requests.sessions.Session object at 0x7f9ef40373a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f9fecc45dc0>
           └ <requests.sessions.Session object at 0x7f9ef40373a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f9fecc45280>
        └ <requests.adapters.HTTPAdapter object at 0x7f9ef4196070>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9ed416f8e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
