2022-06-08 11:17:20.647 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%258F%25A4%25E7%2589%25B9%25E9%259B%25B7%25E6%2596%25AF%25E5%2591%25BC%25E5%2590%2581%25E5%25B0%2586%25E4%25BF%2584%25E4%25B9%258C%25E5%2586%259C%25E4%25B8%259A%25E7%2594%259F%25E4%25BA%25A7%25E9%2587%258D%25E6%2596%25B0%25E7%25BA%25B3%25E5%2585%25A5%25E4%25B8%2596%25E7%2595%258C%25E5%25B8%2582%25E5%259C%25BA%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D2&timestamp=1654658240&signature=cd53e4dbdd0b3bc1d9c0a56a80fab62b (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fddf02dcbe0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fde70045b20>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fddf02dcbe0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fde70045b20>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fde70045b20>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fde3028d740>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fde3028d740>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fddf02dcbe0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fddf02dcbe0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%258F%25A4%25E7%2589%25B9%25E9%259B%25B7%25E6%2596%25AF%25E5%2591%25BC%25E5%2590%2581%25E5%25B0%2586%25E4%25BF%2584%25E4%25B9%258C%25E5%2586%259C%25E4%25B8%259A%25E7%2594%259F%25E4%25BA%25A7%25E9%2587%258D%25E6%2596%25B0%25E7%25BA%25B3%25E5%2585%25A5%25E4%25B8%2596%25E7%2595%258C%25E5%25B8%2582%25E5%259C%25BA%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D2&timestamp=1654658240&signature=cd53e4dbdd0b3bc1d9c0a56a80fab62b (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-22201, started daemon 140587571726080)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-22201, started daemon 140587571726080)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-22201, started daemon 140587571726080)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-22201, started daemon 140587571726080)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-22201, started daemon 140587571726080)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fdce12c7d30>
    │    │                                │              │         └ '古特雷斯呼吁将俄乌农业生产重新纳入世界市场'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fdce12c7d30>
               │    │                        │         └ '古特雷斯呼吁将俄乌农业生产重新纳入世界市场'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '古特雷斯呼吁将俄乌农业生产重新纳入世界市场'
                   │    │       │                                  │        └ <string.Template object at 0x7fe06005d400>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=古特雷斯呼吁将俄乌农业生产重新纳入世界市场&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=2'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=古特雷斯呼吁将俄乌农业生产重新纳入世界市场&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=2'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=古特雷斯呼吁将俄乌农业生产重新纳入世界市场&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=2'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fde706e58b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde706e58b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fe060088f20>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde706e58b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdda273dd30>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%258F%25A4%25E7%2589%25B9%25E9%259B%25B7%25E6%2596%25AF%25E5%2591%25BC%25E5%2590%2581%25E5%25B0%2586%25E4%25BF%2584%25E4%25B9%258C%25E5%2586%259C%25E4%25B8%259A%25E7%2594%259F%25E4%25BA%25A7%25E9%2587%258D%25E6%2596%25B0%25E7%25BA%25B3%25E5%2585%25A5%25E4%25B8%2596%25E7%2595%258C%25E5%25B8%2582%25E5%259C%25BA%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D2&timestamp=1654658240&signature=cd53e4dbdd0b3bc1d9c0a56a80fab62b (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 11:38:40.856 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%2597%25A5%25E6%259C%25AC%25E7%25A0%2594%25E7%25A9%25B6%25E5%258F%2591%25E7%258E%25B0%25E5%25B0%258F%25E8%25A1%258C%25E6%2598%259F%25E6%25A0%25B7%25E6%259C%25AC%25E4%25B8%25AD%25E5%25AD%2598%25E5%259C%25A8%25E5%25A4%259A%25E7%25A7%258D%25E6%25B0%25A8%25E5%259F%25BA%25E9%2585%25B8%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D22&timestamp=1654659520&signature=9b4b6c72c7ae1300f0ec447548d3ba27 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdef063e820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fde50d2e700>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdef063e820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fde50d2e700>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fde50d2e700>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdf5435c7c0>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdf5435c7c0>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdef063e820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdef063e820>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%2597%25A5%25E6%259C%25AC%25E7%25A0%2594%25E7%25A9%25B6%25E5%258F%2591%25E7%258E%25B0%25E5%25B0%258F%25E8%25A1%258C%25E6%2598%259F%25E6%25A0%25B7%25E6%259C%25AC%25E4%25B8%25AD%25E5%25AD%2598%25E5%259C%25A8%25E5%25A4%259A%25E7%25A7%258D%25E6%25B0%25A8%25E5%259F%25BA%25E9%2585%25B8%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D22&timestamp=1654659520&signature=9b4b6c72c7ae1300f0ec447548d3ba27 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-24994, started daemon 140588891723520)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-24994, started daemon 140588891723520)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-24994, started daemon 140588891723520)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-24994, started daemon 140588891723520)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-24994, started daemon 140588891723520)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fde1046be20>
    │    │                                │              │         └ '日本研究发现小行星样本中存在多种氨基酸'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fde1046be20>
               │    │                        │         └ '日本研究发现小行星样本中存在多种氨基酸'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '日本研究发现小行星样本中存在多种氨基酸'
                   │    │       │                                  │        └ <string.Template object at 0x7fde50d7d9d0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=日本研究发现小行星样本中存在多种氨基酸&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=22'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=日本研究发现小行星样本中存在多种氨基酸&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=22'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=日本研究发现小行星样本中存在多种氨基酸&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=22'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fde901964c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde901964c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fe0605790b0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde901964c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdd3a82f520>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%2597%25A5%25E6%259C%25AC%25E7%25A0%2594%25E7%25A9%25B6%25E5%258F%2591%25E7%258E%25B0%25E5%25B0%258F%25E8%25A1%258C%25E6%2598%259F%25E6%25A0%25B7%25E6%259C%25AC%25E4%25B8%25AD%25E5%25AD%2598%25E5%259C%25A8%25E5%25A4%259A%25E7%25A7%258D%25E6%25B0%25A8%25E5%259F%25BA%25E9%2585%25B8%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D22&timestamp=1654659520&signature=9b4b6c72c7ae1300f0ec447548d3ba27 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 11:41:30.233 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E8%25A5%2584%25E9%2598%25B3%25E6%25A8%258A%25E5%259F%258E%25E5%258C%25BA%25E6%25B3%2595%25E9%2599%25A2%25EF%25BC%259A%25E2%2580%259C%25E9%25A2%2584%25E5%2591%258A%25E5%25A4%2584%25E7%25BD%259A%25E2%2580%259D%25E7%25A0%25B4%25E8%25A7%25A3%25E6%2589%25A7%25E8%25A1%258C%25E5%2583%25B5%25E5%25B1%2580%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D14&timestamp=1654659690&signature=283f81e8cd22e66c961a6f573ee9dc64 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fde504efc40>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fded0518c10>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fde504efc40>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fded0518c10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fded0518c10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdce85d21c0>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdce85d21c0>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fde504efc40>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fde504efc40>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E8%25A5%2584%25E9%2598%25B3%25E6%25A8%258A%25E5%259F%258E%25E5%258C%25BA%25E6%25B3%2595%25E9%2599%25A2%25EF%25BC%259A%25E2%2580%259C%25E9%25A2%2584%25E5%2591%258A%25E5%25A4%2584%25E7%25BD%259A%25E2%2580%259D%25E7%25A0%25B4%25E8%25A7%25A3%25E6%2589%25A7%25E8%25A1%258C%25E5%2583%25B5%25E5%25B1%2580%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D14&timestamp=1654659690&signature=283f81e8cd22e66c961a6f573ee9dc64 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-23869, started daemon 140588175988480)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-23869, started daemon 140588175988480)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-23869, started daemon 140588175988480)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-23869, started daemon 140588175988480)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-23869, started daemon 140588175988480)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fdf3025f8b0>
    │    │                                │              │         └ '襄阳樊城区法院：“预告处罚”破解执行僵局'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fdf3025f8b0>
               │    │                        │         └ '襄阳樊城区法院：“预告处罚”破解执行僵局'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '襄阳樊城区法院：“预告处罚”破解执行僵局'
                   │    │       │                                  │        └ <string.Template object at 0x7fdd1e9bdc70>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=襄阳樊城区法院：“预告处罚”破解执行僵局&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=14'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=襄阳樊城区法院：“预告处罚”破解执行僵局&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=14'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=襄阳樊城区法院：“预告处罚”破解执行僵局&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=14'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fde700e5b50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde700e5b50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdf10740200>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde700e5b50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdef072eb20>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E8%25A5%2584%25E9%2598%25B3%25E6%25A8%258A%25E5%259F%258E%25E5%258C%25BA%25E6%25B3%2595%25E9%2599%25A2%25EF%25BC%259A%25E2%2580%259C%25E9%25A2%2584%25E5%2591%258A%25E5%25A4%2584%25E7%25BD%259A%25E2%2580%259D%25E7%25A0%25B4%25E8%25A7%25A3%25E6%2589%25A7%25E8%25A1%258C%25E5%2583%25B5%25E5%25B1%2580%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D14&timestamp=1654659690&signature=283f81e8cd22e66c961a6f573ee9dc64 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 12:10:20.697 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E3%2580%2590%25E7%25BB%2584%25E5%259B%25BE%25E3%2580%2591%25E2%2580%259C%25E5%25BA%2594%25E6%2580%25A5%25E4%25BD%25BF%25E5%2591%25BD%25C2%25B72022%25E2%2580%259D%25E9%25AB%2598%25E5%258E%259F%25E9%25AB%2598%25E5%25AF%2592%25E5%259C%25B0%25E5%258C%25BA%25E6%258A%2597%25E9%259C%2587%25E6%2595%2591%25E7%2581%25BE%25E5%25AE%259E%25E6%2588%2598%25E5%258C%2596%25E6%25BC%2594%25E4%25B9%25A0%25E4%25B8%25BE%25E8%25A1%258C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D3&timestamp=1654661420&signature=c567dabb09e66af5d796a7ee9a95c91f (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdcf0a87c10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fdd48a8bcd0>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdcf0a87c10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fdd48a8bcd0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fdd48a8bcd0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdd27efeec0>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdd27efeec0>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdcf0a87c10>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdcf0a87c10>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E3%2580%2590%25E7%25BB%2584%25E5%259B%25BE%25E3%2580%2591%25E2%2580%259C%25E5%25BA%2594%25E6%2580%25A5%25E4%25BD%25BF%25E5%2591%25BD%25C2%25B72022%25E2%2580%259D%25E9%25AB%2598%25E5%258E%259F%25E9%25AB%2598%25E5%25AF%2592%25E5%259C%25B0%25E5%258C%25BA%25E6%258A%2597%25E9%259C%2587%25E6%2595%2591%25E7%2581%25BE%25E5%25AE%259E%25E6%2588%2598%25E5%258C%2596%25E6%25BC%2594%25E4%25B9%25A0%25E4%25B8%25BE%25E8%25A1%258C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D3&timestamp=1654661420&signature=c567dabb09e66af5d796a7ee9a95c91f (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-24808, started daemon 140589898848000)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-24808, started daemon 140589898848000)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-24808, started daemon 140589898848000)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-24808, started daemon 140589898848000)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-24808, started daemon 140589898848000)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fdd3a878670>
    │    │                                │              │         └ '【组图】“应急使命·2022”高原高寒地区抗震救灾实战化演习举行'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fdd3a878670>
               │    │                        │         └ '【组图】“应急使命·2022”高原高寒地区抗震救灾实战化演习举行'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '【组图】“应急使命·2022”高原高寒地区抗震救灾实战化演习举行'
                   │    │       │                                  │        └ <string.Template object at 0x7fddd03e0d90>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=【组图】“应急使命·2022”高原高寒地区抗震救灾实战化演习举行&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=3'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=【组图】“应急使命·2022”高原高寒地区抗震救灾实战化演习举行&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=3'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=【组图】“应急使命·2022”高原高寒地区抗震救灾实战化演习举行&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=3'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fdcf0a78880>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdcf0a78880>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdef033c2e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdcf0a78880>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdd0e7450a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E3%2580%2590%25E7%25BB%2584%25E5%259B%25BE%25E3%2580%2591%25E2%2580%259C%25E5%25BA%2594%25E6%2580%25A5%25E4%25BD%25BF%25E5%2591%25BD%25C2%25B72022%25E2%2580%259D%25E9%25AB%2598%25E5%258E%259F%25E9%25AB%2598%25E5%25AF%2592%25E5%259C%25B0%25E5%258C%25BA%25E6%258A%2597%25E9%259C%2587%25E6%2595%2591%25E7%2581%25BE%25E5%25AE%259E%25E6%2588%2598%25E5%258C%2596%25E6%25BC%2594%25E4%25B9%25A0%25E4%25B8%25BE%25E8%25A1%258C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D3&timestamp=1654661420&signature=c567dabb09e66af5d796a7ee9a95c91f (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 12:15:30.552 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25A4%2596%25E4%25BA%25A4%25E9%2583%25A8%25EF%25BC%259A%25E5%259C%25A8%25E5%2590%2584%25E6%2596%25B9%25E8%25BE%25BE%25E6%2588%2590%25E5%2585%25B1%25E8%25AF%2586%25E4%25B9%258B%25E5%2589%258D%25E7%25BE%258E%25E8%258B%25B1%25E6%25BE%25B3%25E4%25B8%258D%25E5%25BA%2594%25E5%25BC%2580%25E5%25B1%2595%25E6%25A0%25B8%25E6%25BD%259C%25E8%2589%2587%25E5%2590%2588%25E4%25BD%259C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D4&timestamp=1654661730&signature=d98d9918031ddc02606e4a3bfc563ce3 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdccc545400>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fdd3a92de80>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdccc545400>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fdd3a92de80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fdd3a92de80>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdd23e730c0>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdd23e730c0>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdccc545400>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdccc545400>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25A4%2596%25E4%25BA%25A4%25E9%2583%25A8%25EF%25BC%259A%25E5%259C%25A8%25E5%2590%2584%25E6%2596%25B9%25E8%25BE%25BE%25E6%2588%2590%25E5%2585%25B1%25E8%25AF%2586%25E4%25B9%258B%25E5%2589%258D%25E7%25BE%258E%25E8%258B%25B1%25E6%25BE%25B3%25E4%25B8%258D%25E5%25BA%2594%25E5%25BC%2580%25E5%25B1%2595%25E6%25A0%25B8%25E6%25BD%259C%25E8%2589%2587%25E5%2590%2588%25E4%25BD%259C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D4&timestamp=1654661730&signature=d98d9918031ddc02606e4a3bfc563ce3 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-25770, started daemon 140587003913984)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-25770, started daemon 140587003913984)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-25770, started daemon 140587003913984)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-25770, started daemon 140587003913984)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-25770, started daemon 140587003913984)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fdda23a8970>
    │    │                                │              │         └ '外交部：在各方达成共识之前美英澳不应开展核潜艇合作'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fdda23a8970>
               │    │                        │         └ '外交部：在各方达成共识之前美英澳不应开展核潜艇合作'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '外交部：在各方达成共识之前美英澳不应开展核潜艇合作'
                   │    │       │                                  │        └ <string.Template object at 0x7fdf54402670>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=外交部：在各方达成共识之前美英澳不应开展核潜艇合作&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=4'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=外交部：在各方达成共识之前美英澳不应开展核潜艇合作&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=4'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=外交部：在各方达成共识之前美英澳不应开展核潜艇合作&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=4'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fdce23c43a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdce23c43a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fddf0325200>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdce23c43a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdd0c427250>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25A4%2596%25E4%25BA%25A4%25E9%2583%25A8%25EF%25BC%259A%25E5%259C%25A8%25E5%2590%2584%25E6%2596%25B9%25E8%25BE%25BE%25E6%2588%2590%25E5%2585%25B1%25E8%25AF%2586%25E4%25B9%258B%25E5%2589%258D%25E7%25BE%258E%25E8%258B%25B1%25E6%25BE%25B3%25E4%25B8%258D%25E5%25BA%2594%25E5%25BC%2580%25E5%25B1%2595%25E6%25A0%25B8%25E6%25BD%259C%25E8%2589%2587%25E5%2590%2588%25E4%25BD%259C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D4&timestamp=1654661730&signature=d98d9918031ddc02606e4a3bfc563ce3 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 12:26:10.138 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25A4%2596%25E4%25BA%25A4%25E9%2583%25A8%25EF%25BC%259A%25E5%259C%25A8%25E5%2590%2584%25E6%2596%25B9%25E8%25BE%25BE%25E6%2588%2590%25E5%2585%25B1%25E8%25AF%2586%25E4%25B9%258B%25E5%2589%258D%25E7%25BE%258E%25E8%258B%25B1%25E6%25BE%25B3%25E4%25B8%258D%25E5%25BA%2594%25E5%25BC%2580%25E5%25B1%2595%25E6%25A0%25B8%25E6%25BD%259C%25E8%2589%2587%25E5%2590%2588%25E4%25BD%259C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D24&timestamp=1654662370&signature=64cb9bbae5d1bc24a6a1e3185ac64eec (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdf542d0040>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fdd4ad1cfd0>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdf542d0040>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fdd4ad1cfd0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fdd4ad1cfd0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdd0f11f440>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdd0f11f440>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdf542d0040>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdf542d0040>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25A4%2596%25E4%25BA%25A4%25E9%2583%25A8%25EF%25BC%259A%25E5%259C%25A8%25E5%2590%2584%25E6%2596%25B9%25E8%25BE%25BE%25E6%2588%2590%25E5%2585%25B1%25E8%25AF%2586%25E4%25B9%258B%25E5%2589%258D%25E7%25BE%258E%25E8%258B%25B1%25E6%25BE%25B3%25E4%25B8%258D%25E5%25BA%2594%25E5%25BC%2580%25E5%25B1%2595%25E6%25A0%25B8%25E6%25BD%259C%25E8%2589%2587%25E5%2590%2588%25E4%25BD%259C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D24&timestamp=1654662370&signature=64cb9bbae5d1bc24a6a1e3185ac64eec (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-25980, started daemon 140586776528640)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-25980, started daemon 140586776528640)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-25980, started daemon 140586776528640)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-25980, started daemon 140586776528640)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-25980, started daemon 140586776528640)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fdce85ec040>
    │    │                                │              │         └ '外交部：在各方达成共识之前美英澳不应开展核潜艇合作'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fdce85ec040>
               │    │                        │         └ '外交部：在各方达成共识之前美英澳不应开展核潜艇合作'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '外交部：在各方达成共识之前美英澳不应开展核潜艇合作'
                   │    │       │                                  │        └ <string.Template object at 0x7fdd1def3dc0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=外交部：在各方达成共识之前美英澳不应开展核潜艇合作&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=24'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=外交部：在各方达成共识之前美英澳不应开展核潜艇合作&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=24'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=外交部：在各方达成共识之前美英澳不应开展核潜艇合作&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=24'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fe06017c580>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fe06017c580>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdce4d99740>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fe06017c580>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fde9008b400>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25A4%2596%25E4%25BA%25A4%25E9%2583%25A8%25EF%25BC%259A%25E5%259C%25A8%25E5%2590%2584%25E6%2596%25B9%25E8%25BE%25BE%25E6%2588%2590%25E5%2585%25B1%25E8%25AF%2586%25E4%25B9%258B%25E5%2589%258D%25E7%25BE%258E%25E8%258B%25B1%25E6%25BE%25B3%25E4%25B8%258D%25E5%25BA%2594%25E5%25BC%2580%25E5%25B1%2595%25E6%25A0%25B8%25E6%25BD%259C%25E8%2589%2587%25E5%2590%2588%25E4%25BD%259C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D24&timestamp=1654662370&signature=64cb9bbae5d1bc24a6a1e3185ac64eec (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 12:33:04.006 | ERROR    | monitor.hotSpiders.ifeng:get_title:33 - url:https://www.ifeng.com/  ("Connection broken: ConnectionResetError(104, 'Connection reset by peer')", ConnectionResetError(104, 'Connection reset by peer'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/response.py", line 438, in _error_catcher
    yield
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/response.py", line 519, in read
    data = self._fp.read(amt) if not fp_closed else b""
           │    │   │    │           └ False
           │    │   │    └ 10240
           │    │   └ <function HTTPResponse.read at 0x7fe08116ca60>
           │    └ <http.client.HTTPResponse object at 0x7fddd0240b80>
           └ <urllib3.response.HTTPResponse object at 0x7fdcd1e58d60>
  File "/usr/lib/python3.8/http/client.py", line 459, in read
    n = self.readinto(b)
        │    │        └ bytearray(b'e":"","thumbnail":"","children":null},{"url":"https://finance.ifeng.com/c/8GfFsKdf8cY","title":"\xe8\x82\xa1\xe4\...
        │    └ <function HTTPResponse.readinto at 0x7fe08116caf0>
        └ <http.client.HTTPResponse object at 0x7fddd0240b80>
  File "/usr/lib/python3.8/http/client.py", line 503, in readinto
    n = self.fp.readinto(b)
        │    │           └ bytearray(b'e":"","thumbnail":"","children":null},{"url":"https://finance.ifeng.com/c/8GfFsKdf8cY","title":"\xe8\x82\xa1\xe4\...
        │    └ None
        └ <http.client.HTTPResponse object at 0x7fddd0240b80>
  File "/usr/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
           │    │               └ <memory at 0x7fe06065a100>
           │    └ None
           └ <socket.SocketIO object at 0x7fddd0240400>
  File "/usr/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
           │    │    │       └ <memory at 0x7fe06065a100>
           │    │    └ 8192
           │    └ <function SSLSocket.read at 0x7fe08c8d1f70>
           └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
           │    │            │    └ <memory at 0x7fe06065a100>
           │    │            └ 8192
           │    └ None
           └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ConnectionResetError: [Errno 104] Connection reset by peer


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/models.py", line 758, in generate
    for chunk in self.raw.stream(chunk_size, decode_content=True):
        │        │    │   │      └ 10240
        │        │    │   └ <function HTTPResponse.stream at 0x7fe06b3fd9d0>
        │        │    └ <urllib3.response.HTTPResponse object at 0x7fdcd1e58d60>
        │        └ <Response [200]>
        └ b'st":[{"url":"https://news.ifeng.com/c/8FD5MvzKwJ3","title":"\xe7\xac\xac17\xe5\xb1\x8a\xc2\xb72022\xe7\x88\xb1\xe5\xbf\x83\...
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/response.py", line 576, in stream
    data = self.read(amt=amt, decode_content=decode_content)
           │    │        │                   └ True
           │    │        └ 10240
           │    └ <function HTTPResponse.read at 0x7fe06b3fd940>
           └ <urllib3.response.HTTPResponse object at 0x7fdcd1e58d60>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/response.py", line 541, in read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
          │              │    │               │    └ 307559
          │              │    │               └ <urllib3.response.HTTPResponse object at 0x7fdcd1e58d60>
          │              │    └ 40960
          │              └ <urllib3.response.HTTPResponse object at 0x7fdcd1e58d60>
          └ <class 'urllib3.exceptions.IncompleteRead'>
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
    │    │   │     │     │      └ <traceback object at 0x7fde701eed40>
    │    │   │     │     └ ConnectionResetError(104, 'Connection reset by peer')
    │    │   │     └ <class 'ConnectionResetError'>
    │    │   └ <method 'throw' of 'generator' objects>
    │    └ <generator object HTTPResponse._error_catcher at 0x7fde100a8eb0>
    └ <contextlib._GeneratorContextManager object at 0x7fdda22624f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/response.py", line 455, in _error_catcher
    raise ProtocolError("Connection broken: %r" % e, e)
          └ <class 'urllib3.exceptions.ProtocolError'>

urllib3.exceptions.ProtocolError: ("Connection broken: ConnectionResetError(104, 'Connection reset by peer')", ConnectionResetError(104, 'Connection reset by peer'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-27275, started daemon 140587809076992)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-27275, started daemon 140587809076992)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-27275, started daemon 140587809076992)>
    │    │        │    └ ([],)
    │    │        └ <Thread(Thread-27275, started daemon 140587809076992)>
    │    └ <bound method ProjectManager.crawl_hot_title of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-27275, started daemon 140587809076992)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 743, in crawl_hot_title
    self.hot_spider_manager.crawl_hot()
    │    │                  └ <function HotSpiderManager.crawl_hot at 0x7fe063c70e50>
    │    └ <monitor.spiderManager.HotSpiderManager object at 0x7fe0639939d0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 50, in crawl_hot
    status, title = spider.get_title(headers, hot_url)
    │               │      │         │        └ 'https://www.ifeng.com/'
    │               │      │         └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'sec-ch-ua': "'Chromium';v='94', 'Google Chrome';v='94', ';Not A B...
    │               │      └ <function Ifeng.get_title at 0x7fe0638d3d30>
    │               └ <monitor.hotSpiders.ifeng.Ifeng object at 0x7fe0638c11f0>
    └ True

> File "/home/users/Scy/yuqing/spider/monitor/hotSpiders/ifeng.py", line 25, in get_title
    response = requests.get(url, headers=headers)
               │        │   │            └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'sec-ch-ua': "'Chromium';v='94', 'Google Chrome';v='94', ';Not A B...
               │        │   └ 'https://www.ifeng.com/'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'sec-ch-ua': "'Chromium';v='94', 'Google Chrome';v='94...
           │              │           └ None
           │              └ 'https://www.ifeng.com/'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'sec-ch-ua': "'Chromium';v='94', 'Goog...
           │       │              │           └ 'https://www.ifeng.com/'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fde306e9f70>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde306e9f70>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 697, in send
    r.content
    │ └ <property object at 0x7fe06b2671d0>
    └ <Response [200]>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/models.py", line 836, in content
    self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''
    │    │                   │    │            └ 10240
    │    │                   │    └ <function Response.iter_content at 0x7fe06b265e50>
    │    │                   └ <Response [200]>
    │    └ False
    └ <Response [200]>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/models.py", line 761, in generate
    raise ChunkedEncodingError(e)
          └ <class 'requests.exceptions.ChunkedEncodingError'>

requests.exceptions.ChunkedEncodingError: ("Connection broken: ConnectionResetError(104, 'Connection reset by peer')", ConnectionResetError(104, 'Connection reset by peer'))
2022-06-08 12:48:10.454 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E7%25A6%258F%25E5%25BB%25BA%25E9%259C%259E%25E6%25B5%25A6%25EF%25BC%259A%25E4%25BC%2591%25E6%25B8%2594%25E5%25AD%25A3%2520%25E4%25BF%25AE%25E8%2588%25B9%25E5%25BF%2599%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D16&timestamp=1654663690&signature=cd33f384435139cf0cccd6a6672a4cbf (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd0ded1ee0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fded014c4c0>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd0ded1ee0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fded014c4c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fded014c4c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdd3d87f7c0>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdd3d87f7c0>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd0ded1ee0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd0ded1ee0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E7%25A6%258F%25E5%25BB%25BA%25E9%259C%259E%25E6%25B5%25A6%25EF%25BC%259A%25E4%25BC%2591%25E6%25B8%2594%25E5%25AD%25A3%2520%25E4%25BF%25AE%25E8%2588%25B9%25E5%25BF%2599%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D16&timestamp=1654663690&signature=cd33f384435139cf0cccd6a6672a4cbf (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-25980, started daemon 140586776528640)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-25980, started daemon 140586776528640)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-25980, started daemon 140586776528640)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-25980, started daemon 140586776528640)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-25980, started daemon 140586776528640)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fdce85ec040>
    │    │                                │              │         └ '福建霞浦：休渔季 修船忙'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fdce85ec040>
               │    │                        │         └ '福建霞浦：休渔季 修船忙'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '福建霞浦：休渔季 修船忙'
                   │    │       │                                  │        └ <string.Template object at 0x7fdcf13aa970>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=福建霞浦：休渔季 修船忙&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=16'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=福建霞浦：休渔季 修船忙&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=16'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=福建霞浦：休渔季 修船忙&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=16'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fdf5439d9a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdf5439d9a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdd27f37cf0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdf5439d9a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdce2410280>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E7%25A6%258F%25E5%25BB%25BA%25E9%259C%259E%25E6%25B5%25A6%25EF%25BC%259A%25E4%25BC%2591%25E6%25B8%2594%25E5%25AD%25A3%2520%25E4%25BF%25AE%25E8%2588%25B9%25E5%25BF%2599%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D16&timestamp=1654663690&signature=cd33f384435139cf0cccd6a6672a4cbf (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 12:56:00.290 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25A4%2596%25E4%25BA%25A4%25E9%2583%25A8%25EF%25BC%259A%25E5%259C%25A8%25E5%2590%2584%25E6%2596%25B9%25E8%25BE%25BE%25E6%2588%2590%25E5%2585%25B1%25E8%25AF%2586%25E4%25B9%258B%25E5%2589%258D%25E7%25BE%258E%25E8%258B%25B1%25E6%25BE%25B3%25E4%25B8%258D%25E5%25BA%2594%25E5%25BC%2580%25E5%25B1%2595%25E6%25A0%25B8%25E6%25BD%259C%25E8%2589%2587%25E5%2590%2588%25E4%25BD%259C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D12&timestamp=1654664160&signature=3d72aada2d9870973003d7a0d5950a79 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fde50f10370>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fdcd1e69220>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fde50f10370>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fdcd1e69220>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fdcd1e69220>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdeb0362840>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdeb0362840>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fde50f10370>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fde50f10370>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25A4%2596%25E4%25BA%25A4%25E9%2583%25A8%25EF%25BC%259A%25E5%259C%25A8%25E5%2590%2584%25E6%2596%25B9%25E8%25BE%25BE%25E6%2588%2590%25E5%2585%25B1%25E8%25AF%2586%25E4%25B9%258B%25E5%2589%258D%25E7%25BE%258E%25E8%258B%25B1%25E6%25BE%25B3%25E4%25B8%258D%25E5%25BA%2594%25E5%25BC%2580%25E5%25B1%2595%25E6%25A0%25B8%25E6%25BD%259C%25E8%2589%2587%25E5%2590%2588%25E4%25BD%259C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D12&timestamp=1654664160&signature=3d72aada2d9870973003d7a0d5950a79 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-26562, started daemon 140587444524800)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-26562, started daemon 140587444524800)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-26562, started daemon 140587444524800)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-26562, started daemon 140587444524800)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-26562, started daemon 140587444524800)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fde500accd0>
    │    │                                │              │         └ '外交部：在各方达成共识之前美英澳不应开展核潜艇合作'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fde500accd0>
               │    │                        │         └ '外交部：在各方达成共识之前美英澳不应开展核潜艇合作'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '外交部：在各方达成共识之前美英澳不应开展核潜艇合作'
                   │    │       │                                  │        └ <string.Template object at 0x7fded00f7d90>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=外交部：在各方达成共识之前美英澳不应开展核潜艇合作&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=12'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=外交部：在各方达成共识之前美英澳不应开展核潜艇合作&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=12'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=外交部：在各方达成共识之前美英澳不应开展核潜艇合作&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=12'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fde900ed460>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde900ed460>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdd4293f580>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fde900ed460>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdda251fc10>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E5%25A4%2596%25E4%25BA%25A4%25E9%2583%25A8%25EF%25BC%259A%25E5%259C%25A8%25E5%2590%2584%25E6%2596%25B9%25E8%25BE%25BE%25E6%2588%2590%25E5%2585%25B1%25E8%25AF%2586%25E4%25B9%258B%25E5%2589%258D%25E7%25BE%258E%25E8%258B%25B1%25E6%25BE%25B3%25E4%25B8%258D%25E5%25BA%2594%25E5%25BC%2580%25E5%25B1%2595%25E6%25A0%25B8%25E6%25BD%259C%25E8%2589%2587%25E5%2590%2588%25E4%25BD%259C%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D12&timestamp=1654664160&signature=3d72aada2d9870973003d7a0d5950a79 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 13:12:50.163 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%25B1%259F%25E8%258B%258F%25E7%259B%2590%25E5%259F%258E%25EF%25BC%259A%25E6%25BB%25A9%25E6%25B6%2582%25E2%2580%259C%25E9%25A3%258E%25E8%25A1%25A5%25E6%25B8%2594%25E2%2580%259D%25E7%25BB%25BC%25E5%2590%2588%25E5%25BC%2580%25E5%258F%2591%25E5%2587%25B8%25E7%258E%25B0%25E7%2594%259F%25E6%2580%2581%25E6%2595%2588%25E7%259B%258A%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D19&timestamp=1654665170&signature=a4a53b3a8cbcf884b99ad5fc3809f036 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fde504a6220>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fded0267460>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fde504a6220>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fded0267460>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fded0267460>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdd0101cdc0>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdd0101cdc0>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fde504a6220>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fde504a6220>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%25B1%259F%25E8%258B%258F%25E7%259B%2590%25E5%259F%258E%25EF%25BC%259A%25E6%25BB%25A9%25E6%25B6%2582%25E2%2580%259C%25E9%25A3%258E%25E8%25A1%25A5%25E6%25B8%2594%25E2%2580%259D%25E7%25BB%25BC%25E5%2590%2588%25E5%25BC%2580%25E5%258F%2591%25E5%2587%25B8%25E7%258E%25B0%25E7%2594%259F%25E6%2580%2581%25E6%2595%2588%25E7%259B%258A%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D19&timestamp=1654665170&signature=a4a53b3a8cbcf884b99ad5fc3809f036 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-25847, started daemon 140590536693504)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-25847, started daemon 140590536693504)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-25847, started daemon 140590536693504)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-25847, started daemon 140590536693504)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-25847, started daemon 140590536693504)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fde1076e4f0>
    │    │                                │              │         └ '江苏盐城：滩涂“风补渔”综合开发凸现生态效益'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fde1076e4f0>
               │    │                        │         └ '江苏盐城：滩涂“风补渔”综合开发凸现生态效益'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '江苏盐城：滩涂“风补渔”综合开发凸现生态效益'
                   │    │       │                                  │        └ <string.Template object at 0x7fdd3e8debb0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=江苏盐城：滩涂“风补渔”综合开发凸现生态效益&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=19'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=江苏盐城：滩涂“风补渔”综合开发凸现生态效益&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=19'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=江苏盐城：滩涂“风补渔”综合开发凸现生态效益&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=19'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fdd010a8c40>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdd010a8c40>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdcf1378ba0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdd010a8c40>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdd4ac95a60>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%25B1%259F%25E8%258B%258F%25E7%259B%2590%25E5%259F%258E%25EF%25BC%259A%25E6%25BB%25A9%25E6%25B6%2582%25E2%2580%259C%25E9%25A3%258E%25E8%25A1%25A5%25E6%25B8%2594%25E2%2580%259D%25E7%25BB%25BC%25E5%2590%2588%25E5%25BC%2580%25E5%258F%2591%25E5%2587%25B8%25E7%258E%25B0%25E7%2594%259F%25E6%2580%2581%25E6%2595%2588%25E7%259B%258A%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D19&timestamp=1654665170&signature=a4a53b3a8cbcf884b99ad5fc3809f036 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 13:13:10.254 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E8%2593%259D%25E8%258A%25B1%25E6%25A5%25B9%25E7%25BB%25BD%25E6%2594%25BE%25EF%25BC%259A%25E6%2598%25A5%25E5%259F%258E%25E6%2598%2586%25E6%2598%258E%25E7%259A%2584%25E2%2580%259C%25E8%258A%25B1%25E5%25BC%258F%25E6%25B5%25AA%25E6%25BC%25AB%25E2%2580%259D%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D11&timestamp=1654665190&signature=73144d6b018f6e101e7f09ed5acd9ad3 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdcd3231d90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fde9033df70>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdcd3231d90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fde9033df70>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fde9033df70>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdce1b0adc0>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdce1b0adc0>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdcd3231d90>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdcd3231d90>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E8%2593%259D%25E8%258A%25B1%25E6%25A5%25B9%25E7%25BB%25BD%25E6%2594%25BE%25EF%25BC%259A%25E6%2598%25A5%25E5%259F%258E%25E6%2598%2586%25E6%2598%258E%25E7%259A%2584%25E2%2580%259C%25E8%258A%25B1%25E5%25BC%258F%25E6%25B5%25AA%25E6%25BC%25AB%25E2%2580%259D%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D11&timestamp=1654665190&signature=73144d6b018f6e101e7f09ed5acd9ad3 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-22738, started daemon 140586895075072)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-22738, started daemon 140586895075072)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-22738, started daemon 140586895075072)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-22738, started daemon 140586895075072)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-22738, started daemon 140586895075072)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fddf37c05e0>
    │    │                                │              │         └ '蓝花楹绽放：春城昆明的“花式浪漫”'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fddf37c05e0>
               │    │                        │         └ '蓝花楹绽放：春城昆明的“花式浪漫”'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '蓝花楹绽放：春城昆明的“花式浪漫”'
                   │    │       │                                  │        └ <string.Template object at 0x7fdf544ff070>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=蓝花楹绽放：春城昆明的“花式浪漫”&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=11'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=蓝花楹绽放：春城昆明的“花式浪漫”&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=11'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=蓝花楹绽放：春城昆明的“花式浪漫”&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=11'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fdcd313e820>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdcd313e820>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdef072bd60>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdcd313e820>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdd3d7eb880>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E8%2593%259D%25E8%258A%25B1%25E6%25A5%25B9%25E7%25BB%25BD%25E6%2594%25BE%25EF%25BC%259A%25E6%2598%25A5%25E5%259F%258E%25E6%2598%2586%25E6%2598%258E%25E7%259A%2584%25E2%2580%259C%25E8%258A%25B1%25E5%25BC%258F%25E6%25B5%25AA%25E6%25BC%25AB%25E2%2580%259D%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D11&timestamp=1654665190&signature=73144d6b018f6e101e7f09ed5acd9ad3 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 13:23:10.144 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E7%25A6%258F%25E5%25BB%25BA%25E9%259C%259E%25E6%25B5%25A6%25EF%25BC%259A%25E4%25BC%2591%25E6%25B8%2594%25E5%25AD%25A3%2520%25E4%25BF%25AE%25E8%2588%25B9%25E5%25BF%2599%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D5&timestamp=1654665790&signature=8aac46e882020615231a5e417ad13d4f (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdf541ee160>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fdf74261280>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdf541ee160>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fdf74261280>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fdf74261280>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fdda23853c0>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fdda23853c0>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdf541ee160>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdf541ee160>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E7%25A6%258F%25E5%25BB%25BA%25E9%259C%259E%25E6%25B5%25A6%25EF%25BC%259A%25E4%25BC%2591%25E6%25B8%2594%25E5%25AD%25A3%2520%25E4%25BF%25AE%25E8%2588%25B9%25E5%25BF%2599%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D5&timestamp=1654665790&signature=8aac46e882020615231a5e417ad13d4f (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-26610, started daemon 140589605103360)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-26610, started daemon 140589605103360)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-26610, started daemon 140589605103360)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-26610, started daemon 140589605103360)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-26610, started daemon 140589605103360)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fdef054f430>
    │    │                                │              │         └ '福建霞浦：休渔季 修船忙'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fdef054f430>
               │    │                        │         └ '福建霞浦：休渔季 修船忙'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '福建霞浦：休渔季 修船忙'
                   │    │       │                                  │        └ <string.Template object at 0x7fdd49ba3d30>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=福建霞浦：休渔季 修船忙&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=5'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=福建霞浦：休渔季 修船忙&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=5'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=福建霞浦：休渔季 修船忙&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=5'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fdd3cdf4c10>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdd3cdf4c10>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdd14337120>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fdd3cdf4c10>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdda2259b20>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E7%25A6%258F%25E5%25BB%25BA%25E9%259C%259E%25E6%25B5%25A6%25EF%25BC%259A%25E4%25BC%2591%25E6%25B8%2594%25E5%25AD%25A3%2520%25E4%25BF%25AE%25E8%2588%25B9%25E5%25BF%2599%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D5&timestamp=1654665790&signature=8aac46e882020615231a5e417ad13d4f (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-06-08 13:23:31.149 | ERROR    | monitor.searchSpiders.tieba:get_request_from_keyword:34 - E 贴吧错误HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%25B3%25A2%25E5%2585%25B0%25E5%258D%2597%25E9%2583%25A8%25E6%25B2%25B9%25E8%258F%259C%25E8%258A%25B1%25E7%25BB%25BD%25E6%2594%25BE%25E7%25BE%258E%25E4%25B8%258D%25E8%2583%259C%25E6%2594%25B6%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D28&timestamp=1654665811&signature=74632f62369537ae1fa8c15a3eb896a7 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7fe06b3fed30>
                       └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd2b005d30>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
    │    │              └ <urllib3.connection.HTTPSConnection object at 0x7fddc47a04c0>
    │    └ <function HTTPSConnectionPool._validate_conn at 0x7fe06b3ff280>
    └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd2b005d30>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
    │    └ <function HTTPSConnection.connect at 0x7fe06b46d940>
    └ <urllib3.connection.HTTPSConnection object at 0x7fddc47a04c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 416, in connect
    self.sock = ssl_wrap_socket(
    │    │      └ <function ssl_wrap_socket at 0x7fe06b468670>
    │    └ None
    └ <urllib3.connection.HTTPSConnection object at 0x7fddc47a04c0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               └ <function _ssl_wrap_socket_impl at 0x7fe06b468820>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           │           │           │                     └ 'wappass.baidu.com'
           │           │           └ <socket.socket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
           │           └ <function SSLContext.wrap_socket at 0x7fe08118de50>
           └ <ssl.SSLContext object at 0x7fde5048cd40>
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
           │    │               └ <classmethod object at 0x7fe08c8cfaf0>
           │    └ <class 'ssl.SSLSocket'>
           └ <ssl.SSLContext object at 0x7fde5048cd40>
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
    │    └ <function SSLSocket.do_handshake at 0x7fe08c8d2d30>
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
    │    └ None
    └ <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>

ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7fe06b3fef70>
           └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd2b005d30>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7fe06b443280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)'))
          │             │      └ '/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fis...
          │             └ <urllib3.connectionpool.HTTPSConnectionPool object at 0x7fdd2b005d30>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%25B3%25A2%25E5%2585%25B0%25E5%258D%2597%25E9%2583%25A8%25E6%25B2%25B9%25E8%258F%259C%25E8%258A%25B1%25E7%25BB%25BD%25E6%2594%25BE%25E7%25BE%258E%25E4%25B8%258D%25E8%2583%259C%25E6%2594%25B6%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D28&timestamp=1654665811&signature=74632f62369537ae1fa8c15a3eb896a7 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fe08f92ea60>
    └ <Thread(Thread-27150, started daemon 140589999560448)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fe08f92e790>
    └ <Thread(Thread-27150, started daemon 140589999560448)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-27150, started daemon 140589999560448)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-27150, started daemon 140589999560448)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fe063c65790>>
    └ <Thread(Thread-27150, started daemon 140589999560448)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 833, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe063c71160>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>
    └ <monitor.projectManager.ProjectManager object at 0x7fe063c65790>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe0639a2b80>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fdd1f4123a0>
    │    │                                │              │         └ '波兰南部油菜花绽放美不胜收'
    │    │                                │              └ '贴吧'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe063c71280>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 150, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword_only, **crawl_time.to_dict())
               │    │                        │         │               │          └ <function TimeSection.to_dict at 0x7fe06b8931f0>
               │    │                        │         │               └ <monitor.TimeSection object at 0x7fdd1f4123a0>
               │    │                        │         └ '波兰南部油菜花绽放美不胜收'
               │    │                        └ '贴吧'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe063c713a0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 214, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ None
                   │    │       │                                  │        │           └ '波兰南部油菜花绽放美不胜收'
                   │    │       │                                  │        └ <string.Template object at 0x7fde30490100>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
                   │    │       └ '贴吧'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe063893370>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe0638938b0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/tieba.py", line 22, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=50)
               │        │   │            └ {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec-ch-ua-mobil...
               │        │   └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=波兰南部油菜花绽放美不胜收&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=28'
               │        └ <function get at 0x7fe06b2724c0>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrome';v='92'", 'sec...
           │              │           └ None
           │              └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=波兰南部油菜花绽放美不胜收&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=28'
           └ <function request at 0x7fe06b268310>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'sec-ch-ua': "'Chromium';v='92',' Not A;Brand';v='99', 'Google Chrom...
           │       │              │           └ 'https://tieba.baidu.com/f/search/res?isnew=1&kw=&qw=波兰南部油菜花绽放美不胜收&rn=10&un=&only_thread=0&sm=1&sd=&ed=&pn=28'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7fe06b27bc10>
           └ <requests.sessions.Session object at 0x7fddd036b3d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 50, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fddd036b3d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in send
    history = [resp for resp in gen]
                                └ <generator object SessionRedirectMixin.resolve_redirects at 0x7fdccb46dba0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
           │    └ <function Session.send at 0x7fe06b2720d0>
           └ <requests.sessions.Session object at 0x7fddd036b3d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'stream': False, 'timeout': 50, 'verify': True, 'cert': None, 'proxies': OrderedDict()}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7fe06b27b550>
        └ <requests.adapters.HTTPAdapter object at 0x7fdcf3d73940>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
          │                   └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.SSLError'>

requests.exceptions.SSLError: HTTPSConnectionPool(host='wappass.baidu.com', port=443): Max retries exceeded with url: /static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Ff%2Fsearch%2Fres%3Fisnew%3D1%26kw%3D%26qw%3D%25E6%25B3%25A2%25E5%2585%25B0%25E5%258D%2597%25E9%2583%25A8%25E6%25B2%25B9%25E8%258F%259C%25E8%258A%25B1%25E7%25BB%25BD%25E6%2594%25BE%25E7%25BE%258E%25E4%25B8%258D%25E8%2583%259C%25E6%2594%25B6%26rn%3D10%26un%3D%26only_thread%3D0%26sm%3D1%26sd%3D%26ed%3D%26pn%3D28&timestamp=1654665811&signature=74632f62369537ae1fa8c15a3eb896a7 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
