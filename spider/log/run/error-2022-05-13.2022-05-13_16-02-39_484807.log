2022-05-13 09:00:34.944 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://api.weibo.com/2/statuses/go?uid=2286908003&id=4765833727576122
2022-05-13 09:00:35.579 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://api.weibo.com/2/statuses/go?uid=2286908003&id=4765833727576122
2022-05-13 09:00:52.875 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://api.weibo.com/2/statuses/go?uid=2286908003&id=4765833727576122
2022-05-13 09:01:00.631 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://api.weibo.com/2/statuses/go?uid=2286908003&id=4765833727576122
2022-05-13 09:01:18.760 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://api.weibo.com/2/statuses/go?uid=2286908003&id=4765833727576122
2022-05-13 09:01:36.917 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://api.weibo.com/2/statuses/go?uid=2286908003&id=4765833727576122
2022-05-13 09:01:45.472 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://api.weibo.com/2/statuses/go?uid=2286908003&id=4765833727576122
2022-05-13 09:01:47.842 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://api.weibo.com/2/statuses/go?uid=2286908003&id=4765833727576122
2022-05-13 09:02:18.303 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://api.weibo.com/2/statuses/go?uid=2286908003&id=4765833727576122
2022-05-13 09:02:36.147 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://api.weibo.com/2/statuses/go?uid=2286908003&id=4765833727576122
2022-05-13 09:07:08.926 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177707785.html
2022-05-13 09:07:08.964 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://api.weibo.com/2/statuses/go?uid=2286908003&id=4765874260805091
2022-05-13 09:07:19.514 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177707785.html
2022-05-13 09:07:19.537 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://api.weibo.com/2/statuses/go?uid=2286908003&id=4765874260805091
2022-05-13 09:12:14.822 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E5%87%8F%E8%BD%BB%E7%81%BE%E5%AE%B3%E9%A3%8E%E9%99%A9%20%20%E5%AE%88%E6%8A%A4%E7%BE%8E%E5%A5%BD%E5%AE%B6%E5%9B%AD&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=10 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:14:27.889 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:14:31.924 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:14:32.031 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:15:09.543 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:15:24.859 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%B8%96%E5%8D%AB%E7%BB%84%E7%BB%87%EF%BC%9A%E5%85%A8%E7%90%83%E7%B4%AF%E8%AE%A1%E6%96%B0%E5%86%A0%E7%A1%AE%E8%AF%8A%E7%97%85%E4%BE%8B%E8%BE%BE513384685%E4%BE%8B&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=60 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:16:38.567 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:16:43.926 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:16:44.159 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E5%8C%97%E4%BA%AC%E6%96%B0%E5%A2%9E35%E4%BE%8B%E6%9C%AC%E5%9C%9F%E7%A1%AE%E8%AF%8A%E7%97%85%E4%BE%8B%E5%92%8C11%E4%BE%8B%E6%9C%AC%E5%9C%9F%E6%97%A0%E7%97%87%E7%8A%B6%E6%84%9F%E6%9F%93%E8%80%85&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=60 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:17:23.304 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:17:28.403 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:17:32.443 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:17:32.771 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:17:41.721 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E2%80%9C%E9%81%93%E5%87%BA%E4%BA%BA%E7%B1%BB%E5%8F%AF%E6%8C%81%E7%BB%AD%E5%8F%91%E5%B1%95%E7%9A%84%E5%A5%A5%E7%A7%98%E2%80%9D%EF%BC%88%E5%A4%A7%E9%81%93%E4%B9%8B%E8%A1%8C%EF%BC%89&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=70 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:18:23.309 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:18:53.363 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:18:54.658 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:19:00.190 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:19:00.765 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:19:01.799 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:19:53.634 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:20:29.371 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:20:30.991 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:20:36.255 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:20:37.836 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:20:47.390 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:22:23.133 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:22:24.386 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:23:01.481 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%BB%A5%E6%88%91%E6%97%A0%E5%90%8D%EF%BC%8C%E6%88%90%E5%B0%B1%E9%95%BF%E5%89%91%E5%A8%81%E5%90%8D&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=90 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:23:12.050 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:23:14.494 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:23:17.463 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:23:17.939 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:23:19.949 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:23:47.964 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:23:49.993 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:23:50.260 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:24:02.347 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:24:37.349 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E7%BB%B4%E5%85%8B%E5%8B%92%E9%A9%AC%E8%BE%9B%E5%93%88%E5%86%8D%E5%BA%A6%E5%87%BA%E4%BB%BB%E6%96%AF%E9%87%8C%E5%85%B0%E5%8D%A1%E6%80%BB%E7%90%86&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=0 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:24:39.533 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%BB%A5%E6%88%91%E6%97%A0%E5%90%8D%EF%BC%8C%E6%88%90%E5%B0%B1%E9%95%BF%E5%89%91%E5%A8%81%E5%90%8D&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=0 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:24:39.564 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%BA%8B%E5%85%B3%E5%85%A8%E5%B1%80%EF%BC%9A%E2%80%9C%E4%BF%9D%E6%8A%A4%E5%A5%BD%E8%80%81%E5%B9%B4%E4%BA%BA%E2%80%9D%E6%98%AF%E7%AD%91%E7%89%A2%E5%85%8D%E7%96%AB%E5%B1%8F%E9%9A%9C%E7%9A%84%E5%85%B3%E9%94%AE&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=0 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:26:25.581 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 500
2022-05-13 09:29:46.304 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%B8%96%E5%8D%AB%E7%BB%84%E7%BB%87%EF%BC%9A%E9%9D%A2%E5%AF%B9%E6%96%B0%E5%8F%98%E5%BC%82%E6%96%B0%E5%86%A0%E7%97%85%E6%AF%92%20%E7%96%AB%E8%8B%97%E9%A2%84%E9%98%B2%E9%87%8D%E7%97%87%E5%92%8C%E6%AD%BB%E4%BA%A1%E4%BB%8D%E6%95%88%E6%9E%9C%E2%80%A6&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=80 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:30:50.429 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E5%96%80%E9%BA%A6%E9%9A%86%E4%B8%80%E6%90%AD%E8%BD%BD11%E4%BA%BA%E9%A3%9E%E6%9C%BA%E5%A4%B1%E8%81%94&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=40 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:31:02.741 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%BF%84%E6%96%B9%E8%AF%B4%E5%8C%97%E7%BA%A6%E8%A1%8C%E4%B8%BA%E5%A2%9E%E5%8A%A0%E7%9B%B4%E6%8E%A5%E5%86%B2%E7%AA%81%E9%A3%8E%E9%99%A9%20%E8%8A%AC%E5%85%B0%E9%A2%86%E5%AF%BC%E4%BA%BA%E7%A7%B0%E6%94%AF%E6%8C%81%E8%AF%A5%E5%9B%BD%E7%94%B3%E2%80%A6&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=0 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:35:33.549 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:36:10.292 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:36:37.604 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:39:25.383 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:39:25.496 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:40:12.221 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:41:18.131 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:41:31.083 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:42:13.611 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:42:45.349 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:43:24.057 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:43:24.584 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:44:05.411 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:44:09.433 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:44:09.533 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:44:10.630 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:44:12.881 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:44:15.623 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:44:36.065 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%BF%84%E7%BD%97%E6%96%AF%E5%B8%83%E8%89%AF%E6%96%AF%E5%85%8B%E5%B7%9E%E4%B8%80%E8%BE%B9%E9%98%B2%E8%AE%BE%E6%96%BD%E9%81%AD%E7%82%AE%E5%87%BB&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=10 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:44:58.722 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%BC%8A%E6%9C%97%E5%A4%96%E4%BA%A4%E9%83%A8%EF%BC%9A%E6%AC%A7%E7%9B%9F%E4%BB%A3%E8%A1%A8%E8%AE%BF%E9%97%AE%E4%BC%8A%E6%9C%97%E5%B0%86%E4%BD%BF%E4%BC%8A%E6%A0%B8%E8%B0%88%E5%88%A4%E6%9C%9D%E6%AD%A3%E7%A1%AE%E6%96%B9%E5%90%91%E8%BF%88%E8%BF%9B&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=0 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:45:34.337 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%BC%8A%E6%9C%97%E5%A4%96%E4%BA%A4%E9%83%A8%EF%BC%9A%E6%AC%A7%E7%9B%9F%E4%BB%A3%E8%A1%A8%E8%AE%BF%E9%97%AE%E4%BC%8A%E6%9C%97%E5%B0%86%E4%BD%BF%E4%BC%8A%E6%A0%B8%E8%B0%88%E5%88%A4%E6%9C%9D%E6%AD%A3%E7%A1%AE%E6%96%B9%E5%90%91%E8%BF%88%E8%BF%9B&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=0 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:46:20.347 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:46:55.829 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:46:58.741 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:47:00.723 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:47:03.363 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:47:56.973 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:48:00.627 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:48:03.858 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:48:07.293 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:48:08.959 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 09:48:56.837 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E9%A9%AC%E6%8B%89%E5%96%80%E4%BB%80%E6%9D%A1%E7%BA%A6%E5%AF%B9%E6%88%91%E5%9B%BD%E7%94%9F%E6%95%88%20%E6%9E%81%E5%A4%A7%E4%B8%B0%E5%AF%8C%E9%98%85%E8%AF%BB%E9%9A%9C%E7%A2%8D%E8%80%85%E7%B2%BE%E7%A5%9E%E6%96%87%E5%8C%96%E7%94%9F%E6%B4%BB&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=90 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 09:53:08.145 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误'NoneType' object is not subscriptable
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fea32858a60>
    └ <Thread(Thread-245, started daemon 140635986179840)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fea32858790>
    └ <Thread(Thread-245, started daemon 140635986179840)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-245, started daemon 140635986179840)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-245, started daemon 140635986179840)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>>
    └ <Thread(Thread-245, started daemon 140635986179840)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe91ac39ee0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
    └ <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe91a90cc10>, 'test': <monitor.TimeSection object at 0x7fe9185fc8b0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fe9182fdc70>
    │    │                                │              │         └ '欧盟发布扩大地理标志计划新提案'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe91ac3a040>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fea10c63a60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fe9182fdc70>
               │    │                        │         └ '欧盟发布扩大地理标志计划新提案'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe91ac3a160>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7fe900232d90>
        │          │    │       │                                  │        │           └ '欧盟发布扩大地理标志计划新提案'
        │          │    │       │                                  │        └ <string.Template object at 0x7fe90017cca0>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe91a84c880>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
        └ <GET http://www.qstheory.cn/qshyjx/2022-02/10/c_1128351178.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 28, in get_request_from_keyword
    for res in json_response['results']:
        │      └ None
        └ {'des': "勇于自我革命，从严管党治党，是我们党最鲜明的品格。在<font color='red'>新</font>的历史条件下，要把党的自我革命向纵深推进", 'pubtime': '2022-02-10 14:11:54', 'author...

TypeError: 'NoneType' object is not subscriptable
2022-05-13 09:53:08.161 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误'NoneType' object is not subscriptable
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fea32858a60>
    └ <Thread(Thread-288, started daemon 140635482879744)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fea32858790>
    └ <Thread(Thread-288, started daemon 140635482879744)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-288, started daemon 140635482879744)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-288, started daemon 140635482879744)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>>
    └ <Thread(Thread-288, started daemon 140635482879744)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe91ac39ee0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
    └ <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe91a90cc10>, 'test': <monitor.TimeSection object at 0x7fe9185fc8b0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fe9186bd340>
    │    │                                │              │         └ '欧盟发布扩大地理标志计划新提案'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe91ac3a040>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fea10c63a60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fe9186bd340>
               │    │                        │         └ '欧盟发布扩大地理标志计划新提案'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe91ac3a160>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7fe9003c9c70>
        │          │    │       │                                  │        │           └ '欧盟发布扩大地理标志计划新提案'
        │          │    │       │                                  │        └ <string.Template object at 0x7fe91821d4f0>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe91a84c880>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
        └ <GET http://www.qstheory.cn/yaowen/2022-02/22/c_1128406852.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 28, in get_request_from_keyword
    for res in json_response['results']:
        │      └ None
        └ {'des': None, 'pubtime': '2022-02-22 20:02:21', 'author': None, 'sitename': '新华网 ', 'title': "（受权<font color='red'>发布</font>）...

TypeError: 'NoneType' object is not subscriptable
2022-05-13 09:53:24.253 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E6%AC%A7%E7%9B%9F%E5%8F%91%E5%B8%83%E6%89%A9%E5%A4%A7%E5%9C%B0%E7%90%86%E6%A0%87%E5%BF%97%E8%AE%A1%E5%88%92%E6%96%B0%E6%8F%90%E6%A1%88&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=0 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 10:00:07.563 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%BF%84%E7%BD%97%E6%96%AF%E4%B8%BE%E8%A1%8C%E8%83%9C%E5%88%A9%E6%97%A5%E9%98%85%E5%85%B5&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=60 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 10:00:18.430 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误'NoneType' object is not subscriptable
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fea32858a60>
    └ <Thread(Thread-267, started daemon 140635994572544)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fea32858790>
    └ <Thread(Thread-267, started daemon 140635994572544)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-267, started daemon 140635994572544)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-267, started daemon 140635994572544)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>>
    └ <Thread(Thread-267, started daemon 140635994572544)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe91ac39ee0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
    └ <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe91a90cc10>, 'test': <monitor.TimeSection object at 0x7fe9185fc8b0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fe9007629d0>
    │    │                                │              │         └ '技术进步赋予多重优点，无人机成为军事竞争新热点'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe91ac3a040>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fea10c63a60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fe9007629d0>
               │    │                        │         └ '技术进步赋予多重优点，无人机成为军事竞争新热点'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe91ac3a160>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7fe8bc4572e0>
        │          │    │       │                                  │        │           └ '技术进步赋予多重优点，无人机成为军事竞争新热点'
        │          │    │       │                                  │        └ <string.Template object at 0x7fe8bc7dffa0>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe91a84c880>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
        └ <GET http://www.qstheory.cn/qshyjx/2021-03/16/c_1127215712.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 28, in get_request_from_keyword
    for res in json_response['results']:
        │      └ None
        └ {'des': "蓝图已经擘画，逐梦惟有笃行。以好作风保障<font color='red'>新</font>征程，要从百年党史中汲取营养和力量，赓续艰苦奋斗", 'pubtime': '2021-03-16 09:47:38', 'author':...

TypeError: 'NoneType' object is not subscriptable
2022-05-13 10:00:18.440 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误'NoneType' object is not subscriptable
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fea32858a60>
    └ <Thread(Thread-337, started daemon 140634929223424)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fea32858790>
    └ <Thread(Thread-337, started daemon 140634929223424)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-337, started daemon 140634929223424)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-337, started daemon 140634929223424)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>>
    └ <Thread(Thread-337, started daemon 140634929223424)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe91ac39ee0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
    └ <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe91a90cc10>, 'test': <monitor.TimeSection object at 0x7fe9185fc8b0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fe8dc599310>
    │    │                                │              │         └ '沈跃跃出席2022上合组织民间友好论坛开幕式并致辞'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe91ac3a040>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fea10c63a60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fe8dc599310>
               │    │                        │         └ '沈跃跃出席2022上合组织民间友好论坛开幕式并致辞'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe91ac3a160>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7fe8bc453fd0>
        │          │    │       │                                  │        │           └ '沈跃跃出席2022上合组织民间友好论坛开幕式并致辞'
        │          │    │       │                                  │        └ <string.Template object at 0x7fe8dc55f0d0>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe91a84c880>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
        └ <GET http://www.qstheory.cn/laigao/ycjx/2020-10/15/c_1126615800.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 28, in get_request_from_keyword
    for res in json_response['results']:
        │      └ None
        └ {'des': None, 'pubtime': '2020-10-15 16:59:35', 'author': '求是记者 吴晓迪', 'sitename': '求是网 ', 'title': "百城千县万村调研行 | “把支部建在电梯<font...

TypeError: 'NoneType' object is not subscriptable
2022-05-13 10:01:58.061 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E6%B9%98%E6%BD%AD%E5%9B%9B%E7%94%B7%E5%AD%90%E4%BE%B5%E7%8A%AF%E5%85%AC%E6%B0%91%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF%E5%88%86%E8%8E%B7%E5%88%91%E7%BD%9A&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=20 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 10:02:24.800 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E6%B9%98%E6%BD%AD%E5%9B%9B%E7%94%B7%E5%AD%90%E4%BE%B5%E7%8A%AF%E5%85%AC%E6%B0%91%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF%E5%88%86%E8%8E%B7%E5%88%91%E7%BD%9A&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=60 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 10:03:57.573 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%BB%A5%E6%88%91%E6%97%A0%E5%90%8D%EF%BC%8C%E6%88%90%E5%B0%B1%E9%95%BF%E5%89%91%E5%A8%81%E5%90%8D&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=20 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 10:04:41.768 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E5%8D%83%E9%87%8C%E5%90%8C%E5%A0%82%E5%85%B1%E7%A0%BA%E5%BC%BA%E5%86%9B%E5%BF%97&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=0 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 10:05:44.728 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误'NoneType' object is not subscriptable
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fea32858a60>
    └ <Thread(Thread-421, started daemon 140633821910784)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fea32858790>
    └ <Thread(Thread-421, started daemon 140633821910784)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-421, started daemon 140633821910784)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-421, started daemon 140633821910784)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>>
    └ <Thread(Thread-421, started daemon 140633821910784)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe91ac39ee0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
    └ <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe91a90cc10>, 'test': <monitor.TimeSection object at 0x7fe9185fc8b0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fe900761760>
    │    │                                │              │         └ '欧盟发布扩大地理标志计划新提案'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe91ac3a040>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fea10c63a60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fe900761760>
               │    │                        │         └ '欧盟发布扩大地理标志计划新提案'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe91ac3a160>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7fe85c694910>
        │          │    │       │                                  │        │           └ '欧盟发布扩大地理标志计划新提案'
        │          │    │       │                                  │        └ <string.Template object at 0x7fe8bc12c5e0>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe91a84c880>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
        └ <GET http://www.qstheory.cn/laigao/ycjx/2021-02/06/c_1127072993.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 28, in get_request_from_keyword
    for res in json_response['results']:
        │      └ None
        └ {'des': None, 'pubtime': '2021-02-06 17:12:36', 'author': '是说新语', 'sitename': '求是网 ', 'title': "奋斗百年路 启航<font color='red'>新</...

TypeError: 'NoneType' object is not subscriptable
2022-05-13 10:06:09.562 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E5%8C%97%E4%BA%AC4%E5%9C%B0%E5%8D%87%E7%BA%A7%E4%B8%BA%E9%AB%98%E9%A3%8E%E9%99%A9%E5%9C%B0%E5%8C%BA&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=40 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 10:09:06.419 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%BC%8A%E6%9C%97%E5%A4%96%E4%BA%A4%E9%83%A8%EF%BC%9A%E6%AC%A7%E7%9B%9F%E4%BB%A3%E8%A1%A8%E8%AE%BF%E9%97%AE%E4%BC%8A%E6%9C%97%E5%B0%86%E4%BD%BF%E4%BC%8A%E6%A0%B8%E8%B0%88%E5%88%A4%E6%9C%9D%E6%AD%A3%E7%A1%AE%E6%96%B9%E5%90%91%E8%BF%88%E8%BF%9B&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=0 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 10:09:27.512 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E6%B9%98%E6%BD%AD%E5%9B%9B%E7%94%B7%E5%AD%90%E4%BE%B5%E7%8A%AF%E5%85%AC%E6%B0%91%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF%E5%88%86%E8%8E%B7%E5%88%91%E7%BD%9A&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=50 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 10:09:57.909 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E5%8D%A1%E5%A1%94%E5%B0%94%E5%9F%83%E7%B1%B3%E5%B0%94%E8%AE%BF%E9%97%AE%E4%BC%8A%E6%9C%97&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=30 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 10:10:06.442 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 502
2022-05-13 10:11:07.763 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 502
2022-05-13 10:12:18.918 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 10:13:41.239 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误'NoneType' object is not subscriptable
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fea32858a60>
    └ <Thread(Thread-337, started daemon 140634929223424)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fea32858790>
    └ <Thread(Thread-337, started daemon 140634929223424)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-337, started daemon 140634929223424)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-337, started daemon 140634929223424)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>>
    └ <Thread(Thread-337, started daemon 140634929223424)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe91ac39ee0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
    └ <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe91a90cc10>, 'test': <monitor.TimeSection object at 0x7fe9185fc8b0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fe8dc599310>
    │    │                                │              │         └ '马拉喀什条约对我国生效 极大丰富阅读障碍者精神文化生活'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe91ac3a040>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fea10c63a60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fe8dc599310>
               │    │                        │         └ '马拉喀什条约对我国生效 极大丰富阅读障碍者精神文化生活'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe91ac3a160>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7fe89c374760>
        │          │    │       │                                  │        │           └ '马拉喀什条约对我国生效 极大丰富阅读障碍者精神文化生活'
        │          │    │       │                                  │        └ <string.Template object at 0x7fe8dc3f7f70>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe91a84c880>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
        └ <GET http://www.qstheory.cn/2021-09/06/c_1127809963.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 28, in get_request_from_keyword
    for res in json_response['results']:
        │      └ None
        └ {'des': None, 'pubtime': '2021-09-06 11:19:42', 'author': None, 'sitename': None, 'title': "寻<font color='red'>我</font>们将来永远的...

TypeError: 'NoneType' object is not subscriptable
2022-05-13 10:13:41.255 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误'NoneType' object is not subscriptable
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fea32858a60>
    └ <Thread(Thread-426, started daemon 140633838696192)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fea32858790>
    └ <Thread(Thread-426, started daemon 140633838696192)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-426, started daemon 140633838696192)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-426, started daemon 140633838696192)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>>
    └ <Thread(Thread-426, started daemon 140633838696192)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fe91ac39ee0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
    └ <monitor.projectManager.ProjectManager object at 0x7fea09a564f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fe91a90cc10>, 'test': <monitor.TimeSection object at 0x7fe9185fc8b0>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fe87c5aff40>
    │    │                                │              │         └ '沈跃跃出席2022上合组织民间友好论坛开幕式并致辞'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fe91ac3a040>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fea10c63a60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fe87c5aff40>
               │    │                        │         └ '沈跃跃出席2022上合组织民间友好论坛开幕式并致辞'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fe91ac3a160>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7fe89c171670>
        │          │    │       │                                  │        │           └ '沈跃跃出席2022上合组织民间友好论坛开幕式并致辞'
        │          │    │       │                                  │        └ <string.Template object at 0x7fe89c637940>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fe91a84c880>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7fe91a84c280>
        └ <GET http://www.qstheory.cn/yaowen/2021-11/10/c_1128051005.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 28, in get_request_from_keyword
    for res in json_response['results']:
        │      └ None
        └ {'des': "以视频方式<font color='red'>出席</font>亚太经<font color='red'>合组织</font>第二十八次领导人非正式会议并发表重要讲话，并于11日以预录视频方式<font color='red'>出席...

TypeError: 'NoneType' object is not subscriptable
2022-05-13 10:14:05.782 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 10:14:07.542 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 10:14:51.569 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 10:14:59.516 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 10:15:03.961 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 10:15:04.386 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 10:15:04.792 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 10:15:06.170 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:62 - E 微博检索 504
2022-05-13 10:16:09.546 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E6%B2%88%E8%B7%83%E8%B7%83%E5%87%BA%E5%B8%AD2022%E4%B8%8A%E5%90%88%E7%BB%84%E7%BB%87%E6%B0%91%E9%97%B4%E5%8F%8B%E5%A5%BD%E8%AE%BA%E5%9D%9B%E5%BC%80%E5%B9%95%E5%BC%8F%E5%B9%B6%E8%87%B4%E8%BE%9E&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=10 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 13:41:46.666 | ERROR    | monitor.searchSpiders.qinagguoLT:get_request_from_keyword:27 - E 强国论坛错误HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Read timed out. (read timeout=None)
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 445, in _make_request
    six.raise_from(e, None)
    │   └ <function raise_from at 0x7f12bb0eb820>
    └ <module 'urllib3.packages.six' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py'>
  File "<string>", line 3, in raise_from
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 440, in _make_request
    httplib_response = conn.getresponse()
                       │    └ <function HTTPConnection.getresponse at 0x7f12d2610310>
                       └ <urllib3.connection.HTTPConnection object at 0x7f11a84f6790>
  File "/usr/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
    │        └ <function HTTPResponse.begin at 0x7f12d260e670>
    └ <http.client.HTTPResponse object at 0x7f10207ec880>
  File "/usr/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
                              │    └ <function HTTPResponse._read_status at 0x7f12d260e5e0>
                              └ <http.client.HTTPResponse object at 0x7f10207ec880>
  File "/usr/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               │    │           └ 65536
               │    └ None
               └ <http.client.HTTPResponse object at 0x7f10207ec880>
  File "/usr/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
           │    │               └ <memory at 0x7f10207a9ac0>
           │    └ None
           └ <socket.SocketIO object at 0x7f10207ec1c0>

TimeoutError: [Errno 110] Connection timed out


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f12bae29ee0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f108867feb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f12bae6c280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 532, in increment
    raise six.reraise(type(error), error, _stacktrace)
          │   │            │       │      └ <traceback object at 0x7f0f7b591500>
          │   │            │       └ ReadTimeoutError("HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Read timed out. (read timeout=None)")
          │   │            └ ReadTimeoutError("HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Read timed out. (read timeout=None)")
          │   └ <function reraise at 0x7f12bb0eb790>
          └ <module 'urllib3.packages.six' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py", line 770, in reraise
    raise value
          └ None
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f12bae29ca0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f108867feb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 447, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    │    │                         │                  └ None
    │    │                         └ '/board/1.html'
    │    └ <function HTTPConnectionPool._raise_timeout at 0x7f12bae29c10>
    └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f108867feb0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 353, in _raise_timeout
    raise ReadTimeoutError(
          └ <class 'urllib3.exceptions.ReadTimeoutError'>

urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Read timed out. (read timeout=None)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f12e2dd3a60>
    └ <Thread(Thread-2097, started daemon 139704227227392)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f12e2dd3790>
    └ <Thread(Thread-2097, started daemon 139704227227392)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-2097, started daemon 139704227227392)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-2097, started daemon 139704227227392)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f11cb193160>>
    └ <Thread(Thread-2097, started daemon 139704227227392)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f11cb192f70>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
    └ <monitor.projectManager.ProjectManager object at 0x7f11cb193160>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f11caeb8fd0>, 'test': <monitor.TimeSection object at 0x7f11cae7bd30>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f116841fcd0>
    │    │                                │              │         └ '德国和乌克兰两国总统通电话'
    │    │                                │              └ '强国论坛'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f11cb1940d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f12c11dea60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f116841fcd0>
               │    │                        │         └ '德国和乌克兰两国总统通电话'
               │    │                        └ '强国论坛'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f11cb1941f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f10886f0d00>
                   │    │       │                                  │        │           └ '德国和乌克兰两国总统通电话'
                   │    │       │                                  │        └ <string.Template object at 0x7f11685fc1c0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (X11;...
                   │    │       └ '强国论坛'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f11cadbaf40>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qinagguoLT.py", line 18, in get_request_from_keyword
    response = requests.get(search_url.substitute(), headers=headers)
               │        │   │          │                     └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (X11;...
               │        │   │          └ <function Template.substitute at 0x7f12e2dbc0d0>
               │        │   └ <string.Template object at 0x7f11685fc1c0>
               │        └ <function get at 0x7f12bacb2430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozil...
           │              │           └ None
           │              └ 'http://bbs1.people.com.cn/board/1.html'
           └ <function request at 0x7f12baca3280>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'Use...
           │       │              │           └ 'http://bbs1.people.com.cn/board/1.html'
           │       │              └ 'get'
           │       └ <function Session.request at 0x7f12bacbbb80>
           └ <requests.sessions.Session object at 0x7f1188274a30>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7f12bacb2040>
           └ <requests.sessions.Session object at 0x7f1188274a30>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7f12bacbb4c0>
        └ <requests.adapters.HTTPAdapter object at 0x7f1168736fd0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
          │                      └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.ReadTimeout'>

requests.exceptions.ReadTimeout: HTTPConnectionPool(host='bbs1.people.com.cn', port=80): Read timed out. (read timeout=None)
2022-05-13 14:30:28.694 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 445, in _make_request
    six.raise_from(e, None)
    │   └ <function raise_from at 0x7f12bb0eb820>
    └ <module 'urllib3.packages.six' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py'>
  File "<string>", line 3, in raise_from
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 440, in _make_request
    httplib_response = conn.getresponse()
                       │    └ <function HTTPConnection.getresponse at 0x7f12d2610310>
                       └ <urllib3.connection.HTTPConnection object at 0x7f0f189f0400>
  File "/usr/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
    │        └ <function HTTPResponse.begin at 0x7f12d260e670>
    └ <http.client.HTTPResponse object at 0x7f0f86c1dc10>
  File "/usr/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
                              │    └ <function HTTPResponse._read_status at 0x7f12d260e5e0>
                              └ <http.client.HTTPResponse object at 0x7f0f86c1dc10>
  File "/usr/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               │    │           └ 65536
               │    └ None
               └ <http.client.HTTPResponse object at 0x7f0f86c1dc10>
  File "/usr/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
           │    │               └ <memory at 0x7f0fbed3fa00>
           │    └ None
           └ <socket.SocketIO object at 0x7f10c878fa30>

socket.timeout: timed out


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f12bae29ee0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f0f191cfcd0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f12bae6c280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 532, in increment
    raise six.reraise(type(error), error, _stacktrace)
          │   │            │       │      └ <traceback object at 0x7f0fe6b1b8c0>
          │   │            │       └ ReadTimeoutError("HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)")
          │   │            └ ReadTimeoutError("HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)")
          │   └ <function reraise at 0x7f12bb0eb790>
          └ <module 'urllib3.packages.six' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py", line 770, in reraise
    raise value
          └ None
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f12bae29ca0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f0f191cfcd0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 447, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    │    │                         │                  └ 10
    │    │                         └ '/qiushi/more?callback=jsonpCallback&page=38&keyword=%E5%BE%B7%E5%9B%BD%E5%92%8C%E4%B9%8C%E5%85%8B%E5%85%B0%E4%B8%A4%E5%9B%BD...
    │    └ <function HTTPConnectionPool._raise_timeout at 0x7f12bae29c10>
    └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f0f191cfcd0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 336, in _raise_timeout
    raise ReadTimeoutError(
          └ <class 'urllib3.exceptions.ReadTimeoutError'>

urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f12e2dd3a60>
    └ <Thread(Thread-3003, started daemon 139702871045888)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f12e2dd3790>
    └ <Thread(Thread-3003, started daemon 139702871045888)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-3003, started daemon 139702871045888)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-3003, started daemon 139702871045888)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f11cb193160>>
    └ <Thread(Thread-3003, started daemon 139702871045888)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f11cb192f70>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
    └ <monitor.projectManager.ProjectManager object at 0x7f11cb193160>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f11caeb8fd0>, 'test': <monitor.TimeSection object at 0x7f11cae7bd30>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f0f802be7c0>
    │    │                                │              │         └ '德国和乌克兰两国总统通电话'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f11cb1940d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f12c11dea60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f0f802be7c0>
               │    │                        │         └ '德国和乌克兰两国总统通电话'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f11cb1941f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f0f408c77f0>
        │          │    │       │                                  │        │           └ '德国和乌克兰两国总统通电话'
        │          │    │       │                                  │        └ <string.Template object at 0x7f0f20b42fd0>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f11cadbaf40>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
        └ <GET http://www.qstheory.cn/laigao/ycjx/2021-12/11/c_1128153839.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 26, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=10)
               │        │   │            └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
               │        │   └ 'http://so.news.cn/qiushi/more?callback=jsonpCallback&page=38&keyword=德国和乌克兰两国总统通电话&searchword=(LinkTitle%3D%E5%AD%9F%E6%99%9...
               │        └ <function get at 0x7f12bacb2430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozil...
           │              │           └ None
           │              └ 'http://so.news.cn/qiushi/more?callback=jsonpCallback&page=38&keyword=德国和乌克兰两国总统通电话&searchword=(LinkTitle%3D%E5%AD%9F%E6%99%9...
           └ <function request at 0x7f12baca3280>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'Use...
           │       │              │           └ 'http://so.news.cn/qiushi/more?callback=jsonpCallback&page=38&keyword=德国和乌克兰两国总统通电话&searchword=(LinkTitle%3D%E5%AD%9F%E6%99%9...
           │       │              └ 'get'
           │       └ <function Session.request at 0x7f12bacbbb80>
           └ <requests.sessions.Session object at 0x7f10a8211160>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 10, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7f12bacb2040>
           └ <requests.sessions.Session object at 0x7f10a8211160>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': 10, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7f12bacbb4c0>
        └ <requests.adapters.HTTPAdapter object at 0x7f10a81b4490>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
          │                      └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.ReadTimeout'>

requests.exceptions.ReadTimeout: HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)
2022-05-13 14:30:53.600 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 445, in _make_request
    six.raise_from(e, None)
    │   └ <function raise_from at 0x7f12bb0eb820>
    └ <module 'urllib3.packages.six' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py'>
  File "<string>", line 3, in raise_from
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 440, in _make_request
    httplib_response = conn.getresponse()
                       │    └ <function HTTPConnection.getresponse at 0x7f12d2610310>
                       └ <urllib3.connection.HTTPConnection object at 0x7f0f89a023d0>
  File "/usr/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
    │        └ <function HTTPResponse.begin at 0x7f12d260e670>
    └ <http.client.HTTPResponse object at 0x7f0f180019d0>
  File "/usr/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
                              │    └ <function HTTPResponse._read_status at 0x7f12d260e5e0>
                              └ <http.client.HTTPResponse object at 0x7f0f180019d0>
  File "/usr/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               │    │           └ 65536
               │    └ None
               └ <http.client.HTTPResponse object at 0x7f0f180019d0>
  File "/usr/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
           │    │               └ <memory at 0x7f0f175f8880>
           │    └ None
           └ <socket.SocketIO object at 0x7f0fa27efbe0>

socket.timeout: timed out


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f12bae29ee0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f0f89a018b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f12bae6c280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 532, in increment
    raise six.reraise(type(error), error, _stacktrace)
          │   │            │       │      └ <traceback object at 0x7f1048113780>
          │   │            │       └ ReadTimeoutError("HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)")
          │   │            └ ReadTimeoutError("HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)")
          │   └ <function reraise at 0x7f12bb0eb790>
          └ <module 'urllib3.packages.six' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py", line 770, in reraise
    raise value
          └ None
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f12bae29ca0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f0f89a018b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 447, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    │    │                         │                  └ 10
    │    │                         └ '/qiushi/more?callback=jsonpCallback&page=56&keyword=%E5%BE%B7%E5%9B%BD%E5%92%8C%E4%B9%8C%E5%85%8B%E5%85%B0%E4%B8%A4%E5%9B%BD...
    │    └ <function HTTPConnectionPool._raise_timeout at 0x7f12bae29c10>
    └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f0f89a018b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 336, in _raise_timeout
    raise ReadTimeoutError(
          └ <class 'urllib3.exceptions.ReadTimeoutError'>

urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f12e2dd3a60>
    └ <Thread(Thread-2918, started daemon 139702938449664)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f12e2dd3790>
    └ <Thread(Thread-2918, started daemon 139702938449664)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-2918, started daemon 139702938449664)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-2918, started daemon 139702938449664)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f11cb193160>>
    └ <Thread(Thread-2918, started daemon 139702938449664)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f11cb192f70>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
    └ <monitor.projectManager.ProjectManager object at 0x7f11cb193160>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f11caeb8fd0>, 'test': <monitor.TimeSection object at 0x7f11cae7bd30>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f116822bf40>
    │    │                                │              │         └ '德国和乌克兰两国总统通电话'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f11cb1940d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f12c11dea60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f116822bf40>
               │    │                        │         └ '德国和乌克兰两国总统通电话'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f11cb1941f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f1108710b80>
        │          │    │       │                                  │        │           └ '德国和乌克兰两国总统通电话'
        │          │    │       │                                  │        └ <string.Template object at 0x7f0f624cd8e0>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f11cadbaf40>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
        └ <GET http://www.qstheory.cn/dukan/hqwg/2022-01/26/c_1128302320.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 26, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=10)
               │        │   │            └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
               │        │   └ 'http://so.news.cn/qiushi/more?callback=jsonpCallback&page=56&keyword=德国和乌克兰两国总统通电话&searchword=(LinkTitle%3D%E5%AD%9F%E6%99%9...
               │        └ <function get at 0x7f12bacb2430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozil...
           │              │           └ None
           │              └ 'http://so.news.cn/qiushi/more?callback=jsonpCallback&page=56&keyword=德国和乌克兰两国总统通电话&searchword=(LinkTitle%3D%E5%AD%9F%E6%99%9...
           └ <function request at 0x7f12baca3280>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'Use...
           │       │              │           └ 'http://so.news.cn/qiushi/more?callback=jsonpCallback&page=56&keyword=德国和乌克兰两国总统通电话&searchword=(LinkTitle%3D%E5%AD%9F%E6%99%9...
           │       │              └ 'get'
           │       └ <function Session.request at 0x7f12bacbbb80>
           └ <requests.sessions.Session object at 0x7f0f18dd9e80>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 10, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7f12bacb2040>
           └ <requests.sessions.Session object at 0x7f0f18dd9e80>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': 10, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7f12bacbb4c0>
        └ <requests.adapters.HTTPAdapter object at 0x7f0f2ec46cd0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
          │                      └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.ReadTimeout'>

requests.exceptions.ReadTimeout: HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)
2022-05-13 14:30:56.878 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 445, in _make_request
    six.raise_from(e, None)
    │   └ <function raise_from at 0x7f12bb0eb820>
    └ <module 'urllib3.packages.six' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py'>
  File "<string>", line 3, in raise_from
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 440, in _make_request
    httplib_response = conn.getresponse()
                       │    └ <function HTTPConnection.getresponse at 0x7f12d2610310>
                       └ <urllib3.connection.HTTPConnection object at 0x7f1088058f40>
  File "/usr/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
    │        └ <function HTTPResponse.begin at 0x7f12d260e670>
    └ <http.client.HTTPResponse object at 0x7f1108643730>
  File "/usr/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
                              │    └ <function HTTPResponse._read_status at 0x7f12d260e5e0>
                              └ <http.client.HTTPResponse object at 0x7f1108643730>
  File "/usr/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               │    │           └ 65536
               │    └ None
               └ <http.client.HTTPResponse object at 0x7f1108643730>
  File "/usr/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
           │    │               └ <memory at 0x7f0f1c0254c0>
           │    └ None
           └ <socket.SocketIO object at 0x7f0f34e6ebb0>

socket.timeout: timed out


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f12bae29ee0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f0f49d63850>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f12bae6c280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 532, in increment
    raise six.reraise(type(error), error, _stacktrace)
          │   │            │       │      └ <traceback object at 0x7f118805e280>
          │   │            │       └ ReadTimeoutError("HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)")
          │   │            └ ReadTimeoutError("HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)")
          │   └ <function reraise at 0x7f12bb0eb790>
          └ <module 'urllib3.packages.six' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py", line 770, in reraise
    raise value
          └ None
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f12bae29ca0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f0f49d63850>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 447, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    │    │                         │                  └ 10
    │    │                         └ '/qiushi/more?callback=jsonpCallback&page=41&keyword=%E5%BE%B7%E5%9B%BD%E5%92%8C%E4%B9%8C%E5%85%8B%E5%85%B0%E4%B8%A4%E5%9B%BD...
    │    └ <function HTTPConnectionPool._raise_timeout at 0x7f12bae29c10>
    └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f0f49d63850>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 336, in _raise_timeout
    raise ReadTimeoutError(
          └ <class 'urllib3.exceptions.ReadTimeoutError'>

urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f12e2dd3a60>
    └ <Thread(Thread-3007, started daemon 139702852949760)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f12e2dd3790>
    └ <Thread(Thread-3007, started daemon 139702852949760)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-3007, started daemon 139702852949760)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-3007, started daemon 139702852949760)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f11cb193160>>
    └ <Thread(Thread-3007, started daemon 139702852949760)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f11cb192f70>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
    └ <monitor.projectManager.ProjectManager object at 0x7f11cb193160>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f11caeb8fd0>, 'test': <monitor.TimeSection object at 0x7f11cae7bd30>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f0f640518e0>
    │    │                                │              │         └ '德国和乌克兰两国总统通电话'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f11cb1940d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f12c11dea60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f0f640518e0>
               │    │                        │         └ '德国和乌克兰两国总统通电话'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f11cb1941f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f0f9ede8c10>
        │          │    │       │                                  │        │           └ '德国和乌克兰两国总统通电话'
        │          │    │       │                                  │        └ <string.Template object at 0x7f0f69c08070>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f11cadbaf40>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
        └ <GET http://www.qstheory.cn/qshyjx/2021-08/06/c_1127736013.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 26, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=10)
               │        │   │            └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
               │        │   └ 'http://so.news.cn/qiushi/more?callback=jsonpCallback&page=41&keyword=德国和乌克兰两国总统通电话&searchword=(LinkTitle%3D%E5%AD%9F%E6%99%9...
               │        └ <function get at 0x7f12bacb2430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozil...
           │              │           └ None
           │              └ 'http://so.news.cn/qiushi/more?callback=jsonpCallback&page=41&keyword=德国和乌克兰两国总统通电话&searchword=(LinkTitle%3D%E5%AD%9F%E6%99%9...
           └ <function request at 0x7f12baca3280>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'Use...
           │       │              │           └ 'http://so.news.cn/qiushi/more?callback=jsonpCallback&page=41&keyword=德国和乌克兰两国总统通电话&searchword=(LinkTitle%3D%E5%AD%9F%E6%99%9...
           │       │              └ 'get'
           │       └ <function Session.request at 0x7f12bacbbb80>
           └ <requests.sessions.Session object at 0x7f0f27084ca0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 10, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7f12bacb2040>
           └ <requests.sessions.Session object at 0x7f0f27084ca0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': 10, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7f12bacbb4c0>
        └ <requests.adapters.HTTPAdapter object at 0x7f0f8db07400>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
          │                      └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.ReadTimeout'>

requests.exceptions.ReadTimeout: HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)
2022-05-13 14:31:50.581 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 445, in _make_request
    six.raise_from(e, None)
    │   └ <function raise_from at 0x7f12bb0eb820>
    └ <module 'urllib3.packages.six' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py'>
  File "<string>", line 3, in raise_from
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 440, in _make_request
    httplib_response = conn.getresponse()
                       │    └ <function HTTPConnection.getresponse at 0x7f12d2610310>
                       └ <urllib3.connection.HTTPConnection object at 0x7f0f17ffed00>
  File "/usr/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
    │        └ <function HTTPResponse.begin at 0x7f12d260e670>
    └ <http.client.HTTPResponse object at 0x7f0f20b8b8e0>
  File "/usr/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
                              │    └ <function HTTPResponse._read_status at 0x7f12d260e5e0>
                              └ <http.client.HTTPResponse object at 0x7f0f20b8b8e0>
  File "/usr/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               │    │           └ 65536
               │    └ None
               └ <http.client.HTTPResponse object at 0x7f0f20b8b8e0>
  File "/usr/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
           │    │               └ <memory at 0x7f0f18b55d00>
           │    └ None
           └ <socket.SocketIO object at 0x7f10e872cf40>

socket.timeout: timed out


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f12bae29ee0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f1108137760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f12bae6c280>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 532, in increment
    raise six.reraise(type(error), error, _stacktrace)
          │   │            │       │      └ <traceback object at 0x7f0f89ac66c0>
          │   │            │       └ ReadTimeoutError("HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)")
          │   │            └ ReadTimeoutError("HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)")
          │   └ <function reraise at 0x7f12bb0eb790>
          └ <module 'urllib3.packages.six' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/packages/six.py", line 770, in reraise
    raise value
          └ None
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f12bae29ca0>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f1108137760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 447, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    │    │                         │                  └ 10
    │    │                         └ '/qiushi/more?callback=jsonpCallback&page=49&keyword=%E5%BE%B7%E5%9B%BD%E5%92%8C%E4%B9%8C%E5%85%8B%E5%85%B0%E4%B8%A4%E5%9B%BD...
    │    └ <function HTTPConnectionPool._raise_timeout at 0x7f12bae29c10>
    └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f1108137760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 336, in _raise_timeout
    raise ReadTimeoutError(
          └ <class 'urllib3.exceptions.ReadTimeoutError'>

urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f12e2dd3a60>
    └ <Thread(Thread-2948, started daemon 139702913271552)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f12e2dd3790>
    └ <Thread(Thread-2948, started daemon 139702913271552)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-2948, started daemon 139702913271552)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-2948, started daemon 139702913271552)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f11cb193160>>
    └ <Thread(Thread-2948, started daemon 139702913271552)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f11cb192f70>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
    └ <monitor.projectManager.ProjectManager object at 0x7f11cb193160>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f11caeb8fd0>, 'test': <monitor.TimeSection object at 0x7f11cae7bd30>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f1028673f70>
    │    │                                │              │         └ '德国和乌克兰两国总统通电话'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f11cb1940d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f12c11dea60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f1028673f70>
               │    │                        │         └ '德国和乌克兰两国总统通电话'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f11cb1941f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f0f408cb400>
        │          │    │       │                                  │        │           └ '德国和乌克兰两国总统通电话'
        │          │    │       │                                  │        └ <string.Template object at 0x7f0f56e87df0>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f11cadbaf40>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
        └ <GET http://www.qstheory.cn/qshyjx/2021-12/07/c_1128138518.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 26, in get_request_from_keyword
    response = requests.get(url, headers=headers, timeout=10)
               │        │   │            └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
               │        │   └ 'http://so.news.cn/qiushi/more?callback=jsonpCallback&page=49&keyword=德国和乌克兰两国总统通电话&searchword=(LinkTitle%3D%E5%AD%9F%E6%99%9...
               │        └ <function get at 0x7f12bacb2430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
           │              │           │         └ {'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozil...
           │              │           └ None
           │              └ 'http://so.news.cn/qiushi/more?callback=jsonpCallback&page=49&keyword=德国和乌克兰两国总统通电话&searchword=(LinkTitle%3D%E5%AD%9F%E6%99%9...
           └ <function request at 0x7f12baca3280>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'params': None, 'headers': {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'Use...
           │       │              │           └ 'http://so.news.cn/qiushi/more?callback=jsonpCallback&page=49&keyword=德国和乌克兰两国总统通电话&searchword=(LinkTitle%3D%E5%AD%9F%E6%99%9...
           │       │              └ 'get'
           │       └ <function Session.request at 0x7f12bacbbb80>
           └ <requests.sessions.Session object at 0x7f10e86500d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': 10, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [GET]>
           │    └ <function Session.send at 0x7f12bacb2040>
           └ <requests.sessions.Session object at 0x7f10e86500d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': 10, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [GET]>
        │       └ <function HTTPAdapter.send at 0x7f12bacbb4c0>
        └ <requests.adapters.HTTPAdapter object at 0x7f0f9345c7f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
          │                      └ <PreparedRequest [GET]>
          └ <class 'requests.exceptions.ReadTimeout'>

requests.exceptions.ReadTimeout: HTTPConnectionPool(host='so.news.cn', port=80): Read timed out. (read timeout=10)
2022-05-13 15:03:47.445 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误'NoneType' object is not subscriptable
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f12e2dd3a60>
    └ <Thread(Thread-3121, started daemon 139705021896448)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f12e2dd3790>
    └ <Thread(Thread-3121, started daemon 139705021896448)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-3121, started daemon 139705021896448)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-3121, started daemon 139705021896448)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f11cb193160>>
    └ <Thread(Thread-3121, started daemon 139705021896448)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f11cb192f70>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
    └ <monitor.projectManager.ProjectManager object at 0x7f11cb193160>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f11caeb8fd0>, 'test': <monitor.TimeSection object at 0x7f11cae7bd30>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f0fe6a2f4c0>
    │    │                                │              │         └ '德国和乌克兰两国总统通电话'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f11cb1940d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f12c11dea60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f0fe6a2f4c0>
               │    │                        │         └ '德国和乌克兰两国总统通电话'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f11cb1941f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f1188153a30>
        │          │    │       │                                  │        │           └ '德国和乌克兰两国总统通电话'
        │          │    │       │                                  │        └ <string.Template object at 0x7f1188153bb0>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f11cadbaf40>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
        └ <GET http://www.qstheory.cn/qshyjx/2022-03/04/c_1128437345.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 28, in get_request_from_keyword
    for res in json_response['results']:
        │      └ None
        └ {'des': "“<font color='red'>两</font>手抓、<font color='red'>两</font>手都要硬”的战略方针。", 'pubtime': '2022-03-04 15:16:22', 'author': '王...

TypeError: 'NoneType' object is not subscriptable
2022-05-13 15:04:08.938 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误'NoneType' object is not subscriptable
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f12e2dd3a60>
    └ <Thread(Thread-2959, started daemon 139702896486144)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f12e2dd3790>
    └ <Thread(Thread-2959, started daemon 139702896486144)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-2959, started daemon 139702896486144)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-2959, started daemon 139702896486144)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f11cb193160>>
    └ <Thread(Thread-2959, started daemon 139702896486144)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f11cb192f70>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
    └ <monitor.projectManager.ProjectManager object at 0x7f11cb193160>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f11caeb8fd0>, 'test': <monitor.TimeSection object at 0x7f11cae7bd30>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f0f9784cd00>
    │    │                                │              │         └ '德国和乌克兰两国总统通电话'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f11cb1940d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f12c11dea60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f0f9784cd00>
               │    │                        │         └ '德国和乌克兰两国总统通电话'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f11cb1941f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
        │          │    │       │                                  │        │           │        └ <string.Template object at 0x7f106852b100>
        │          │    │       │                                  │        │           └ '德国和乌克兰两国总统通电话'
        │          │    │       │                                  │        └ <string.Template object at 0x7f11280f5070>
        │          │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
        │          │    │       └ '求是'
        │          │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f11cadbaf40>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
        │          └ <monitor.spiderManager.SearchSpidersManager object at 0x7f11cadbac70>
        └ <GET http://www.qstheory.cn/2021-06/05/c_1127532416.htm>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 28, in get_request_from_keyword
    for res in json_response['results']:
        │      └ None
        └ {'des': "“<font color='red'>两</font>弹一星”先进群体荣获“最美奋斗者”称号。", 'pubtime': '2021-06-05 10:37:09', 'author': '记者 喻思南', 'sitename': ...

TypeError: 'NoneType' object is not subscriptable
2022-05-13 15:19:31.091 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177706759.html
2022-05-13 15:19:36.232 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177702921.html
2022-05-13 15:19:55.106 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/2/1/2/177703643.html
2022-05-13 15:30:20.151 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177706759.html
2022-05-13 15:30:28.459 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177702921.html
2022-05-13 15:30:50.215 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/2/1/2/177703643.html
2022-05-13 15:36:18.684 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:63 - E 微博检索 502
2022-05-13 15:37:22.322 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa27b7e4a60>
    └ <Thread(Thread-74, started daemon 140331126019840)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa27b7e4790>
    └ <Thread(Thread-74, started daemon 140331126019840)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-74, started daemon 140331126019840)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-74, started daemon 140331126019840)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>>
    └ <Thread(Thread-74, started daemon 140331126019840)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fa163ba1f70>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>
    └ <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fa1638c4c10>, 'test': <monitor.TimeSection object at 0x7fa16385b880>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fa162edc670>
    │    │                                │              │         └ '土耳其4月CPI同比涨幅近70%'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fa163ba30d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fa259befa60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fa162edc670>
               │    │                        │         └ '土耳其4月CPI同比涨幅近70%'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fa163ba31f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fa163b9fc70>
                   │    │       │                                  │        │           └ '土耳其4月CPI同比涨幅近70%'
                   │    │       │                                  │        └ <string.Template object at 0x7fa1637b33d0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
                   │    │       └ '求是'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fa1637d0070>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 22, in get_request_from_keyword
    page_json = json.loads(page_response.text[14:-2])
                │    │     │             └ <property object at 0x7fa2536a2db0>
                │    │     └ <Response [404]>
                │    └ <function loads at 0x7fa27b6b1f70>
                └ <module 'json' from '/usr/lib/python3.8/json/__init__.py'>

  File "/usr/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
           │                │      └ ''
           │                └ <function JSONDecoder.decode at 0x7fa27b6b18b0>
           └ <json.decoder.JSONDecoder object at 0x7fa27b6a9760>
  File "/usr/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ ''
               │    │          │      └ <built-in method match of re.Pattern object at 0x7fa27b6d4f30>
               │    │          └ ''
               │    └ <function JSONDecoder.raw_decode at 0x7fa27b6b1940>
               └ <json.decoder.JSONDecoder object at 0x7fa27b6a9760>
  File "/usr/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
          │                                  └ ''
          └ <class 'json.decoder.JSONDecodeError'>

json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2022-05-13 15:40:28.412 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa27b7e4a60>
    └ <Thread(Thread-74, started daemon 140331126019840)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa27b7e4790>
    └ <Thread(Thread-74, started daemon 140331126019840)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-74, started daemon 140331126019840)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-74, started daemon 140331126019840)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>>
    └ <Thread(Thread-74, started daemon 140331126019840)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fa163ba1f70>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>
    └ <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fa1638c4c10>, 'test': <monitor.TimeSection object at 0x7fa16385b880>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fa162edc670>
    │    │                                │              │         └ '日本3月家庭消费同比下降2.3%'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fa163ba30d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fa259befa60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fa162edc670>
               │    │                        │         └ '日本3月家庭消费同比下降2.3%'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fa163ba31f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fa16382bc70>
                   │    │       │                                  │        │           └ '日本3月家庭消费同比下降2.3%'
                   │    │       │                                  │        └ <string.Template object at 0x7fa1637b9dc0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
                   │    │       └ '求是'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fa1637d0070>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 22, in get_request_from_keyword
    page_json = json.loads(page_response.text[14:-2])
                │    │     │             └ <property object at 0x7fa2536a2db0>
                │    │     └ <Response [404]>
                │    └ <function loads at 0x7fa27b6b1f70>
                └ <module 'json' from '/usr/lib/python3.8/json/__init__.py'>

  File "/usr/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
           │                │      └ ''
           │                └ <function JSONDecoder.decode at 0x7fa27b6b18b0>
           └ <json.decoder.JSONDecoder object at 0x7fa27b6a9760>
  File "/usr/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ ''
               │    │          │      └ <built-in method match of re.Pattern object at 0x7fa27b6d4f30>
               │    │          └ ''
               │    └ <function JSONDecoder.raw_decode at 0x7fa27b6b1940>
               └ <json.decoder.JSONDecoder object at 0x7fa27b6a9760>
  File "/usr/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
          │                                  └ ''
          └ <class 'json.decoder.JSONDecodeError'>

json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2022-05-13 15:40:38.053 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177706759.html
2022-05-13 15:40:46.302 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177702921.html
2022-05-13 15:40:52.131 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa27b7e4a60>
    └ <Thread(Thread-138, started daemon 140331117627136)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa27b7e4790>
    └ <Thread(Thread-138, started daemon 140331117627136)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-138, started daemon 140331117627136)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-138, started daemon 140331117627136)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>>
    └ <Thread(Thread-138, started daemon 140331117627136)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fa163ba1f70>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>
    └ <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fa1638c4c10>, 'test': <monitor.TimeSection object at 0x7fa16385b880>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fa161c75c70>
    │    │                                │              │         └ '土耳其4月CPI同比涨幅近70%'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fa163ba30d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fa259befa60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fa161c75c70>
               │    │                        │         └ '土耳其4月CPI同比涨幅近70%'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fa163ba31f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fa161c8c280>
                   │    │       │                                  │        │           └ '土耳其4月CPI同比涨幅近70%'
                   │    │       │                                  │        └ <string.Template object at 0x7fa163b72fa0>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
                   │    │       └ '求是'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fa1637d0070>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 22, in get_request_from_keyword
    page_json = json.loads(page_response.text[14:-2])
                │    │     │             └ <property object at 0x7fa2536a2db0>
                │    │     └ <Response [404]>
                │    └ <function loads at 0x7fa27b6b1f70>
                └ <module 'json' from '/usr/lib/python3.8/json/__init__.py'>

  File "/usr/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
           │                │      └ ''
           │                └ <function JSONDecoder.decode at 0x7fa27b6b18b0>
           └ <json.decoder.JSONDecoder object at 0x7fa27b6a9760>
  File "/usr/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ ''
               │    │          │      └ <built-in method match of re.Pattern object at 0x7fa27b6d4f30>
               │    │          └ ''
               │    └ <function JSONDecoder.raw_decode at 0x7fa27b6b1940>
               └ <json.decoder.JSONDecoder object at 0x7fa27b6a9760>
  File "/usr/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
          │                                  └ ''
          └ <class 'json.decoder.JSONDecodeError'>

json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2022-05-13 15:41:11.081 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/2/1/2/177703643.html
2022-05-13 15:43:59.471 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa27b7e4a60>
    └ <Thread(Thread-138, started daemon 140331117627136)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa27b7e4790>
    └ <Thread(Thread-138, started daemon 140331117627136)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-138, started daemon 140331117627136)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-138, started daemon 140331117627136)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>>
    └ <Thread(Thread-138, started daemon 140331117627136)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fa163ba1f70>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>
    └ <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fa1638c4c10>, 'test': <monitor.TimeSection object at 0x7fa16385b880>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fa161c75c70>
    │    │                                │              │         └ '日本3月家庭消费同比下降2.3%'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fa163ba30d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fa259befa60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fa161c75c70>
               │    │                        │         └ '日本3月家庭消费同比下降2.3%'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fa163ba31f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fa161dcbb80>
                   │    │       │                                  │        │           └ '日本3月家庭消费同比下降2.3%'
                   │    │       │                                  │        └ <string.Template object at 0x7fa161d87670>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
                   │    │       └ '求是'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fa1637d0070>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 22, in get_request_from_keyword
    page_json = json.loads(page_response.text[14:-2])
                │    │     │             └ <property object at 0x7fa2536a2db0>
                │    │     └ <Response [404]>
                │    └ <function loads at 0x7fa27b6b1f70>
                └ <module 'json' from '/usr/lib/python3.8/json/__init__.py'>

  File "/usr/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
           │                │      └ ''
           │                └ <function JSONDecoder.decode at 0x7fa27b6b18b0>
           └ <json.decoder.JSONDecoder object at 0x7fa27b6a9760>
  File "/usr/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ ''
               │    │          │      └ <built-in method match of re.Pattern object at 0x7fa27b6d4f30>
               │    │          └ ''
               │    └ <function JSONDecoder.raw_decode at 0x7fa27b6b1940>
               └ <json.decoder.JSONDecoder object at 0x7fa27b6a9760>
  File "/usr/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
          │                                  └ ''
          └ <class 'json.decoder.JSONDecodeError'>

json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2022-05-13 15:46:21.226 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177698826.html
2022-05-13 15:49:29.846 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177698826.html
2022-05-13 15:50:25.482 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177706759.html
2022-05-13 15:50:30.679 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177702921.html
2022-05-13 15:50:55.555 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/2/1/2/177703643.html
2022-05-13 15:51:06.000 | ERROR    | monitor.searchSpiders.qiushi:get_request_from_keyword:35 - E 求是错误Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa27b7e4a60>
    └ <Thread(Thread-202, started daemon 140331105974016)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa27b7e4790>
    └ <Thread(Thread-202, started daemon 140331105974016)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-202, started daemon 140331105974016)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-202, started daemon 140331105974016)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>>
    └ <Thread(Thread-202, started daemon 140331105974016)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 815, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7fa163ba1f70>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>
    └ <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times, titles)
    │    │                                │              │         │        │           │              └ None
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7fa1638c4c10>, 'test': <monitor.TimeSection object at 0x7fa16385b880>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7fa161da56d0>
    │    │                                │              │         └ '日本3月家庭消费同比下降2.3%'
    │    │                                │              └ '求是'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7fa163ba30d0>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 145, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7fa259befa60>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7fa161da56d0>
               │    │                        │         └ '日本3月家庭消费同比下降2.3%'
               │    │                        └ '求是'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7fa163ba31f0>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 209, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7fa161d8b7c0>
                   │    │       │                                  │        │           └ '日本3月家庭消费同比下降2.3%'
                   │    │       │                                  │        └ <string.Template object at 0x7fa161d8b520>
                   │    │       │                                  └ {'Connection': 'keep-alive', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Wind...
                   │    │       └ '求是'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7fa1637d0070>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7fa1637d04f0>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/qiushi.py", line 22, in get_request_from_keyword
    page_json = json.loads(page_response.text[14:-2])
                │    │     │             └ <property object at 0x7fa2536a2db0>
                │    │     └ <Response [404]>
                │    └ <function loads at 0x7fa27b6b1f70>
                └ <module 'json' from '/usr/lib/python3.8/json/__init__.py'>

  File "/usr/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
           │                │      └ ''
           │                └ <function JSONDecoder.decode at 0x7fa27b6b18b0>
           └ <json.decoder.JSONDecoder object at 0x7fa27b6a9760>
  File "/usr/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ ''
               │    │          │      └ <built-in method match of re.Pattern object at 0x7fa27b6d4f30>
               │    │          └ ''
               │    └ <function JSONDecoder.raw_decode at 0x7fa27b6b1940>
               └ <json.decoder.JSONDecoder object at 0x7fa27b6a9760>
  File "/usr/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
          │                                  └ ''
          └ <class 'json.decoder.JSONDecodeError'>

json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2022-05-13 15:55:04.863 | ERROR    | monitor.searchSpiders.baidu:get_request_from_keyword:31 - E 百度检索HTTPSConnectionPool(host='www.baidu.com', port=443): Max retries exceeded with url: /s?ie=utf-8&medium=2&rtt=1&bsst=1&rsv_dl=news_b_pn&cl=2&wd=%E4%BF%84%E5%A4%96%E9%95%BF%E8%A1%A8%E7%A4%BA%E4%BF%84%E4%B8%8D%E4%BC%9A%E8%B5%B6%E5%9C%A85%E6%9C%889%E6%97%A5%E5%89%8D%E4%BA%BA%E4%B8%BA%E7%BB%93%E6%9D%9F%E7%89%B9%E5%88%AB%E5%86%9B%E4%BA%8B%E8%A1%8C%E5%8A%A8&tn=news&rsv_bp=1&oq=&rsv_btype=t&f=8&x_bfe_rqs=03208&x_bfe_tjscore=0.080000&tngroupname=organic_news&newVideo=12&goods_entry_switch=1&pn=40 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))
2022-05-13 15:56:18.307 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177698826.html
2022-05-13 15:56:50.057 | ERROR    | monitor.searchSpiders.weibo:get_request_from_keyword:63 - E 微博检索 502
2022-05-13 15:59:46.409 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177707523.html
2022-05-13 15:59:50.981 | ERROR    | base.db.mysql:update:390 - 【mysql更新数据出错】
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1771, in _execute_context
    self.dialect.do_execute(
    │    │       └ <function DefaultDialect.do_execute at 0x7fa2531b45e0>
    │    └ <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x7fa1638b6d90>
    └ <sqlalchemy.engine.base.Connection object at 0x7fa161c10be0>
  File "/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 717, in do_execute
    cursor.execute(statement, parameters)
    │      │       │          └ {'server_id': '180.201.163.246:6800', 'ip': '180.201.163.246', 'username': 'chase', 'password': '3786780571376074145996196172...
    │      │       └ 'UPDATE device SET server_id=%(server_id)s, ip=%(ip)s, username=%(username)s, password=%(password)s, address=%(address)s, por...
    │      └ <function Cursor.execute at 0x7fa252e09dc0>
    └ <pymysql.cursors.Cursor object at 0x7fa160739d90>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 148, in execute
    result = self._query(query)
             │    │      └ "UPDATE device SET server_id='180.201.163.246:6800', ip='180.201.163.246', username='chase', password='3786780571376074145996...
             │    └ <function Cursor._query at 0x7fa252d94280>
             └ <pymysql.cursors.Cursor object at 0x7fa160739d90>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 310, in _query
    conn.query(q)
    │    │     └ "UPDATE device SET server_id='180.201.163.246:6800', ip='180.201.163.246', username='chase', password='3786780571376074145996...
    │    └ <function Connection.query at 0x7fa252da2670>
    └ <pymysql.connections.Connection object at 0x7fa161c838b0>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    │    │                │    │                             └ False
    │    │                │    └ <function Connection._read_query_result at 0x7fa252da2ca0>
    │    │                └ <pymysql.connections.Connection object at 0x7fa161c838b0>
    │    └ 1
    └ <pymysql.connections.Connection object at 0x7fa161c838b0>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/connections.py", line 775, in _read_query_result
    result.read()
    │      └ <function MySQLResult.read at 0x7fa252da34c0>
    └ <pymysql.connections.MySQLResult object at 0x7fa162ed1b80>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
                   │    └ None
                   └ <pymysql.connections.MySQLResult object at 0x7fa162ed1b80>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/connections.py", line 725, in _read_packet
    packet.raise_for_error()
    │      └ <function MysqlPacket.raise_for_error at 0x7fa252d9aee0>
    └ <pymysql.protocol.MysqlPacket object at 0x7fa1607398e0>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
    │   │                     │    └ <member '_data' of 'MysqlPacket' objects>
    │   │                     └ <pymysql.protocol.MysqlPacket object at 0x7fa1607398e0>
    │   └ <function raise_mysql_exception at 0x7fa252e49670>
    └ <module 'pymysql.err' from '/home/chase/.local/lib/python3.8/site-packages/pymysql/err.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
          │          │      └ "Duplicate entry '180.201.163.246:6800' for key 'device.PRIMARY'"
          │          └ 1062
          └ <class 'pymysql.err.IntegrityError'>

pymysql.err.IntegrityError: (1062, "Duplicate entry '180.201.163.246:6800' for key 'device.PRIMARY'")


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7fa27b7e4a60>
    └ <Thread(Thread-341, started daemon 140330607310592)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7fa27b7e4790>
    └ <Thread(Thread-341, started daemon 140330607310592)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-341, started daemon 140330607310592)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-341, started daemon 140330607310592)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>>
    └ <Thread(Thread-341, started daemon 140330607310592)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 799, in get_request_from_keywords_hot
    self.start_finished_spider_every_interval(project_names)
    │    │                                    └ ['default', 'test']
    │    └ <function ProjectManager.start_finished_spider_every_interval at 0x7fa1638be280>
    └ <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 784, in start_finished_spider_every_interval
    self[name].start_spider()
    │    └ 'default'
    └ <monitor.projectManager.ProjectManager object at 0x7fa163b9f250>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 366, in start_spider
    self.update_device_valid(device)
    │    │                   └ <monitor.deviceManager.DeviceC object at 0x7fa1638c4730>
    │    └ <function Project.update_device_valid at 0x7fa1638bc280>
    └ <monitor.projectManager.Project object at 0x7fa1638c48e0>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 421, in update_device_valid
    self.database_manager.mysql.update(Device(**device.to_item()))
    │    │                │     │      │        │      └ <function DeviceC.to_item at 0x7fa252daa310>
    │    │                │     │      │        └ <monitor.deviceManager.DeviceC object at 0x7fa1638c4730>
    │    │                │     │      └ <class 'base.db.mysql.Device'>
    │    │                │     └ <function Mysql.update at 0x7fa252eb1790>
    │    │                └ <base.db.mysql.Mysql object at 0x7fa1638b6f40>
    │    └ <base.db.dbSlot.Slot object at 0x7fa1638b6e80>
    └ <monitor.projectManager.Project object at 0x7fa1638c48e0>

> File "/home/users/Scy/yuqing/spider/base/db/mysql.py", line 375, in update
    row.update(new)
    │   │      └ {'server_id': '180.201.163.246:6800', 'ip': '180.201.163.246', 'username': 'chase', 'password': '3786780571376074145996196172...
    │   └ <function Query.update at 0x7fa252ff03a0>
    └ <sqlalchemy.orm.query.Query object at 0x7fa162eb8e80>

  File "/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3221, in update
    result = self.session.execute(
             │    │       └ <function Session.execute at 0x7fa252fccaf0>
             │    └ <sqlalchemy.orm.session.Session object at 0x7fa162eb8d30>
             └ <sqlalchemy.orm.query.Query object at 0x7fa162eb8e80>
  File "/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1689, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
             │    │           │          │             └ immutabledict({'synchronize_session': 'evaluate', '_sa_orm_update_options': default_update_options(_matched_objects=[], _reso...
             │    │           │          └ immutabledict({})
             │    │           └ <sqlalchemy.sql.annotation.AnnotatedUpdate object at 0x7fa160739c40>
             │    └ <function Connection._execute_20 at 0x7fa253279790>
             └ <sqlalchemy.engine.base.Connection object at 0x7fa161c10be0>
  File "/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1583, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           │    │     │             │               └ immutabledict({'synchronize_session': 'evaluate', '_sa_orm_update_options': default_update_options(_matched_objects=[], _reso...
           │    │     │             └ immutabledict({})
           │    │     └ ({},)
           │    └ <sqlalchemy.engine.base.Connection object at 0x7fa161c10be0>
           └ <bound method ClauseElement._execute_on_connection of <sqlalchemy.sql.annotation.AnnotatedUpdate object at 0x7fa160739c40>>
  File "/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 323, in _execute_on_connection
    return connection._execute_clauseelement(
           │          └ <function Connection._execute_clauseelement at 0x7fa2532795e0>
           └ <sqlalchemy.engine.base.Connection object at 0x7fa161c10be0>
  File "/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1452, in _execute_clauseelement
    ret = self._execute_context(
          │    └ <function Connection._execute_context at 0x7fa2532798b0>
          └ <sqlalchemy.engine.base.Connection object at 0x7fa161c10be0>
  File "/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1814, in _execute_context
    self._handle_dbapi_exception(
    │    └ <function Connection._handle_dbapi_exception at 0x7fa253279a60>
    └ <sqlalchemy.engine.base.Connection object at 0x7fa161c10be0>
  File "/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1995, in _handle_dbapi_exception
    util.raise_(
    │    └ <function raise_ at 0x7fa25363aa60>
    └ <module 'sqlalchemy.util' from '/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/util/__init__.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1771, in _execute_context
    self.dialect.do_execute(
    │    │       └ <function DefaultDialect.do_execute at 0x7fa2531b45e0>
    │    └ <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x7fa1638b6d90>
    └ <sqlalchemy.engine.base.Connection object at 0x7fa161c10be0>
  File "/home/chase/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 717, in do_execute
    cursor.execute(statement, parameters)
    │      │       │          └ {'server_id': '180.201.163.246:6800', 'ip': '180.201.163.246', 'username': 'chase', 'password': '3786780571376074145996196172...
    │      │       └ 'UPDATE device SET server_id=%(server_id)s, ip=%(ip)s, username=%(username)s, password=%(password)s, address=%(address)s, por...
    │      └ <function Cursor.execute at 0x7fa252e09dc0>
    └ <pymysql.cursors.Cursor object at 0x7fa160739d90>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 148, in execute
    result = self._query(query)
             │    │      └ "UPDATE device SET server_id='180.201.163.246:6800', ip='180.201.163.246', username='chase', password='3786780571376074145996...
             │    └ <function Cursor._query at 0x7fa252d94280>
             └ <pymysql.cursors.Cursor object at 0x7fa160739d90>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 310, in _query
    conn.query(q)
    │    │     └ "UPDATE device SET server_id='180.201.163.246:6800', ip='180.201.163.246', username='chase', password='3786780571376074145996...
    │    └ <function Connection.query at 0x7fa252da2670>
    └ <pymysql.connections.Connection object at 0x7fa161c838b0>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
    │    │                │    │                             └ False
    │    │                │    └ <function Connection._read_query_result at 0x7fa252da2ca0>
    │    │                └ <pymysql.connections.Connection object at 0x7fa161c838b0>
    │    └ 1
    └ <pymysql.connections.Connection object at 0x7fa161c838b0>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/connections.py", line 775, in _read_query_result
    result.read()
    │      └ <function MySQLResult.read at 0x7fa252da34c0>
    └ <pymysql.connections.MySQLResult object at 0x7fa162ed1b80>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
                   │    └ None
                   └ <pymysql.connections.MySQLResult object at 0x7fa162ed1b80>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/connections.py", line 725, in _read_packet
    packet.raise_for_error()
    │      └ <function MysqlPacket.raise_for_error at 0x7fa252d9aee0>
    └ <pymysql.protocol.MysqlPacket object at 0x7fa1607398e0>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
    │   │                     │    └ <member '_data' of 'MysqlPacket' objects>
    │   │                     └ <pymysql.protocol.MysqlPacket object at 0x7fa1607398e0>
    │   └ <function raise_mysql_exception at 0x7fa252e49670>
    └ <module 'pymysql.err' from '/home/chase/.local/lib/python3.8/site-packages/pymysql/err.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
          │          │      └ "Duplicate entry '180.201.163.246:6800' for key 'device.PRIMARY'"
          │          └ 1062
          └ <class 'pymysql.err.IntegrityError'>

sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry '180.201.163.246:6800' for key 'device.PRIMARY'")
[SQL: UPDATE device SET server_id=%(server_id)s, ip=%(ip)s, username=%(username)s, password=%(password)s, address=%(address)s, port=%(port)s, valid=%(valid)s WHERE device.ip = %(ip_1)s]
[parameters: {'server_id': '180.201.163.246:6800', 'ip': '180.201.163.246', 'username': 'chase', 'password': '37867805713760741459961961725869338902169759829860123196114073145771671648288249350602589743702586632745401787979077175463375166421871420817190711254 ... (10 characters truncated) ... 55086731828061949134184656920211123209313547311437131367882471248024936105343035143887552333721766896101803182776948123332176807506209832690534710651', 'address': '/home/users/CT/pycharmproject/spiders/', 'port': 6800, 'valid': 1, 'ip_1': '180.201.163.246'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
2022-05-13 16:00:46.680 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177706759.html
2022-05-13 16:00:54.922 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177702921.html
2022-05-13 16:00:56.911 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177705855.html
2022-05-13 16:01:19.883 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/2/1/2/177703643.html
2022-05-13 16:02:39.488 | ERROR    | base.utils.time:people_time_from_url:173 - 【url error】url:http://bbs1.people.com.cn/post/1/1/2/177707523.html
