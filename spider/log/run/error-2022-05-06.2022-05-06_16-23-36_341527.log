2022-05-06 16:23:36.269 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f29984b4280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f29984c2670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e514cee0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u96...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f299846a040>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f29a9d07280>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection.endheaders at 0x7f29a9d07160>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection._send_output at 0x7f29a9d6ed30>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f29a9d6eb80>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f2998469e50>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f2998469ca0>
           └ <urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f29984c28b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e514cee0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f29984bec10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e514cee0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f29ba4cba60>
    └ <Thread(Thread-149, started daemon 139810404542208)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f29ba4cb790>
    └ <Thread(Thread-149, started daemon 139810404542208)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-149, started daemon 139810404542208)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-149, started daemon 139810404542208)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>>
    └ <Thread(Thread-149, started daemon 139810404542208)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f28a29c3dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>
    └ <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f28a26d0730>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f28887582b0>
    │    │                                │              │         └ '持续监测病毒  加强疫情防控（国际视点）'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f28a29c3e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f299a95f550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f28887582b0>
               │    │                        │         └ '持续监测病毒  加强疫情防控（国际视点）'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f28a29c3f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f26e21bc250>
                   │    │       │                                  │        │           └ '持续监测病毒  加强疫情防控（国际视点）'
                   │    │       │                                  │        └ <string.Template object at 0x7f270442dd60>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f28a25d1850>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
               │        │    │          └ <function Template.substitute at 0x7f29ba4b40d0>
               │        │    └ <string.Template object at 0x7f270442dd60>
               │        └ <function post at 0x7f299829e430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f299830a0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f299829c9d0>
           └ <requests.sessions.Session object at 0x7f26e1eba160>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f299829ce50>
           └ <requests.sessions.Session object at 0x7f26e1eba160>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f299829c310>
        └ <requests.adapters.HTTPAdapter object at 0x7f2824565b80>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1eeb640>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 16:23:36.603 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f29984b4280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f29984c2670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e1d45250>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u96...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f299846a040>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f29a9d07280>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection.endheaders at 0x7f29a9d07160>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection._send_output at 0x7f29a9d6ed30>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f29a9d6eb80>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f2998469e50>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f2998469ca0>
           └ <urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f29984c28b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e1d45250>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f29984bec10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e1d45250>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f29ba4cba60>
    └ <Thread(Thread-185, started daemon 139809859278592)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f29ba4cb790>
    └ <Thread(Thread-185, started daemon 139809859278592)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-185, started daemon 139809859278592)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-185, started daemon 139809859278592)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>>
    └ <Thread(Thread-185, started daemon 139809859278592)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f28a29c3dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>
    └ <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f28a26d0730>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f2888141370>
    │    │                                │              │         └ '持续监测病毒  加强疫情防控（国际视点）'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f28a29c3e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f299a95f550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f2888141370>
               │    │                        │         └ '持续监测病毒  加强疫情防控（国际视点）'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f28a29c3f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f26e20f5280>
                   │    │       │                                  │        │           └ '持续监测病毒  加强疫情防控（国际视点）'
                   │    │       │                                  │        └ <string.Template object at 0x7f26e2fe11c0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f28a25d1850>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
               │        │    │          └ <function Template.substitute at 0x7f29ba4b40d0>
               │        │    └ <string.Template object at 0x7f26e2fe11c0>
               │        └ <function post at 0x7f299829e430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f299830a0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f299829c9d0>
           └ <requests.sessions.Session object at 0x7f26e34ede50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f299829ce50>
           └ <requests.sessions.Session object at 0x7f26e34ede50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f299829c310>
        └ <requests.adapters.HTTPAdapter object at 0x7f26e4ef8ee0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1d0be20>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 16:23:38.707 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f29984b4280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f29984c2670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f28444609a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u96...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f299846a040>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f29a9d07280>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection.endheaders at 0x7f29a9d07160>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection._send_output at 0x7f29a9d6ed30>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f29a9d6eb80>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f2998469e50>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f2998469ca0>
           └ <urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f29984c28b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f28444609a0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f29984bec10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f28444609a0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f29ba4cba60>
    └ <Thread(Thread-138, started daemon 139810421327616)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f29ba4cb790>
    └ <Thread(Thread-138, started daemon 139810421327616)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-138, started daemon 139810421327616)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-138, started daemon 139810421327616)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>>
    └ <Thread(Thread-138, started daemon 139810421327616)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f28a29c3dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>
    └ <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f28a26d0730>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f28a030cfd0>
    │    │                                │              │         └ '持续监测病毒  加强疫情防控（国际视点）'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f28a29c3e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f299a95f550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f28a030cfd0>
               │    │                        │         └ '持续监测病毒  加强疫情防控（国际视点）'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f28a29c3f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f26e1f10c70>
                   │    │       │                                  │        │           └ '持续监测病毒  加强疫情防控（国际视点）'
                   │    │       │                                  │        └ <string.Template object at 0x7f26e4d604f0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f28a25d1850>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
               │        │    │          └ <function Template.substitute at 0x7f29ba4b40d0>
               │        │    └ <string.Template object at 0x7f26e4d604f0>
               │        └ <function post at 0x7f299829e430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f299830a0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f299829c9d0>
           └ <requests.sessions.Session object at 0x7f26e5156910>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f299829ce50>
           └ <requests.sessions.Session object at 0x7f26e5156910>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f299829c310>
        └ <requests.adapters.HTTPAdapter object at 0x7f272475d430>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1dbe4f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 16:23:42.104 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e20358e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f29984b4280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f29984c2670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e4f82430>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u96...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f299846a040>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e20358e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f26e20358e0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f29a9d07280>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e20358e0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection.endheaders at 0x7f29a9d07160>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e20358e0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection._send_output at 0x7f29a9d6ed30>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e20358e0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f29a9d6eb80>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e20358e0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f2998469e50>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e20358e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f2998469ca0>
           └ <urllib3.connection.HTTPConnection object at 0x7f26e20358e0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f26e20358e0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f29984c28b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e4f82430>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f29984bec10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e20358e0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e4f82430>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e20358e0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f29ba4cba60>
    └ <Thread(Thread-162, started daemon 139809901242112)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f29ba4cb790>
    └ <Thread(Thread-162, started daemon 139809901242112)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-162, started daemon 139809901242112)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-162, started daemon 139809901242112)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>>
    └ <Thread(Thread-162, started daemon 139809901242112)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f28a29c3dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>
    └ <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f28a26d0730>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f2888639850>
    │    │                                │              │         └ '持续监测病毒  加强疫情防控（国际视点）'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f28a29c3e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f299a95f550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f2888639850>
               │    │                        │         └ '持续监测病毒  加强疫情防控（国际视点）'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f28a29c3f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f26e1f7ea00>
                   │    │       │                                  │        │           └ '持续监测病毒  加强疫情防控（国际视点）'
                   │    │       │                                  │        └ <string.Template object at 0x7f26e375b460>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f28a25d1850>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
               │        │    │          └ <function Template.substitute at 0x7f29ba4b40d0>
               │        │    └ <string.Template object at 0x7f26e375b460>
               │        └ <function post at 0x7f299829e430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f299830a0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f299829c9d0>
           └ <requests.sessions.Session object at 0x7f26e197a100>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f299829ce50>
           └ <requests.sessions.Session object at 0x7f26e197a100>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f299829c310>
        └ <requests.adapters.HTTPAdapter object at 0x7f26e193be50>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e20358e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 16:23:42.956 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f29984b4280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f29984c2670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e18eb7f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u8054\\u5408\\u56fd\\u542f\\u52a8\\u884c\\u52a8\\u8ba1\\u5212\\u4fc3\\u8fdb\\u53ef\\u518d\\u751f\\u80fd...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f299846a040>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u8054\\u5408\\u56fd\\u542f\\u52a8\\u884c\\u52a8\\u8ba1\\u5212\\u4fc3\\u8fdb\\u53ef\\u518d\\u751f\\u80fd\\u6e90\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u8054\\u5408\\u56fd\\u542f\\u52a8\\u884c\\u52a8\\u8ba1\\u5212\\u4fc3\\u8fdb\\u53ef\\u518d\\u751f\\u80fd\\u6e90\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f29a9d07280>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u8054\\u5408\\u56fd\\u542f\\u52a8\\u884c\\u52a8\\u8ba1\\u5212\\u4fc3\\u8fdb\\u53ef\\u518d\\u751f\\u80fd\\u6e90\\...
    │    └ <function HTTPConnection.endheaders at 0x7f29a9d07160>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u8054\\u5408\\u56fd\\u542f\\u52a8\\u884c\\u52a8\\u8ba1\\u5212\\u4fc3\\u8fdb\\u53ef\\u518d\\u751f\\u80fd\\u6e90\\...
    │    └ <function HTTPConnection._send_output at 0x7f29a9d6ed30>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f29a9d6eb80>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f2998469e50>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f2998469ca0>
           └ <urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f29984c28b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e18eb7f0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f29984bec10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e18eb7f0>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f29ba4cba60>
    └ <Thread(Thread-619, started daemon 139805010151168)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f29ba4cb790>
    └ <Thread(Thread-619, started daemon 139805010151168)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-619, started daemon 139805010151168)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-619, started daemon 139805010151168)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>>
    └ <Thread(Thread-619, started daemon 139805010151168)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f28a29c3dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>
    └ <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f28a26d0730>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f26e1ef2160>
    │    │                                │              │         └ '联合国启动行动计划促进可再生能源使用'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f28a29c3e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f299a95f550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f26e1ef2160>
               │    │                        │         └ '联合国启动行动计划促进可再生能源使用'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f28a29c3f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f26e1b0ac70>
                   │    │       │                                  │        │           └ '联合国启动行动计划促进可再生能源使用'
                   │    │       │                                  │        └ <string.Template object at 0x7f26e1aa4130>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f28a25d1850>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '联合国启动行动计划促进可再生能源使用', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sort...
               │        │    │          └ <function Template.substitute at 0x7f29ba4b40d0>
               │        │    └ <string.Template object at 0x7f26e1aa4130>
               │        └ <function post at 0x7f299829e430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '联合国启动行动计划促进可再生能源使用', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sort...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f299830a0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '联合国启动行动计划促进可再生能源使用', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy':...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f299829c9d0>
           └ <requests.sessions.Session object at 0x7f26e5101400>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f299829ce50>
           └ <requests.sessions.Session object at 0x7f26e5101400>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f299829c310>
        └ <requests.adapters.HTTPAdapter object at 0x7f26e23bf640>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e1f6a430>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 16:23:42.937 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e19a1160>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f29984b4280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f29984c2670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f27244a6d00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u96...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f299846a040>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e19a1160>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f26e19a1160>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f29a9d07280>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e19a1160>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection.endheaders at 0x7f29a9d07160>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e19a1160>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection._send_output at 0x7f29a9d6ed30>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e19a1160>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f29a9d6eb80>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e19a1160>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f2998469e50>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e19a1160>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f2998469ca0>
           └ <urllib3.connection.HTTPConnection object at 0x7f26e19a1160>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f26e19a1160>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f29984c28b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f27244a6d00>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f29984bec10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e19a1160>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f27244a6d00>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e19a1160>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f29ba4cba60>
    └ <Thread(Thread-226, started daemon 139808827500288)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f29ba4cb790>
    └ <Thread(Thread-226, started daemon 139808827500288)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-226, started daemon 139808827500288)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-226, started daemon 139808827500288)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>>
    └ <Thread(Thread-226, started daemon 139808827500288)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f28a29c3dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>
    └ <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f28a26d0730>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f28886218b0>
    │    │                                │              │         └ '持续监测病毒  加强疫情防控（国际视点）'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f28a29c3e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f299a95f550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f28886218b0>
               │    │                        │         └ '持续监测病毒  加强疫情防控（国际视点）'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f28a29c3f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f26e203d910>
                   │    │       │                                  │        │           └ '持续监测病毒  加强疫情防控（国际视点）'
                   │    │       │                                  │        └ <string.Template object at 0x7f26e1d4b760>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f28a25d1850>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
               │        │    │          └ <function Template.substitute at 0x7f29ba4b40d0>
               │        │    └ <string.Template object at 0x7f26e1d4b760>
               │        └ <function post at 0x7f299829e430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f299830a0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f299829c9d0>
           └ <requests.sessions.Session object at 0x7f26e18d61f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f299829ce50>
           └ <requests.sessions.Session object at 0x7f26e18d61f0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f299829c310>
        └ <requests.adapters.HTTPAdapter object at 0x7f26e19ba340>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e19a1160>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 16:23:43.479 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e19effa0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f29984b4280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f29984c2670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e18a3040>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u96...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f299846a040>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e19effa0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f26e19effa0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f29a9d07280>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e19effa0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection.endheaders at 0x7f29a9d07160>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e19effa0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection._send_output at 0x7f29a9d6ed30>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e19effa0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f29a9d6eb80>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e19effa0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f2998469e50>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e19effa0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f2998469ca0>
           └ <urllib3.connection.HTTPConnection object at 0x7f26e19effa0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f26e19effa0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f29984c28b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e18a3040>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f29984bec10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e19effa0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e18a3040>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e19effa0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f29ba4cba60>
    └ <Thread(Thread-203, started daemon 139809355978496)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f29ba4cb790>
    └ <Thread(Thread-203, started daemon 139809355978496)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-203, started daemon 139809355978496)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-203, started daemon 139809355978496)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>>
    └ <Thread(Thread-203, started daemon 139809355978496)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f28a29c3dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>
    └ <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f28a26d0730>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f288840db50>
    │    │                                │              │         └ '持续监测病毒  加强疫情防控（国际视点）'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f28a29c3e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f299a95f550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f288840db50>
               │    │                        │         └ '持续监测病毒  加强疫情防控（国际视点）'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f28a29c3f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f26e1d4b490>
                   │    │       │                                  │        │           └ '持续监测病毒  加强疫情防控（国际视点）'
                   │    │       │                                  │        └ <string.Template object at 0x7f26e1c5f9a0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f28a25d1850>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
               │        │    │          └ <function Template.substitute at 0x7f29ba4b40d0>
               │        │    └ <string.Template object at 0x7f26e1c5f9a0>
               │        └ <function post at 0x7f299829e430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f299830a0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f299829c9d0>
           └ <requests.sessions.Session object at 0x7f26e1a76d30>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f299829ce50>
           └ <requests.sessions.Session object at 0x7f26e1a76d30>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f299829c310>
        └ <requests.adapters.HTTPAdapter object at 0x7f26e1906be0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e19effa0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 16:23:45.015 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f29984b4280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f29984c2670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e0fb5610>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u96...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f299846a040>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f29a9d07280>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection.endheaders at 0x7f29a9d07160>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection._send_output at 0x7f29a9d6ed30>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f29a9d6eb80>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f2998469e50>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f2998469ca0>
           └ <urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f29984c28b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e0fb5610>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f29984bec10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e0fb5610>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f29ba4cba60>
    └ <Thread(Thread-157, started daemon 139810396149504)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f29ba4cb790>
    └ <Thread(Thread-157, started daemon 139810396149504)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-157, started daemon 139810396149504)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-157, started daemon 139810396149504)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>>
    └ <Thread(Thread-157, started daemon 139810396149504)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f28a29c3dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>
    └ <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f28a26d0730>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f28884ef9d0>
    │    │                                │              │         └ '持续监测病毒  加强疫情防控（国际视点）'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f28a29c3e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f299a95f550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f28884ef9d0>
               │    │                        │         └ '持续监测病毒  加强疫情防控（国际视点）'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f28a29c3f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f26e1e8ab20>
                   │    │       │                                  │        │           └ '持续监测病毒  加强疫情防控（国际视点）'
                   │    │       │                                  │        └ <string.Template object at 0x7f26e1e55eb0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f28a25d1850>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
               │        │    │          └ <function Template.substitute at 0x7f29ba4b40d0>
               │        │    └ <string.Template object at 0x7f26e1e55eb0>
               │        └ <function post at 0x7f299829e430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f299830a0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f299829c9d0>
           └ <requests.sessions.Session object at 0x7f26e0f221c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f299829ce50>
           └ <requests.sessions.Session object at 0x7f26e0f221c0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f299829c310>
        └ <requests.adapters.HTTPAdapter object at 0x7f26e18913d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e0f2e8b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 16:23:45.238 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f29984b4280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.246', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f29984c2670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e0ecc130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u96...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f299846a040>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f29a9d07280>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection.endheaders at 0x7f29a9d07160>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u6301\\u7eed\\u76d1\\u6d4b\\u75c5\\u6bd2  \\u52a0\\u5f3a\\u75ab\\u60c5\\u9632\\u63a7\\uff08\\u56fd\\u9645\\u89c6...
    │    └ <function HTTPConnection._send_output at 0x7f29a9d6ed30>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f29a9d6eb80>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f2998469e50>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f2998469ca0>
           └ <urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f29984c28b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e0ecc130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f29984bec10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e0ecc130>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f29ba4cba60>
    └ <Thread(Thread-286, started daemon 139808248665856)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f29ba4cb790>
    └ <Thread(Thread-286, started daemon 139808248665856)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-286, started daemon 139808248665856)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-286, started daemon 139808248665856)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>>
    └ <Thread(Thread-286, started daemon 139808248665856)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f28a29c3dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>
    └ <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f28a26d0730>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f2864662f10>
    │    │                                │              │         └ '持续监测病毒  加强疫情防控（国际视点）'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f28a29c3e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f299a95f550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f2864662f10>
               │    │                        │         └ '持续监测病毒  加强疫情防控（国际视点）'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f28a29c3f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f26e185e9d0>
                   │    │       │                                  │        │           └ '持续监测病毒  加强疫情防控（国际视点）'
                   │    │       │                                  │        └ <string.Template object at 0x7f26e1b560d0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f28a25d1850>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
               │        │    │          └ <function Template.substitute at 0x7f29ba4b40d0>
               │        │    └ <string.Template object at 0x7f26e1b560d0>
               │        └ <function post at 0x7f299829e430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'so...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f299830a0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '持续监测病毒  加强疫情防控（国际视点）', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f299829c9d0>
           └ <requests.sessions.Session object at 0x7f26e1858bb0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f299829ce50>
           └ <requests.sessions.Session object at 0x7f26e1858bb0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f299829c310>
        └ <requests.adapters.HTTPAdapter object at 0x7f26e0ee8a90>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e0ee8130>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 16:23:49.589 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f27c4585190>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f29984b4280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f29984c2670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e6bfc760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u4e24\\u5e74\\u95f4\\u65b0\\u51a0\\u75ab\\u60c5\\u76f4\\u63a5\\u6216...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f299846a040>
    └ <urllib3.connection.HTTPConnection object at 0x7f27c4585190>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u4e24\\u5e74\\u95f4\\u65b0\\u51a0\\u75ab\\u60c5\\u76f4\\u63a5\\u6216\\u95f4\\...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f27c4585190>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u4e24\\u5e74\\u95f4\\u65b0\\u51a0\\u75ab\\u60c5\\u76f4\\u63a5\\u6216\\u95f4\\...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f29a9d07280>
    └ <urllib3.connection.HTTPConnection object at 0x7f27c4585190>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u4e24\\u5e74\\u95f4\\u65b0\\u51a0\\u75ab\\u60c5\\u76f4\\u63a5\\u6216\\u95f4\\...
    │    └ <function HTTPConnection.endheaders at 0x7f29a9d07160>
    └ <urllib3.connection.HTTPConnection object at 0x7f27c4585190>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u4e16\\u536b\\u7ec4\\u7ec7\\uff1a\\u4e24\\u5e74\\u95f4\\u65b0\\u51a0\\u75ab\\u60c5\\u76f4\\u63a5\\u6216\\u95f4\\...
    │    └ <function HTTPConnection._send_output at 0x7f29a9d6ed30>
    └ <urllib3.connection.HTTPConnection object at 0x7f27c4585190>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f29a9d6eb80>
    └ <urllib3.connection.HTTPConnection object at 0x7f27c4585190>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f2998469e50>
    └ <urllib3.connection.HTTPConnection object at 0x7f27c4585190>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f2998469ca0>
           └ <urllib3.connection.HTTPConnection object at 0x7f27c4585190>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f27c4585190>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f29984c28b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e6bfc760>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f29984bec10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f27c4585190>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e6bfc760>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f27c4585190>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f29ba4cba60>
    └ <Thread(Thread-335, started daemon 139807208494848)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f29ba4cb790>
    └ <Thread(Thread-335, started daemon 139807208494848)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-335, started daemon 139807208494848)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-335, started daemon 139807208494848)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>>
    └ <Thread(Thread-335, started daemon 139807208494848)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f28a29c3dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>
    └ <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f28a26d0730>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f27e4641220>
    │    │                                │              │         └ '世卫组织：两年间新冠疫情直接或间接造成近1500万人死亡'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f28a29c3e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f299a95f550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f27e4641220>
               │    │                        │         └ '世卫组织：两年间新冠疫情直接或间接造成近1500万人死亡'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f28a29c3f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f2704666f70>
                   │    │       │                                  │        │           └ '世卫组织：两年间新冠疫情直接或间接造成近1500万人死亡'
                   │    │       │                                  │        └ <string.Template object at 0x7f26e1aea5b0>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f28a25d1850>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '世卫组织：两年间新冠疫情直接或间接造成近1500万人死亡', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type'...
               │        │    │          └ <function Template.substitute at 0x7f29ba4b40d0>
               │        │    └ <string.Template object at 0x7f26e1aea5b0>
               │        └ <function post at 0x7f299829e430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '世卫组织：两年间新冠疫情直接或间接造成近1500万人死亡', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type'...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f299830a0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '世卫组织：两年间新冠疫情直接或间接造成近1500万人死亡', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, ...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f299829c9d0>
           └ <requests.sessions.Session object at 0x7f26e185b790>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f299829ce50>
           └ <requests.sessions.Session object at 0x7f26e185b790>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f299829c310>
        └ <requests.adapters.HTTPAdapter object at 0x7f28443e4d90>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f27c4585190>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 16:23:54.033 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f29984b4280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f29984c2670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e058cb50>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u4ee5\\u6211\\u65e0\\u540d\\uff0c\\u6210\\u5c31\\u957f\\u5251\\u5a01\\u540d", "page": 1, "limit": 10, "...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f299846a040>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u4ee5\\u6211\\u65e0\\u540d\\uff0c\\u6210\\u5c31\\u957f\\u5251\\u5a01\\u540d", "page": 1, "limit": 10, "hasTitle"...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u4ee5\\u6211\\u65e0\\u540d\\uff0c\\u6210\\u5c31\\u957f\\u5251\\u5a01\\u540d", "page": 1, "limit": 10, "hasTitle"...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f29a9d07280>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u4ee5\\u6211\\u65e0\\u540d\\uff0c\\u6210\\u5c31\\u957f\\u5251\\u5a01\\u540d", "page": 1, "limit": 10, "hasTitle"...
    │    └ <function HTTPConnection.endheaders at 0x7f29a9d07160>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u4ee5\\u6211\\u65e0\\u540d\\uff0c\\u6210\\u5c31\\u957f\\u5251\\u5a01\\u540d", "page": 1, "limit": 10, "hasTitle"...
    │    └ <function HTTPConnection._send_output at 0x7f29a9d6ed30>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f29a9d6eb80>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f2998469e50>
    └ <urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f2998469ca0>
           └ <urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f29984c28b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e058cb50>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f29984bec10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26e058cb50>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f29ba4cba60>
    └ <Thread(Thread-521, started daemon 139805237126912)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f29ba4cb790>
    └ <Thread(Thread-521, started daemon 139805237126912)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-521, started daemon 139805237126912)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-521, started daemon 139805237126912)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>>
    └ <Thread(Thread-521, started daemon 139805237126912)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f28a29c3dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>
    └ <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f28a26d0730>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f2824641d60>
    │    │                                │              │         └ '以我无名，成就长剑威名'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f28a29c3e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f299a95f550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f2824641d60>
               │    │                        │         └ '以我无名，成就长剑威名'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f28a29c3f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f26e1b80040>
                   │    │       │                                  │        │           └ '以我无名，成就长剑威名'
                   │    │       │                                  │        └ <string.Template object at 0x7f26e1862b50>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f28a25d1850>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '以我无名，成就长剑威名', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': ...
               │        │    │          └ <function Template.substitute at 0x7f29ba4b40d0>
               │        │    └ <string.Template object at 0x7f26e1862b50>
               │        └ <function post at 0x7f299829e430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '以我无名，成就长剑威名', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortType': ...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f299830a0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '以我无名，成就长剑威名', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, ...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f299829c9d0>
           └ <requests.sessions.Session object at 0x7f26e0e542e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f299829ce50>
           └ <requests.sessions.Session object at 0x7f26e0e542e0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f299829c310>
        └ <requests.adapters.HTTPAdapter object at 0x7f26e058c580>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26e05f8f70>: Failed to establish a new connection: [Errno 111] Connection refused'))
2022-05-06 16:24:06.181 | ERROR    | monitor.searchSpiders.people:get_request_from_keyword:45 - E 人民网错误HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26dfeed130>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           │          └ <function create_connection at 0x7f29984b4280>
           └ <module 'urllib3.util.connection' from '/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py'>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 96, in create_connection
    raise err
          └ ConnectionRefusedError(111, 'Connection refused')
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 86, in create_connection
    sock.connect(sa)
    │            └ ('1.31.128.250', 80)
    └ None

ConnectionRefusedError: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 699, in urlopen
    httplib_response = self._make_request(
                       │    └ <function HTTPConnectionPool._make_request at 0x7f29984c2670>
                       └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26dff9e280>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 394, in _make_request
    conn.request(method, url, **httplib_request_kw)
    │    │       │       │      └ {'body': b'{"key": "\\u652f\\u6301\\u8d77\\u8bc9\\u4e3a\\u56f0\\u5883\\u672a\\u6210\\u5e74\\u4eba\\u201c\\u6491\\u8170\\u201d...
    │    │       │       └ '/search-platform/front/search'
    │    │       └ 'POST'
    │    └ <function HTTPConnection.request at 0x7f299846a040>
    └ <urllib3.connection.HTTPConnection object at 0x7f26dfeed130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
          │               │             │       │         │             └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
          │               │             │       │         └ b'{"key": "\\u652f\\u6301\\u8d77\\u8bc9\\u4e3a\\u56f0\\u5883\\u672a\\u6210\\u5e74\\u4eba\\u201c\\u6491\\u8170\\u201d", "page"...
          │               │             │       └ '/search-platform/front/search'
          │               │             └ 'POST'
          │               └ <urllib3.connection.HTTPConnection object at 0x7f26dfeed130>
          └ <class 'urllib3.connection.HTTPConnection'>
  File "/usr/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
    │    │             │       │    │     │        └ False
    │    │             │       │    │     └ {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari...
    │    │             │       │    └ b'{"key": "\\u652f\\u6301\\u8d77\\u8bc9\\u4e3a\\u56f0\\u5883\\u672a\\u6210\\u5e74\\u4eba\\u201c\\u6491\\u8170\\u201d", "page"...
    │    │             │       └ '/search-platform/front/search'
    │    │             └ 'POST'
    │    └ <function HTTPConnection._send_request at 0x7f29a9d07280>
    └ <urllib3.connection.HTTPConnection object at 0x7f26dfeed130>
  File "/usr/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
    │    │          │                    └ False
    │    │          └ b'{"key": "\\u652f\\u6301\\u8d77\\u8bc9\\u4e3a\\u56f0\\u5883\\u672a\\u6210\\u5e74\\u4eba\\u201c\\u6491\\u8170\\u201d", "page"...
    │    └ <function HTTPConnection.endheaders at 0x7f29a9d07160>
    └ <urllib3.connection.HTTPConnection object at 0x7f26dfeed130>
  File "/usr/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    │    │            │                            └ False
    │    │            └ b'{"key": "\\u652f\\u6301\\u8d77\\u8bc9\\u4e3a\\u56f0\\u5883\\u672a\\u6210\\u5e74\\u4eba\\u201c\\u6491\\u8170\\u201d", "page"...
    │    └ <function HTTPConnection._send_output at 0x7f29a9d6ed30>
    └ <urllib3.connection.HTTPConnection object at 0x7f26dfeed130>
  File "/usr/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
    │    │    └ b'POST /search-platform/front/search HTTP/1.1\r\nHost: search.people.cn\r\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x...
    │    └ <function HTTPConnection.send at 0x7f29a9d6eb80>
    └ <urllib3.connection.HTTPConnection object at 0x7f26dfeed130>
  File "/usr/lib/python3.8/http/client.py", line 951, in send
    self.connect()
    │    └ <function HTTPConnection.connect at 0x7f2998469e50>
    └ <urllib3.connection.HTTPConnection object at 0x7f26dfeed130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           │    └ <function HTTPConnection._new_conn at 0x7f2998469ca0>
           └ <urllib3.connection.HTTPConnection object at 0x7f26dfeed130>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
          └ <class 'urllib3.exceptions.NewConnectionError'>

urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f26dfeed130>: Failed to establish a new connection: [Errno 111] Connection refused


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
           │    └ <function HTTPConnectionPool.urlopen at 0x7f29984c28b0>
           └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26dff9e280>
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/connectionpool.py", line 755, in urlopen
    retries = retries.increment(
              │       └ <function Retry.increment at 0x7f29984bec10>
              └ Retry(total=0, connect=None, read=False, redirect=None, status=None)
  File "/home/chase/.local/lib/python3.8/site-packages/urllib3/util/retry.py", line 574, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
          │             │      │    │        │             └ 'unknown'
          │             │      │    │        └ <class 'urllib3.exceptions.ResponseError'>
          │             │      │    └ NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26dfeed130>: Failed to establish a new connection: [Errn...
          │             │      └ '/search-platform/front/search'
          │             └ <urllib3.connectionpool.HTTPConnectionPool object at 0x7f26dff9e280>
          └ <class 'urllib3.exceptions.MaxRetryError'>

urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26dfeed130>: Failed to establish a new connection: [Errno 111] Connection refused'))


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.8/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x7f29ba4cba60>
    └ <Thread(Thread-348, started daemon 139807216887552)>
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x7f29ba4cb790>
    └ <Thread(Thread-348, started daemon 139807216887552)>
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(Thread-348, started daemon 139807216887552)>
    │    │        │    └ ('ProjectManager.run_func_by_thread',)
    │    │        └ <Thread(Thread-348, started daemon 139807216887552)>
    │    └ <bound method ProjectManager.get_request_from_keywords_hot of <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>>
    └ <Thread(Thread-348, started daemon 139807216887552)>

  File "/home/users/Scy/yuqing/spider/monitor/projectManager.py", line 781, in get_request_from_keywords_hot
    self.search_spider_manager.crawl_by_keyword(
    │    │                     └ <function SearchSpidersManager.crawl_by_keyword at 0x7f28a29c3dc0>
    │    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>
    └ <monitor.projectManager.ProjectManager object at 0x7f28a29c12e0>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 118, in crawl_by_keyword
    self.crawl_by_keyword_signal_platform(project_names, platform, keyword, crawl_time, project_times)
    │    │                                │              │         │        │           └ {'default': <monitor.TimeSection object at 0x7f28a26d0730>}
    │    │                                │              │         │        └ <monitor.TimeSection object at 0x7f27e420e4f0>
    │    │                                │              │         └ '支持起诉为困境未成年人“撑腰”'
    │    │                                │              └ '人民网'
    │    │                                └ ['default']
    │    └ <function SearchSpidersManager.crawl_by_keyword_signal_platform at 0x7f28a29c3e50>
    └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 135, in crawl_by_keyword_signal_platform
    requests = self.get_request_from_keyword(platform, keyword, **crawl_time.to_dict())
               │    │                        │         │          │          └ <function TimeSection.to_dict at 0x7f299a95f550>
               │    │                        │         │          └ <monitor.TimeSection object at 0x7f27e420e4f0>
               │    │                        │         └ '支持起诉为困境未成年人“撑腰”'
               │    │                        └ '人民网'
               │    └ <function SearchSpidersManager.get_request_from_keyword at 0x7f28a29c3f70>
               └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

  File "/home/users/Scy/yuqing/spider/monitor/spiderManager.py", line 192, in get_request_from_keyword
    for request in self.spiders[platform].get_request_from_keyword(headers, search_url, keyword, content_url,
                   │    │       │                                  │        │           │        └ <string.Template object at 0x7f27242692e0>
                   │    │       │                                  │        │           └ '支持起诉为困境未成年人“撑腰”'
                   │    │       │                                  │        └ <string.Template object at 0x7f286443f730>
                   │    │       │                                  └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
                   │    │       └ '人民网'
                   │    └ {'凤凰网': <monitor.searchSpiders.ifeng.Ifeng object at 0x7f28a25d1850>, '头条': <monitor.searchSpiders.toutiao.Toutiao object at ...
                   └ <monitor.spiderManager.SearchSpidersManager object at 0x7f28a25d1c10>

> File "/home/users/Scy/yuqing/spider/monitor/searchSpiders/people.py", line 27, in get_request_from_keyword
    response = requests.post(search_url.substitute(), json=data, headers=headers)
               │        │    │          │                  │             └ {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Origin': 'h...
               │        │    │          │                  └ {'key': '支持起诉为困境未成年人“撑腰”', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortTyp...
               │        │    │          └ <function Template.substitute at 0x7f29ba4b40d0>
               │        │    └ <string.Template object at 0x7f286443f730>
               │        └ <function post at 0x7f299829e430>
               └ <module 'requests' from '/home/chase/.local/lib/python3.8/site-packages/requests/__init__.py'>

  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 117, in post
    return request('post', url, data=data, json=json, **kwargs)
           │               │         │          │       └ {'headers': {'Accept': 'application/json, text/plain, */*', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', ...
           │               │         │          └ {'key': '支持起诉为困境未成年人“撑腰”', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': True, 'type': 0, 'sortTyp...
           │               │         └ None
           │               └ 'http://search.people.cn/search-platform/front/search'
           └ <function request at 0x7f299830a0d0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
           │       │              │           │      └ {'data': None, 'json': {'key': '支持起诉为困境未成年人“撑腰”', 'page': 1, 'limit': 10, 'hasTitle': True, 'hasContent': True, 'isFuzzy': Tr...
           │       │              │           └ 'http://search.people.cn/search-platform/front/search'
           │       │              └ 'post'
           │       └ <function Session.request at 0x7f299829c9d0>
           └ <requests.sessions.Session object at 0x7f26dfeb4c70>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
           │    │    │       └ {'timeout': None, 'allow_redirects': True, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
           │    │    └ <PreparedRequest [POST]>
           │    └ <function Session.send at 0x7f299829ce50>
           └ <requests.sessions.Session object at 0x7f26dfeb4c70>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
        │       │    │          └ {'timeout': None, 'verify': True, 'proxies': OrderedDict(), 'stream': False, 'cert': None}
        │       │    └ <PreparedRequest [POST]>
        │       └ <function HTTPAdapter.send at 0x7f299829c310>
        └ <requests.adapters.HTTPAdapter object at 0x7f26dfd069a0>
  File "/home/chase/.local/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
          │                          └ <PreparedRequest [POST]>
          └ <class 'requests.exceptions.ConnectionError'>

requests.exceptions.ConnectionError: HTTPConnectionPool(host='search.people.cn', port=80): Max retries exceeded with url: /search-platform/front/search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f26dfeed130>: Failed to establish a new connection: [Errno 111] Connection refused'))
